{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas\n",
    "import sklearn\n",
    "import pydot\n",
    "import h5py\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "## 1. Generate data set.\n",
    "\n",
    "# get train set and test set from keras.(numpy ndarray data type.)\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() #여기서 테스트와 트레인 데이터 셋을 각각 가져옴(튜플로 되어있음))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate train set and validation set.\n",
    "X_val = X_train[50000:] # 10000개.\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000] # 50,000 개\n",
    "Y_train = Y_train[:50000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') /255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 700 numbers of value between 0~49999\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding.\n",
    "Y_train = np_utils.to_categorical(Y_train) \n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 344us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0932 - val_acc: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 2.0719 - acc: 0.2086 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 2.0521 - acc: 0.2129 - val_loss: 2.0563 - val_acc: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0409 - val_acc: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 2.0188 - acc: 0.2129 - val_loss: 2.0271 - val_acc: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 2.0042 - acc: 0.2186 - val_loss: 2.0124 - val_acc: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.9912 - acc: 0.2186 - val_loss: 2.0036 - val_acc: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.9788 - acc: 0.2286 - val_loss: 1.9957 - val_acc: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9685 - acc: 0.2314 - val_loss: 1.9834 - val_acc: 0.2067\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9581 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2067\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.9393 - acc: 0.2329 - val_loss: 1.9609 - val_acc: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.9308 - acc: 0.2314 - val_loss: 1.9536 - val_acc: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.9232 - acc: 0.2271 - val_loss: 1.9451 - val_acc: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9391 - val_acc: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.9085 - acc: 0.2329 - val_loss: 1.9359 - val_acc: 0.2067\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9288 - val_acc: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.8953 - acc: 0.2343 - val_loss: 1.9233 - val_acc: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.8894 - acc: 0.2329 - val_loss: 1.9200 - val_acc: 0.2067\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.8831 - acc: 0.2371 - val_loss: 1.9166 - val_acc: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.8771 - acc: 0.2329 - val_loss: 1.9111 - val_acc: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.8715 - acc: 0.2386 - val_loss: 1.9100 - val_acc: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.8664 - acc: 0.2400 - val_loss: 1.9083 - val_acc: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8615 - acc: 0.2429 - val_loss: 1.9053 - val_acc: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.8566 - acc: 0.2271 - val_loss: 1.8978 - val_acc: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.8514 - acc: 0.2471 - val_loss: 1.8969 - val_acc: 0.1900\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.8464 - acc: 0.2371 - val_loss: 1.8926 - val_acc: 0.1867\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.8424 - acc: 0.2243 - val_loss: 1.8874 - val_acc: 0.2100\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.8384 - acc: 0.2329 - val_loss: 1.8811 - val_acc: 0.1967\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.8336 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1933\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.8299 - acc: 0.2371 - val_loss: 1.8755 - val_acc: 0.1900\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.8258 - acc: 0.2514 - val_loss: 1.8744 - val_acc: 0.1800\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.8221 - acc: 0.2371 - val_loss: 1.8698 - val_acc: 0.1967\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.8185 - acc: 0.2443 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.8145 - acc: 0.2343 - val_loss: 1.8681 - val_acc: 0.1967\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.8075 - acc: 0.2486 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.8046 - acc: 0.2414 - val_loss: 1.8612 - val_acc: 0.1733\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.8001 - acc: 0.2429 - val_loss: 1.8573 - val_acc: 0.1933\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7970 - acc: 0.2471 - val_loss: 1.8565 - val_acc: 0.1767\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.7939 - acc: 0.2257 - val_loss: 1.8535 - val_acc: 0.1900\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8552 - val_acc: 0.1833\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7886 - acc: 0.2486 - val_loss: 1.8544 - val_acc: 0.1867\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7858 - acc: 0.2471 - val_loss: 1.8501 - val_acc: 0.1833\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7818 - acc: 0.2471 - val_loss: 1.8444 - val_acc: 0.2333\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7793 - acc: 0.2614 - val_loss: 1.8468 - val_acc: 0.1967\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.7761 - acc: 0.2486 - val_loss: 1.8412 - val_acc: 0.2000\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7742 - acc: 0.2543 - val_loss: 1.8488 - val_acc: 0.2067\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.7714 - acc: 0.2700 - val_loss: 1.8471 - val_acc: 0.1867\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7684 - acc: 0.2543 - val_loss: 1.8357 - val_acc: 0.2033\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7670 - acc: 0.2557 - val_loss: 1.8439 - val_acc: 0.2200\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7638 - acc: 0.2757 - val_loss: 1.8385 - val_acc: 0.2133\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7612 - acc: 0.2586 - val_loss: 1.8347 - val_acc: 0.2233\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7586 - acc: 0.2671 - val_loss: 1.8330 - val_acc: 0.2200\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 98us/step - loss: 1.7549 - acc: 0.2614 - val_loss: 1.8261 - val_acc: 0.2433\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7562 - acc: 0.2843 - val_loss: 1.8340 - val_acc: 0.2367\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7528 - acc: 0.2700 - val_loss: 1.8317 - val_acc: 0.2233\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7501 - acc: 0.2814 - val_loss: 1.8303 - val_acc: 0.2000\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7480 - acc: 0.2800 - val_loss: 1.8278 - val_acc: 0.2167\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7454 - acc: 0.2843 - val_loss: 1.8305 - val_acc: 0.2000\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7436 - acc: 0.2800 - val_loss: 1.8304 - val_acc: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7416 - acc: 0.2657 - val_loss: 1.8308 - val_acc: 0.2033\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7401 - acc: 0.2757 - val_loss: 1.8246 - val_acc: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.7373 - acc: 0.2843 - val_loss: 1.8309 - val_acc: 0.2167\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7352 - acc: 0.2843 - val_loss: 1.8280 - val_acc: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.7341 - acc: 0.2814 - val_loss: 1.8222 - val_acc: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7324 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.7294 - acc: 0.2857 - val_loss: 1.8267 - val_acc: 0.2467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7280 - acc: 0.2829 - val_loss: 1.8272 - val_acc: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7265 - acc: 0.2771 - val_loss: 1.8195 - val_acc: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7251 - acc: 0.2871 - val_loss: 1.8201 - val_acc: 0.2200\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.7224 - acc: 0.3071 - val_loss: 1.8233 - val_acc: 0.2033\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7208 - acc: 0.2857 - val_loss: 1.8200 - val_acc: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7195 - acc: 0.2829 - val_loss: 1.8200 - val_acc: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.7187 - acc: 0.2900 - val_loss: 1.8206 - val_acc: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7162 - acc: 0.2814 - val_loss: 1.8258 - val_acc: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7137 - acc: 0.2829 - val_loss: 1.8152 - val_acc: 0.2667\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7129 - acc: 0.2843 - val_loss: 1.8210 - val_acc: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7123 - acc: 0.2971 - val_loss: 1.8229 - val_acc: 0.2133\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7092 - acc: 0.3000 - val_loss: 1.8161 - val_acc: 0.2200\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7078 - acc: 0.2786 - val_loss: 1.8156 - val_acc: 0.2633\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.7047 - acc: 0.3071 - val_loss: 1.8199 - val_acc: 0.2733\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.7058 - acc: 0.3043 - val_loss: 1.8130 - val_acc: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.7040 - acc: 0.3014 - val_loss: 1.8179 - val_acc: 0.2167\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7024 - acc: 0.2829 - val_loss: 1.8168 - val_acc: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7015 - acc: 0.3071 - val_loss: 1.8202 - val_acc: 0.2133\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6985 - acc: 0.3129 - val_loss: 1.8233 - val_acc: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6977 - acc: 0.3043 - val_loss: 1.8177 - val_acc: 0.2733\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6962 - acc: 0.3186 - val_loss: 1.8198 - val_acc: 0.2100\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6936 - acc: 0.3029 - val_loss: 1.8246 - val_acc: 0.2833\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6941 - acc: 0.3071 - val_loss: 1.8116 - val_acc: 0.2233\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6922 - acc: 0.3057 - val_loss: 1.8274 - val_acc: 0.2200\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6914 - acc: 0.3057 - val_loss: 1.8129 - val_acc: 0.2167\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6893 - acc: 0.3143 - val_loss: 1.8252 - val_acc: 0.2200\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6881 - acc: 0.3029 - val_loss: 1.8233 - val_acc: 0.2300\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6869 - acc: 0.3157 - val_loss: 1.8220 - val_acc: 0.2233\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6868 - acc: 0.3071 - val_loss: 1.8232 - val_acc: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6834 - acc: 0.3057 - val_loss: 1.8119 - val_acc: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6834 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2167\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6812 - acc: 0.3100 - val_loss: 1.8090 - val_acc: 0.2100\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6804 - acc: 0.3200 - val_loss: 1.8208 - val_acc: 0.2200\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6795 - acc: 0.3143 - val_loss: 1.8248 - val_acc: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6774 - acc: 0.3157 - val_loss: 1.8200 - val_acc: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6771 - acc: 0.3129 - val_loss: 1.8203 - val_acc: 0.2333\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6764 - acc: 0.3214 - val_loss: 1.8170 - val_acc: 0.2200\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6765 - acc: 0.3071 - val_loss: 1.8213 - val_acc: 0.2233\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6732 - acc: 0.3200 - val_loss: 1.8223 - val_acc: 0.2267\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6725 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2367\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6714 - acc: 0.3086 - val_loss: 1.8227 - val_acc: 0.2200\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6698 - acc: 0.3171 - val_loss: 1.8140 - val_acc: 0.2367\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6689 - acc: 0.3257 - val_loss: 1.8307 - val_acc: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6684 - acc: 0.3129 - val_loss: 1.8233 - val_acc: 0.2300\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6670 - acc: 0.3157 - val_loss: 1.8280 - val_acc: 0.2333\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6656 - acc: 0.3286 - val_loss: 1.8260 - val_acc: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6647 - acc: 0.3186 - val_loss: 1.8246 - val_acc: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6633 - acc: 0.3157 - val_loss: 1.8152 - val_acc: 0.2267\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6622 - acc: 0.3214 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6614 - acc: 0.3229 - val_loss: 1.8175 - val_acc: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6601 - acc: 0.3186 - val_loss: 1.8246 - val_acc: 0.2367\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6590 - acc: 0.3171 - val_loss: 1.8296 - val_acc: 0.2367\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6573 - acc: 0.3186 - val_loss: 1.8294 - val_acc: 0.2267\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6565 - acc: 0.3171 - val_loss: 1.8174 - val_acc: 0.2400\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6545 - acc: 0.3357 - val_loss: 1.8330 - val_acc: 0.2200\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6549 - acc: 0.3143 - val_loss: 1.8269 - val_acc: 0.2233\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6527 - acc: 0.3257 - val_loss: 1.8178 - val_acc: 0.2567\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6524 - acc: 0.3229 - val_loss: 1.8283 - val_acc: 0.2533\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6522 - acc: 0.3286 - val_loss: 1.8167 - val_acc: 0.2233\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6505 - acc: 0.3257 - val_loss: 1.8354 - val_acc: 0.2500\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.6490 - acc: 0.3200 - val_loss: 1.8272 - val_acc: 0.2733\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6487 - acc: 0.3314 - val_loss: 1.8251 - val_acc: 0.2300\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6471 - acc: 0.3229 - val_loss: 1.8215 - val_acc: 0.2333\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6462 - acc: 0.3200 - val_loss: 1.8227 - val_acc: 0.2300\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.6466 - acc: 0.3214 - val_loss: 1.8264 - val_acc: 0.2367\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6438 - acc: 0.3300 - val_loss: 1.8513 - val_acc: 0.2467\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6439 - acc: 0.3286 - val_loss: 1.8182 - val_acc: 0.2300\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6422 - acc: 0.3286 - val_loss: 1.8329 - val_acc: 0.2367\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6410 - acc: 0.3314 - val_loss: 1.8214 - val_acc: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6410 - acc: 0.3286 - val_loss: 1.8377 - val_acc: 0.2533\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6403 - acc: 0.3443 - val_loss: 1.8325 - val_acc: 0.2333\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6393 - acc: 0.3314 - val_loss: 1.8231 - val_acc: 0.2200\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6369 - acc: 0.3386 - val_loss: 1.8372 - val_acc: 0.2267\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6389 - acc: 0.3157 - val_loss: 1.8363 - val_acc: 0.2367\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6370 - acc: 0.3343 - val_loss: 1.8304 - val_acc: 0.2533\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6357 - acc: 0.3371 - val_loss: 1.8218 - val_acc: 0.2133\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6348 - acc: 0.3286 - val_loss: 1.8306 - val_acc: 0.2267\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6346 - acc: 0.3300 - val_loss: 1.8260 - val_acc: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6337 - acc: 0.3329 - val_loss: 1.8307 - val_acc: 0.2333\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6322 - acc: 0.3443 - val_loss: 1.8293 - val_acc: 0.2333\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6301 - acc: 0.3500 - val_loss: 1.8372 - val_acc: 0.2233\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6304 - acc: 0.3257 - val_loss: 1.8232 - val_acc: 0.2367\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6308 - acc: 0.3329 - val_loss: 1.8346 - val_acc: 0.2267\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6290 - acc: 0.3357 - val_loss: 1.8266 - val_acc: 0.2200\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6292 - acc: 0.3386 - val_loss: 1.8354 - val_acc: 0.2333\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6272 - acc: 0.3314 - val_loss: 1.8352 - val_acc: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.6266 - acc: 0.3343 - val_loss: 1.8328 - val_acc: 0.2300\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6258 - acc: 0.3343 - val_loss: 1.8422 - val_acc: 0.2300\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6252 - acc: 0.3329 - val_loss: 1.8387 - val_acc: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6240 - acc: 0.3357 - val_loss: 1.8380 - val_acc: 0.2267\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6227 - acc: 0.3386 - val_loss: 1.8279 - val_acc: 0.2133\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6223 - acc: 0.3243 - val_loss: 1.8411 - val_acc: 0.2400\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.6218 - acc: 0.3329 - val_loss: 1.8363 - val_acc: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.6208 - acc: 0.3329 - val_loss: 1.8405 - val_acc: 0.2567\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.6196 - acc: 0.3443 - val_loss: 1.8463 - val_acc: 0.2200\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6186 - acc: 0.3443 - val_loss: 1.8540 - val_acc: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8357 - val_acc: 0.2267\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6160 - acc: 0.3271 - val_loss: 1.8518 - val_acc: 0.2633\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6151 - acc: 0.3443 - val_loss: 1.8405 - val_acc: 0.2200\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6170 - acc: 0.3400 - val_loss: 1.8404 - val_acc: 0.2433\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.6158 - acc: 0.3357 - val_loss: 1.8424 - val_acc: 0.2167\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6156 - acc: 0.3386 - val_loss: 1.8429 - val_acc: 0.2233\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.6134 - acc: 0.3286 - val_loss: 1.8422 - val_acc: 0.2667\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6124 - acc: 0.3414 - val_loss: 1.8398 - val_acc: 0.2200\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6130 - acc: 0.3400 - val_loss: 1.8437 - val_acc: 0.2300\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 114us/step - loss: 1.6125 - acc: 0.3471 - val_loss: 1.8386 - val_acc: 0.2267\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6102 - acc: 0.3400 - val_loss: 1.8430 - val_acc: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8358 - val_acc: 0.2567\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6097 - acc: 0.3457 - val_loss: 1.8391 - val_acc: 0.2167\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6106 - acc: 0.3329 - val_loss: 1.8442 - val_acc: 0.2300\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.6083 - acc: 0.3500 - val_loss: 1.8470 - val_acc: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6067 - acc: 0.3400 - val_loss: 1.8662 - val_acc: 0.2233\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6077 - acc: 0.3443 - val_loss: 1.8462 - val_acc: 0.2267\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6057 - acc: 0.3543 - val_loss: 1.8476 - val_acc: 0.2200\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6067 - acc: 0.3400 - val_loss: 1.8433 - val_acc: 0.2200\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6037 - acc: 0.3529 - val_loss: 1.8557 - val_acc: 0.2200\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6058 - acc: 0.3314 - val_loss: 1.8424 - val_acc: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6032 - acc: 0.3571 - val_loss: 1.8625 - val_acc: 0.2233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6037 - acc: 0.3486 - val_loss: 1.8526 - val_acc: 0.2233\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6021 - acc: 0.3443 - val_loss: 1.8571 - val_acc: 0.2300\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6016 - acc: 0.3400 - val_loss: 1.8503 - val_acc: 0.2300\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6011 - acc: 0.3471 - val_loss: 1.8485 - val_acc: 0.2467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6008 - acc: 0.3500 - val_loss: 1.8509 - val_acc: 0.2200\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5994 - acc: 0.3500 - val_loss: 1.8512 - val_acc: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5998 - acc: 0.3400 - val_loss: 1.8612 - val_acc: 0.2233\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5995 - acc: 0.3400 - val_loss: 1.8579 - val_acc: 0.2233\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5967 - acc: 0.3457 - val_loss: 1.8624 - val_acc: 0.2633\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5978 - acc: 0.3443 - val_loss: 1.8496 - val_acc: 0.2167\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5972 - acc: 0.3471 - val_loss: 1.8499 - val_acc: 0.2100\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5959 - acc: 0.3386 - val_loss: 1.8599 - val_acc: 0.2300\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5946 - acc: 0.3629 - val_loss: 1.8489 - val_acc: 0.2167\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5946 - acc: 0.3457 - val_loss: 1.8532 - val_acc: 0.2233\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5938 - acc: 0.3543 - val_loss: 1.8498 - val_acc: 0.2133\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5940 - acc: 0.3529 - val_loss: 1.8572 - val_acc: 0.2267\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5913 - acc: 0.3457 - val_loss: 1.8627 - val_acc: 0.2233\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5912 - acc: 0.3500 - val_loss: 1.8551 - val_acc: 0.2367\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5907 - acc: 0.3471 - val_loss: 1.8530 - val_acc: 0.2300\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5896 - acc: 0.3429 - val_loss: 1.8479 - val_acc: 0.2600\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5907 - acc: 0.3514 - val_loss: 1.8624 - val_acc: 0.2300\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5888 - acc: 0.3500 - val_loss: 1.8556 - val_acc: 0.2300\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5899 - acc: 0.3457 - val_loss: 1.8577 - val_acc: 0.2300\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5880 - acc: 0.3486 - val_loss: 1.8606 - val_acc: 0.2667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5889 - acc: 0.3514 - val_loss: 1.8657 - val_acc: 0.2300\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5875 - acc: 0.3457 - val_loss: 1.8674 - val_acc: 0.2267\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5870 - acc: 0.3457 - val_loss: 1.8631 - val_acc: 0.2300\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5860 - acc: 0.3471 - val_loss: 1.8702 - val_acc: 0.2267\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5850 - acc: 0.3529 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5851 - acc: 0.3471 - val_loss: 1.8646 - val_acc: 0.2267\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5838 - acc: 0.3500 - val_loss: 1.8798 - val_acc: 0.2433\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5839 - acc: 0.3443 - val_loss: 1.8649 - val_acc: 0.2600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5840 - acc: 0.3543 - val_loss: 1.8779 - val_acc: 0.2433\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5827 - acc: 0.3443 - val_loss: 1.8598 - val_acc: 0.2200\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5830 - acc: 0.3500 - val_loss: 1.8710 - val_acc: 0.2267\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5819 - acc: 0.3471 - val_loss: 1.8662 - val_acc: 0.2167\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5818 - acc: 0.3443 - val_loss: 1.8753 - val_acc: 0.2333\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5796 - acc: 0.3543 - val_loss: 1.8736 - val_acc: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5814 - acc: 0.3400 - val_loss: 1.8657 - val_acc: 0.2167\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5793 - acc: 0.3543 - val_loss: 1.8669 - val_acc: 0.2233\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5804 - acc: 0.3529 - val_loss: 1.8785 - val_acc: 0.2200\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5791 - acc: 0.3486 - val_loss: 1.8842 - val_acc: 0.2300\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5786 - acc: 0.3471 - val_loss: 1.8722 - val_acc: 0.2200\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5771 - acc: 0.3571 - val_loss: 1.8741 - val_acc: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5773 - acc: 0.3457 - val_loss: 1.8694 - val_acc: 0.2167\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5765 - acc: 0.3471 - val_loss: 1.8763 - val_acc: 0.2300\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5769 - acc: 0.3457 - val_loss: 1.8661 - val_acc: 0.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5764 - acc: 0.3543 - val_loss: 1.8733 - val_acc: 0.2300\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5745 - acc: 0.3543 - val_loss: 1.8776 - val_acc: 0.2467\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5743 - acc: 0.3571 - val_loss: 1.8800 - val_acc: 0.2433\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5739 - acc: 0.3543 - val_loss: 1.8786 - val_acc: 0.2067\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5738 - acc: 0.3600 - val_loss: 1.8846 - val_acc: 0.2167\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5706 - acc: 0.3600 - val_loss: 1.8761 - val_acc: 0.2200\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5710 - acc: 0.3586 - val_loss: 1.8891 - val_acc: 0.2300\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5707 - acc: 0.3543 - val_loss: 1.8755 - val_acc: 0.2633\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5717 - acc: 0.3543 - val_loss: 1.8651 - val_acc: 0.2200\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5711 - acc: 0.3557 - val_loss: 1.8727 - val_acc: 0.2300\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5708 - acc: 0.3471 - val_loss: 1.8867 - val_acc: 0.2267\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5674 - acc: 0.3614 - val_loss: 1.9022 - val_acc: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5699 - acc: 0.3471 - val_loss: 1.8841 - val_acc: 0.2333\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5677 - acc: 0.3657 - val_loss: 1.8803 - val_acc: 0.2267\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5684 - acc: 0.3543 - val_loss: 1.8864 - val_acc: 0.2167\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5674 - acc: 0.3557 - val_loss: 1.8857 - val_acc: 0.2267\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5677 - acc: 0.3471 - val_loss: 1.8744 - val_acc: 0.2300\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5653 - acc: 0.3529 - val_loss: 1.8795 - val_acc: 0.2533\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5662 - acc: 0.3486 - val_loss: 1.8948 - val_acc: 0.2367\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5644 - acc: 0.3600 - val_loss: 1.9015 - val_acc: 0.2567\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5642 - acc: 0.3629 - val_loss: 1.8975 - val_acc: 0.2233\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5653 - acc: 0.3629 - val_loss: 1.9021 - val_acc: 0.2233\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5632 - acc: 0.3586 - val_loss: 1.8782 - val_acc: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5634 - acc: 0.3600 - val_loss: 1.8893 - val_acc: 0.2100\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5627 - acc: 0.3643 - val_loss: 1.8925 - val_acc: 0.2200\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5634 - acc: 0.3557 - val_loss: 1.8868 - val_acc: 0.2067\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5634 - acc: 0.3657 - val_loss: 1.8963 - val_acc: 0.2267\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5609 - acc: 0.3629 - val_loss: 1.9026 - val_acc: 0.2467\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8956 - val_acc: 0.2267\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5608 - acc: 0.3629 - val_loss: 1.8804 - val_acc: 0.2167\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5596 - acc: 0.3657 - val_loss: 1.8883 - val_acc: 0.2167\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5592 - acc: 0.3686 - val_loss: 1.8748 - val_acc: 0.2333\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5605 - acc: 0.3643 - val_loss: 1.8974 - val_acc: 0.2300\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.9101 - val_acc: 0.2267\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5587 - acc: 0.3571 - val_loss: 1.9020 - val_acc: 0.2133\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5584 - acc: 0.3471 - val_loss: 1.8899 - val_acc: 0.2233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5585 - acc: 0.3586 - val_loss: 1.9001 - val_acc: 0.2233\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5575 - acc: 0.3543 - val_loss: 1.9018 - val_acc: 0.2567\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5576 - acc: 0.3743 - val_loss: 1.8968 - val_acc: 0.2167\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5574 - acc: 0.3600 - val_loss: 1.9086 - val_acc: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5554 - acc: 0.3586 - val_loss: 1.8917 - val_acc: 0.2200\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5555 - acc: 0.3657 - val_loss: 1.8934 - val_acc: 0.2167\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5537 - acc: 0.3557 - val_loss: 1.8958 - val_acc: 0.2333\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5550 - acc: 0.3700 - val_loss: 1.8885 - val_acc: 0.2200\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5537 - acc: 0.3557 - val_loss: 1.8992 - val_acc: 0.2233\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5538 - acc: 0.3586 - val_loss: 1.8983 - val_acc: 0.2600\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5531 - acc: 0.3586 - val_loss: 1.8938 - val_acc: 0.2200\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5532 - acc: 0.3557 - val_loss: 1.9053 - val_acc: 0.2233\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5523 - acc: 0.3700 - val_loss: 1.9063 - val_acc: 0.2133\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5520 - acc: 0.3600 - val_loss: 1.8988 - val_acc: 0.2100\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5515 - acc: 0.3600 - val_loss: 1.9081 - val_acc: 0.2100\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5509 - acc: 0.3657 - val_loss: 1.9104 - val_acc: 0.2200\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5509 - acc: 0.3571 - val_loss: 1.9098 - val_acc: 0.2200\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5503 - acc: 0.3514 - val_loss: 1.9043 - val_acc: 0.2400\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5502 - acc: 0.3543 - val_loss: 1.9065 - val_acc: 0.2333\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5493 - acc: 0.3571 - val_loss: 1.9111 - val_acc: 0.2600\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5495 - acc: 0.3729 - val_loss: 1.9143 - val_acc: 0.2133\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5490 - acc: 0.3557 - val_loss: 1.9151 - val_acc: 0.2067\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5475 - acc: 0.3586 - val_loss: 1.9183 - val_acc: 0.2167\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 111us/step - loss: 1.5473 - acc: 0.3486 - val_loss: 1.9016 - val_acc: 0.2300\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5480 - acc: 0.3671 - val_loss: 1.9222 - val_acc: 0.2300\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5469 - acc: 0.3657 - val_loss: 1.9092 - val_acc: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5465 - acc: 0.3629 - val_loss: 1.8993 - val_acc: 0.2200\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5475 - acc: 0.3671 - val_loss: 1.9139 - val_acc: 0.2200\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5461 - acc: 0.3543 - val_loss: 1.9057 - val_acc: 0.2367\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5448 - acc: 0.3714 - val_loss: 1.9111 - val_acc: 0.2167\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5428 - acc: 0.3686 - val_loss: 1.9211 - val_acc: 0.2233\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5454 - acc: 0.3657 - val_loss: 1.9146 - val_acc: 0.2333\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5431 - acc: 0.3714 - val_loss: 1.9140 - val_acc: 0.2300\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5448 - acc: 0.3600 - val_loss: 1.9182 - val_acc: 0.2333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5432 - acc: 0.3629 - val_loss: 1.9207 - val_acc: 0.2333\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5444 - acc: 0.3657 - val_loss: 1.9132 - val_acc: 0.2233\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5423 - acc: 0.3586 - val_loss: 1.9092 - val_acc: 0.2300\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5419 - acc: 0.3729 - val_loss: 1.9359 - val_acc: 0.2333\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5383 - acc: 0.3700 - val_loss: 1.9114 - val_acc: 0.2567\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5428 - acc: 0.3686 - val_loss: 1.9199 - val_acc: 0.2300\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5401 - acc: 0.3657 - val_loss: 1.9172 - val_acc: 0.2233\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5401 - acc: 0.3657 - val_loss: 1.9196 - val_acc: 0.2267\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5408 - acc: 0.3600 - val_loss: 1.9277 - val_acc: 0.2333\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5404 - acc: 0.3643 - val_loss: 1.9163 - val_acc: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5386 - acc: 0.3586 - val_loss: 1.9136 - val_acc: 0.2233\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5388 - acc: 0.3614 - val_loss: 1.9327 - val_acc: 0.2233\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5389 - acc: 0.3686 - val_loss: 1.9322 - val_acc: 0.2300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5370 - acc: 0.3671 - val_loss: 1.9240 - val_acc: 0.2567\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5379 - acc: 0.3700 - val_loss: 1.9248 - val_acc: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5368 - acc: 0.3700 - val_loss: 1.9306 - val_acc: 0.2233\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5383 - acc: 0.3600 - val_loss: 1.9213 - val_acc: 0.2133\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5361 - acc: 0.3600 - val_loss: 1.9291 - val_acc: 0.2267\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5354 - acc: 0.3757 - val_loss: 1.9449 - val_acc: 0.2300\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5363 - acc: 0.3614 - val_loss: 1.9366 - val_acc: 0.2267\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5351 - acc: 0.3743 - val_loss: 1.9215 - val_acc: 0.2267\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5347 - acc: 0.3657 - val_loss: 1.9312 - val_acc: 0.2333\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5333 - acc: 0.3643 - val_loss: 1.9243 - val_acc: 0.2200\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5343 - acc: 0.3600 - val_loss: 1.9379 - val_acc: 0.2533\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5354 - acc: 0.3729 - val_loss: 1.9298 - val_acc: 0.2300\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5346 - acc: 0.3614 - val_loss: 1.9335 - val_acc: 0.2300\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5432 - acc: 0.373 - 0s 107us/step - loss: 1.5323 - acc: 0.3786 - val_loss: 1.9320 - val_acc: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5331 - acc: 0.3800 - val_loss: 1.9244 - val_acc: 0.2267\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5328 - acc: 0.3786 - val_loss: 1.9371 - val_acc: 0.2200\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5318 - acc: 0.3814 - val_loss: 1.9304 - val_acc: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5308 - acc: 0.3729 - val_loss: 1.9235 - val_acc: 0.2133\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5324 - acc: 0.3743 - val_loss: 1.9475 - val_acc: 0.2233\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.5312 - acc: 0.3786 - val_loss: 1.9290 - val_acc: 0.2333\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5303 - acc: 0.3643 - val_loss: 1.9503 - val_acc: 0.2200\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5303 - acc: 0.3700 - val_loss: 1.9401 - val_acc: 0.2233\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5296 - acc: 0.3700 - val_loss: 1.9492 - val_acc: 0.2233\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.5281 - acc: 0.3700 - val_loss: 1.9504 - val_acc: 0.2467\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5289 - acc: 0.3714 - val_loss: 1.9415 - val_acc: 0.2300\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5267 - acc: 0.3829 - val_loss: 1.9226 - val_acc: 0.2233\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5270 - acc: 0.3629 - val_loss: 1.9381 - val_acc: 0.2133\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5269 - acc: 0.3714 - val_loss: 1.9358 - val_acc: 0.2200\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5265 - acc: 0.3714 - val_loss: 1.9368 - val_acc: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.5247 - acc: 0.3771 - val_loss: 1.9368 - val_acc: 0.2367\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5263 - acc: 0.3771 - val_loss: 1.9366 - val_acc: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5239 - acc: 0.3671 - val_loss: 1.9489 - val_acc: 0.2267\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5259 - acc: 0.3786 - val_loss: 1.9393 - val_acc: 0.2167\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5244 - acc: 0.3614 - val_loss: 1.9548 - val_acc: 0.2300\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5239 - acc: 0.3729 - val_loss: 1.9489 - val_acc: 0.2400\n",
      "Epoch 357/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 89us/step - loss: 1.5238 - acc: 0.3757 - val_loss: 1.9381 - val_acc: 0.2300\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5230 - acc: 0.3743 - val_loss: 1.9576 - val_acc: 0.2167\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5232 - acc: 0.3800 - val_loss: 1.9498 - val_acc: 0.2200\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5213 - acc: 0.3700 - val_loss: 1.9540 - val_acc: 0.2167\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5207 - acc: 0.3714 - val_loss: 1.9511 - val_acc: 0.2300\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5220 - acc: 0.3657 - val_loss: 1.9543 - val_acc: 0.2200\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5194 - acc: 0.3743 - val_loss: 1.9577 - val_acc: 0.2333\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5204 - acc: 0.3657 - val_loss: 1.9386 - val_acc: 0.2300\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5204 - acc: 0.3800 - val_loss: 1.9564 - val_acc: 0.2167\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5200 - acc: 0.3771 - val_loss: 1.9431 - val_acc: 0.2133\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5201 - acc: 0.3786 - val_loss: 1.9540 - val_acc: 0.2233\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5186 - acc: 0.3829 - val_loss: 1.9552 - val_acc: 0.2333\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5185 - acc: 0.3729 - val_loss: 1.9365 - val_acc: 0.2367\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5177 - acc: 0.3714 - val_loss: 1.9570 - val_acc: 0.2333\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5184 - acc: 0.3657 - val_loss: 1.9574 - val_acc: 0.2200\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5171 - acc: 0.3743 - val_loss: 1.9619 - val_acc: 0.2300\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5180 - acc: 0.3729 - val_loss: 1.9597 - val_acc: 0.2200\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5172 - acc: 0.3657 - val_loss: 1.9547 - val_acc: 0.2333\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5158 - acc: 0.3857 - val_loss: 1.9442 - val_acc: 0.2267\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5159 - acc: 0.3786 - val_loss: 1.9532 - val_acc: 0.2200\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5150 - acc: 0.3729 - val_loss: 1.9741 - val_acc: 0.2233\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5157 - acc: 0.3757 - val_loss: 1.9804 - val_acc: 0.2367\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5165 - acc: 0.3686 - val_loss: 1.9547 - val_acc: 0.2400\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.5140 - acc: 0.3686 - val_loss: 1.9638 - val_acc: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5153 - acc: 0.3800 - val_loss: 1.9763 - val_acc: 0.2133\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5138 - acc: 0.3743 - val_loss: 1.9598 - val_acc: 0.2200\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5130 - acc: 0.3800 - val_loss: 1.9689 - val_acc: 0.2433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5137 - acc: 0.3843 - val_loss: 1.9524 - val_acc: 0.2233\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.5139 - acc: 0.3814 - val_loss: 1.9601 - val_acc: 0.2200\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5130 - acc: 0.3743 - val_loss: 1.9506 - val_acc: 0.2400\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5128 - acc: 0.3843 - val_loss: 1.9617 - val_acc: 0.2333\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5116 - acc: 0.3757 - val_loss: 1.9701 - val_acc: 0.2500\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5134 - acc: 0.3814 - val_loss: 1.9539 - val_acc: 0.2267\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5099 - acc: 0.3686 - val_loss: 1.9586 - val_acc: 0.2400\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5104 - acc: 0.3886 - val_loss: 1.9590 - val_acc: 0.2367\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5111 - acc: 0.3771 - val_loss: 1.9601 - val_acc: 0.2267\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5113 - acc: 0.3786 - val_loss: 1.9701 - val_acc: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5105 - acc: 0.3786 - val_loss: 1.9605 - val_acc: 0.2300\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5103 - acc: 0.3857 - val_loss: 1.9572 - val_acc: 0.2233\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5098 - acc: 0.3786 - val_loss: 1.9649 - val_acc: 0.2267\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5086 - acc: 0.3871 - val_loss: 1.9768 - val_acc: 0.2333\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5098 - acc: 0.3671 - val_loss: 1.9594 - val_acc: 0.2300\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5088 - acc: 0.3757 - val_loss: 1.9809 - val_acc: 0.2300\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5089 - acc: 0.3743 - val_loss: 1.9617 - val_acc: 0.2233\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5088 - acc: 0.3671 - val_loss: 1.9653 - val_acc: 0.2367\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5066 - acc: 0.3800 - val_loss: 1.9689 - val_acc: 0.2300\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5051 - acc: 0.3829 - val_loss: 1.9914 - val_acc: 0.2233\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5064 - acc: 0.3800 - val_loss: 1.9636 - val_acc: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5054 - acc: 0.3829 - val_loss: 1.9848 - val_acc: 0.2267\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5066 - acc: 0.3857 - val_loss: 1.9870 - val_acc: 0.2200\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5067 - acc: 0.3843 - val_loss: 1.9742 - val_acc: 0.2367\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5062 - acc: 0.3829 - val_loss: 1.9688 - val_acc: 0.2300\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5024 - acc: 0.3771 - val_loss: 1.9819 - val_acc: 0.2400\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5047 - acc: 0.3843 - val_loss: 1.9650 - val_acc: 0.2233\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5048 - acc: 0.3771 - val_loss: 1.9829 - val_acc: 0.2267\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5044 - acc: 0.3929 - val_loss: 1.9758 - val_acc: 0.2267\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5026 - acc: 0.3771 - val_loss: 1.9726 - val_acc: 0.2367\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5038 - acc: 0.3829 - val_loss: 1.9853 - val_acc: 0.2333\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5011 - acc: 0.3729 - val_loss: 1.9849 - val_acc: 0.2400\n",
      "Epoch 416/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 123us/step - loss: 1.5024 - acc: 0.3886 - val_loss: 1.9949 - val_acc: 0.2167\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5030 - acc: 0.3786 - val_loss: 1.9820 - val_acc: 0.2233\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5015 - acc: 0.3900 - val_loss: 1.9846 - val_acc: 0.2400\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5016 - acc: 0.3786 - val_loss: 1.9718 - val_acc: 0.2267\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5016 - acc: 0.3829 - val_loss: 1.9954 - val_acc: 0.2333\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5016 - acc: 0.3886 - val_loss: 1.9746 - val_acc: 0.2400\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5002 - acc: 0.3800 - val_loss: 1.9733 - val_acc: 0.2400\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5003 - acc: 0.3871 - val_loss: 1.9843 - val_acc: 0.2400\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5000 - acc: 0.3757 - val_loss: 1.9632 - val_acc: 0.2233\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4993 - acc: 0.3957 - val_loss: 1.9719 - val_acc: 0.2400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4985 - acc: 0.3957 - val_loss: 1.9862 - val_acc: 0.2200\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4983 - acc: 0.3843 - val_loss: 1.9847 - val_acc: 0.2600\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4988 - acc: 0.3871 - val_loss: 2.0064 - val_acc: 0.2267\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4986 - acc: 0.3814 - val_loss: 1.9722 - val_acc: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4981 - acc: 0.3871 - val_loss: 1.9820 - val_acc: 0.2500\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4994 - acc: 0.3929 - val_loss: 1.9876 - val_acc: 0.2300\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4981 - acc: 0.3843 - val_loss: 1.9844 - val_acc: 0.2267\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4973 - acc: 0.3814 - val_loss: 1.9859 - val_acc: 0.2400\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4980 - acc: 0.3757 - val_loss: 1.9866 - val_acc: 0.2267\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4965 - acc: 0.3957 - val_loss: 1.9838 - val_acc: 0.2333\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4979 - acc: 0.3871 - val_loss: 1.9700 - val_acc: 0.2267\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4963 - acc: 0.3943 - val_loss: 1.9879 - val_acc: 0.2300\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4955 - acc: 0.3900 - val_loss: 1.9658 - val_acc: 0.2300\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4952 - acc: 0.3757 - val_loss: 1.9761 - val_acc: 0.2267\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4964 - acc: 0.3814 - val_loss: 1.9777 - val_acc: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4957 - acc: 0.3871 - val_loss: 1.9828 - val_acc: 0.2267\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4953 - acc: 0.3857 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4946 - acc: 0.3843 - val_loss: 1.9830 - val_acc: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4955 - acc: 0.3843 - val_loss: 1.9983 - val_acc: 0.2267\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4949 - acc: 0.3829 - val_loss: 1.9953 - val_acc: 0.2367\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4940 - acc: 0.3800 - val_loss: 1.9938 - val_acc: 0.2300\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 2.0143 - val_acc: 0.2267\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4933 - acc: 0.3857 - val_loss: 1.9867 - val_acc: 0.2267\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4931 - acc: 0.3957 - val_loss: 2.0036 - val_acc: 0.2333\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4940 - acc: 0.3871 - val_loss: 1.9937 - val_acc: 0.2267\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4931 - acc: 0.3814 - val_loss: 1.9957 - val_acc: 0.2200\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4924 - acc: 0.3857 - val_loss: 1.9909 - val_acc: 0.2233\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4920 - acc: 0.3871 - val_loss: 1.9880 - val_acc: 0.2333\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4920 - acc: 0.3886 - val_loss: 1.9988 - val_acc: 0.2267\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4919 - acc: 0.3800 - val_loss: 1.9846 - val_acc: 0.2300\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4912 - acc: 0.3857 - val_loss: 1.9927 - val_acc: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4908 - acc: 0.3900 - val_loss: 1.9999 - val_acc: 0.2267\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4915 - acc: 0.3814 - val_loss: 1.9921 - val_acc: 0.2267\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4893 - acc: 0.3957 - val_loss: 1.9930 - val_acc: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4913 - acc: 0.3871 - val_loss: 1.9930 - val_acc: 0.2300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4895 - acc: 0.3914 - val_loss: 2.0034 - val_acc: 0.2300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4897 - acc: 0.3871 - val_loss: 1.9911 - val_acc: 0.2267\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4886 - acc: 0.3857 - val_loss: 1.9982 - val_acc: 0.2433\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4885 - acc: 0.3900 - val_loss: 1.9861 - val_acc: 0.2267\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4889 - acc: 0.3871 - val_loss: 1.9907 - val_acc: 0.2300\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4883 - acc: 0.3886 - val_loss: 2.0012 - val_acc: 0.2300\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4886 - acc: 0.3829 - val_loss: 2.0032 - val_acc: 0.2300\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4881 - acc: 0.3814 - val_loss: 1.9936 - val_acc: 0.2267\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4871 - acc: 0.3929 - val_loss: 2.0193 - val_acc: 0.2333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4884 - acc: 0.3843 - val_loss: 2.0094 - val_acc: 0.2267\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4873 - acc: 0.3900 - val_loss: 2.0058 - val_acc: 0.2267\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4861 - acc: 0.3957 - val_loss: 2.0032 - val_acc: 0.2400\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4866 - acc: 0.3843 - val_loss: 2.0052 - val_acc: 0.2367\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4854 - acc: 0.3914 - val_loss: 1.9968 - val_acc: 0.2300\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4859 - acc: 0.3914 - val_loss: 2.0027 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4849 - acc: 0.3871 - val_loss: 2.0028 - val_acc: 0.2233\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4856 - acc: 0.3971 - val_loss: 2.0057 - val_acc: 0.2233\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4852 - acc: 0.3957 - val_loss: 2.0053 - val_acc: 0.2233\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4849 - acc: 0.3871 - val_loss: 1.9962 - val_acc: 0.2233\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4842 - acc: 0.3957 - val_loss: 2.0161 - val_acc: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.4841 - acc: 0.3900 - val_loss: 2.0118 - val_acc: 0.2300\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4824 - acc: 0.3986 - val_loss: 2.0161 - val_acc: 0.2333\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4837 - acc: 0.3971 - val_loss: 2.0120 - val_acc: 0.2400\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4830 - acc: 0.3986 - val_loss: 2.0129 - val_acc: 0.2400\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4828 - acc: 0.3957 - val_loss: 2.0089 - val_acc: 0.2267\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4824 - acc: 0.3871 - val_loss: 2.0052 - val_acc: 0.2433\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4830 - acc: 0.3929 - val_loss: 2.0084 - val_acc: 0.2467\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4824 - acc: 0.3914 - val_loss: 2.0093 - val_acc: 0.2467\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4821 - acc: 0.3857 - val_loss: 1.9992 - val_acc: 0.2300\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4828 - acc: 0.3900 - val_loss: 1.9990 - val_acc: 0.2333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4824 - acc: 0.3886 - val_loss: 2.0163 - val_acc: 0.2267\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4818 - acc: 0.3914 - val_loss: 1.9977 - val_acc: 0.2367\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4818 - acc: 0.3929 - val_loss: 2.0053 - val_acc: 0.2300\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4822 - acc: 0.3943 - val_loss: 2.0030 - val_acc: 0.2200\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4814 - acc: 0.3943 - val_loss: 2.0129 - val_acc: 0.2300\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0101 - val_acc: 0.2433\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4792 - acc: 0.3871 - val_loss: 2.0079 - val_acc: 0.2467\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4788 - acc: 0.3843 - val_loss: 2.0403 - val_acc: 0.2333\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4796 - acc: 0.3971 - val_loss: 2.0218 - val_acc: 0.2367\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4802 - acc: 0.3914 - val_loss: 2.0198 - val_acc: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4801 - acc: 0.3943 - val_loss: 2.0242 - val_acc: 0.2333\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4782 - acc: 0.3857 - val_loss: 2.0199 - val_acc: 0.2267\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4786 - acc: 0.3986 - val_loss: 2.0166 - val_acc: 0.2267\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4780 - acc: 0.3957 - val_loss: 2.0228 - val_acc: 0.2300\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4780 - acc: 0.3957 - val_loss: 2.0161 - val_acc: 0.2367\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4776 - acc: 0.3943 - val_loss: 2.0119 - val_acc: 0.2267\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4792 - acc: 0.3943 - val_loss: 2.0176 - val_acc: 0.2233\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4771 - acc: 0.3871 - val_loss: 2.0213 - val_acc: 0.2267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4765 - acc: 0.3900 - val_loss: 2.0355 - val_acc: 0.2333\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4767 - acc: 0.3900 - val_loss: 2.0289 - val_acc: 0.2267\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4766 - acc: 0.3929 - val_loss: 2.0121 - val_acc: 0.2233\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4765 - acc: 0.3943 - val_loss: 2.0113 - val_acc: 0.2467\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4756 - acc: 0.3929 - val_loss: 2.0181 - val_acc: 0.2433\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4753 - acc: 0.3929 - val_loss: 2.0250 - val_acc: 0.2267\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4759 - acc: 0.3929 - val_loss: 2.0246 - val_acc: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4767 - acc: 0.3829 - val_loss: 2.0246 - val_acc: 0.2233\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4732 - acc: 0.3943 - val_loss: 2.0334 - val_acc: 0.2533\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4766 - acc: 0.3957 - val_loss: 2.0244 - val_acc: 0.2233\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4750 - acc: 0.4014 - val_loss: 2.0206 - val_acc: 0.2300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4743 - acc: 0.3929 - val_loss: 2.0297 - val_acc: 0.2333\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4740 - acc: 0.4057 - val_loss: 2.0074 - val_acc: 0.2367\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4750 - acc: 0.3971 - val_loss: 2.0306 - val_acc: 0.2267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4748 - acc: 0.3957 - val_loss: 2.0279 - val_acc: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4738 - acc: 0.3986 - val_loss: 2.0199 - val_acc: 0.2300\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4724 - acc: 0.3943 - val_loss: 2.0224 - val_acc: 0.2433\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4738 - acc: 0.3943 - val_loss: 2.0247 - val_acc: 0.2300\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4729 - acc: 0.3914 - val_loss: 2.0231 - val_acc: 0.2300\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4721 - acc: 0.3943 - val_loss: 2.0283 - val_acc: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4708 - acc: 0.3857 - val_loss: 2.0277 - val_acc: 0.2300\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4714 - acc: 0.3986 - val_loss: 2.0400 - val_acc: 0.2333\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4715 - acc: 0.3871 - val_loss: 2.0263 - val_acc: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4719 - acc: 0.3986 - val_loss: 2.0282 - val_acc: 0.2433\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4710 - acc: 0.4000 - val_loss: 2.0201 - val_acc: 0.2267\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4718 - acc: 0.3943 - val_loss: 2.0212 - val_acc: 0.2333\n",
      "Epoch 535/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 120us/step - loss: 1.4703 - acc: 0.3957 - val_loss: 2.0442 - val_acc: 0.2367\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4699 - acc: 0.3971 - val_loss: 2.0427 - val_acc: 0.2267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4706 - acc: 0.3986 - val_loss: 2.0170 - val_acc: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4701 - acc: 0.3886 - val_loss: 2.0320 - val_acc: 0.2333\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4719 - acc: 0.3914 - val_loss: 2.0208 - val_acc: 0.2233\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4706 - acc: 0.3929 - val_loss: 2.0367 - val_acc: 0.2267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4697 - acc: 0.3971 - val_loss: 2.0338 - val_acc: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4696 - acc: 0.4029 - val_loss: 2.0384 - val_acc: 0.2367\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4701 - acc: 0.3957 - val_loss: 2.0305 - val_acc: 0.2333\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4686 - acc: 0.3929 - val_loss: 2.0184 - val_acc: 0.2367\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4697 - acc: 0.3971 - val_loss: 2.0247 - val_acc: 0.2333\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4667 - acc: 0.3957 - val_loss: 2.0416 - val_acc: 0.2367\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4687 - acc: 0.3971 - val_loss: 2.0475 - val_acc: 0.2333\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4674 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2267\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4676 - acc: 0.4014 - val_loss: 2.0208 - val_acc: 0.2267\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4670 - acc: 0.4000 - val_loss: 2.0330 - val_acc: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4677 - acc: 0.3914 - val_loss: 2.0340 - val_acc: 0.2233\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4662 - acc: 0.4057 - val_loss: 2.0297 - val_acc: 0.2300\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4687 - acc: 0.3929 - val_loss: 2.0347 - val_acc: 0.2300\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4658 - acc: 0.3986 - val_loss: 2.0421 - val_acc: 0.2333\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4670 - acc: 0.3929 - val_loss: 2.0402 - val_acc: 0.2333\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4651 - acc: 0.3957 - val_loss: 2.0343 - val_acc: 0.2433\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4646 - acc: 0.4071 - val_loss: 2.0519 - val_acc: 0.2567\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4664 - acc: 0.3986 - val_loss: 2.0341 - val_acc: 0.2333\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4645 - acc: 0.4043 - val_loss: 2.0339 - val_acc: 0.2533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4646 - acc: 0.4043 - val_loss: 2.0384 - val_acc: 0.2567\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4656 - acc: 0.3971 - val_loss: 2.0287 - val_acc: 0.2300\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4651 - acc: 0.3986 - val_loss: 2.0293 - val_acc: 0.2233\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4644 - acc: 0.3957 - val_loss: 2.0286 - val_acc: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4644 - acc: 0.4086 - val_loss: 2.0446 - val_acc: 0.2233\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4637 - acc: 0.3986 - val_loss: 2.0327 - val_acc: 0.2333\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4655 - acc: 0.4029 - val_loss: 2.0357 - val_acc: 0.2300\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4630 - acc: 0.4100 - val_loss: 2.0478 - val_acc: 0.2233\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4633 - acc: 0.4043 - val_loss: 2.0420 - val_acc: 0.2333\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4625 - acc: 0.4029 - val_loss: 2.0366 - val_acc: 0.2400\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4621 - acc: 0.4014 - val_loss: 2.0449 - val_acc: 0.2367\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4619 - acc: 0.3986 - val_loss: 2.0456 - val_acc: 0.2233\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4612 - acc: 0.3929 - val_loss: 2.0392 - val_acc: 0.2400\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4608 - acc: 0.4071 - val_loss: 2.0505 - val_acc: 0.2467\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4631 - acc: 0.4000 - val_loss: 2.0378 - val_acc: 0.2500\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4632 - acc: 0.4071 - val_loss: 2.0379 - val_acc: 0.2267\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4620 - acc: 0.3957 - val_loss: 2.0416 - val_acc: 0.2233\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4617 - acc: 0.3986 - val_loss: 2.0393 - val_acc: 0.2267\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0402 - val_acc: 0.2333\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4618 - acc: 0.4043 - val_loss: 2.0368 - val_acc: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4609 - acc: 0.4043 - val_loss: 2.0451 - val_acc: 0.2367\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4603 - acc: 0.3971 - val_loss: 2.0388 - val_acc: 0.2533\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4604 - acc: 0.4043 - val_loss: 2.0495 - val_acc: 0.2300\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4597 - acc: 0.3957 - val_loss: 2.0477 - val_acc: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4608 - acc: 0.4014 - val_loss: 2.0461 - val_acc: 0.2300\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4590 - acc: 0.4100 - val_loss: 2.0509 - val_acc: 0.2367\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4584 - acc: 0.3943 - val_loss: 2.0501 - val_acc: 0.2467\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4607 - acc: 0.4086 - val_loss: 2.0521 - val_acc: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4596 - acc: 0.4000 - val_loss: 2.0528 - val_acc: 0.2333\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4587 - acc: 0.4000 - val_loss: 2.0525 - val_acc: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4589 - acc: 0.3971 - val_loss: 2.0446 - val_acc: 0.2267\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0544 - val_acc: 0.2300\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4580 - acc: 0.4043 - val_loss: 2.0507 - val_acc: 0.2367\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0428 - val_acc: 0.2267\n",
      "Epoch 594/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 73us/step - loss: 1.4577 - acc: 0.4157 - val_loss: 2.0429 - val_acc: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4574 - acc: 0.4014 - val_loss: 2.0489 - val_acc: 0.2333\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4572 - acc: 0.4057 - val_loss: 2.0388 - val_acc: 0.2267\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4563 - acc: 0.4071 - val_loss: 2.0434 - val_acc: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4572 - acc: 0.3971 - val_loss: 2.0436 - val_acc: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4578 - acc: 0.3986 - val_loss: 2.0417 - val_acc: 0.2333\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4562 - acc: 0.4100 - val_loss: 2.0565 - val_acc: 0.2300\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4559 - acc: 0.4143 - val_loss: 2.0524 - val_acc: 0.2333\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4561 - acc: 0.3971 - val_loss: 2.0533 - val_acc: 0.2333\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4566 - acc: 0.4071 - val_loss: 2.0404 - val_acc: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4563 - acc: 0.4000 - val_loss: 2.0420 - val_acc: 0.2400\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4550 - acc: 0.4029 - val_loss: 2.0493 - val_acc: 0.2367\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4554 - acc: 0.4086 - val_loss: 2.0419 - val_acc: 0.2333\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4555 - acc: 0.4100 - val_loss: 2.0456 - val_acc: 0.2333\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4553 - acc: 0.4100 - val_loss: 2.0408 - val_acc: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4536 - acc: 0.4086 - val_loss: 2.0566 - val_acc: 0.2567\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4546 - acc: 0.4071 - val_loss: 2.0567 - val_acc: 0.2300\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4544 - acc: 0.4043 - val_loss: 2.0587 - val_acc: 0.2300\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4544 - acc: 0.3986 - val_loss: 2.0521 - val_acc: 0.2400\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4541 - acc: 0.4057 - val_loss: 2.0625 - val_acc: 0.2267\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4532 - acc: 0.4100 - val_loss: 2.0599 - val_acc: 0.2433\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4540 - acc: 0.4029 - val_loss: 2.0482 - val_acc: 0.2467\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4534 - acc: 0.4157 - val_loss: 2.0648 - val_acc: 0.2267\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4515 - acc: 0.4086 - val_loss: 2.0601 - val_acc: 0.2567\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4531 - acc: 0.4086 - val_loss: 2.0534 - val_acc: 0.2233\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4517 - acc: 0.4129 - val_loss: 2.0660 - val_acc: 0.2367\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4521 - acc: 0.4086 - val_loss: 2.0532 - val_acc: 0.2333\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4524 - acc: 0.4157 - val_loss: 2.0670 - val_acc: 0.2367\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0654 - val_acc: 0.2367\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4507 - acc: 0.4157 - val_loss: 2.0598 - val_acc: 0.2300\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4519 - acc: 0.4143 - val_loss: 2.0610 - val_acc: 0.2333\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4517 - acc: 0.4029 - val_loss: 2.0654 - val_acc: 0.2433\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4508 - acc: 0.4043 - val_loss: 2.0458 - val_acc: 0.2333\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4516 - acc: 0.4143 - val_loss: 2.0547 - val_acc: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4497 - acc: 0.4071 - val_loss: 2.0457 - val_acc: 0.2400\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4514 - acc: 0.3986 - val_loss: 2.0618 - val_acc: 0.2367\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4497 - acc: 0.4100 - val_loss: 2.0466 - val_acc: 0.2333\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4507 - acc: 0.4114 - val_loss: 2.0735 - val_acc: 0.2400\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4508 - acc: 0.4057 - val_loss: 2.0649 - val_acc: 0.2367\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4495 - acc: 0.4143 - val_loss: 2.0753 - val_acc: 0.2400\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4497 - acc: 0.4114 - val_loss: 2.0604 - val_acc: 0.2333\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4483 - acc: 0.3986 - val_loss: 2.0580 - val_acc: 0.2467\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4503 - acc: 0.4143 - val_loss: 2.0613 - val_acc: 0.2333\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4491 - acc: 0.4057 - val_loss: 2.0698 - val_acc: 0.2400\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4492 - acc: 0.4143 - val_loss: 2.0734 - val_acc: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4488 - acc: 0.4086 - val_loss: 2.0727 - val_acc: 0.2300\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4479 - acc: 0.4100 - val_loss: 2.0520 - val_acc: 0.2333\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4477 - acc: 0.4100 - val_loss: 2.0664 - val_acc: 0.2400\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4490 - acc: 0.4086 - val_loss: 2.0746 - val_acc: 0.2400\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4479 - acc: 0.4071 - val_loss: 2.0770 - val_acc: 0.2333\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4479 - acc: 0.4086 - val_loss: 2.0664 - val_acc: 0.2400\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4471 - acc: 0.4114 - val_loss: 2.0746 - val_acc: 0.2367\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4452 - acc: 0.4071 - val_loss: 2.0640 - val_acc: 0.2600\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4465 - acc: 0.4157 - val_loss: 2.0642 - val_acc: 0.2333\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4471 - acc: 0.4086 - val_loss: 2.0787 - val_acc: 0.2367\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4454 - acc: 0.3986 - val_loss: 2.0794 - val_acc: 0.2367\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4472 - acc: 0.4114 - val_loss: 2.0655 - val_acc: 0.2367\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4460 - acc: 0.4100 - val_loss: 2.0852 - val_acc: 0.2433\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4469 - acc: 0.4114 - val_loss: 2.0712 - val_acc: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4454 - acc: 0.4143 - val_loss: 2.0698 - val_acc: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4456 - acc: 0.4100 - val_loss: 2.0589 - val_acc: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4445 - acc: 0.4114 - val_loss: 2.0690 - val_acc: 0.2467\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4466 - acc: 0.4086 - val_loss: 2.0818 - val_acc: 0.2400\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4450 - acc: 0.4086 - val_loss: 2.0713 - val_acc: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0702 - val_acc: 0.2400\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4444 - acc: 0.4129 - val_loss: 2.0714 - val_acc: 0.2433\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4451 - acc: 0.4057 - val_loss: 2.0705 - val_acc: 0.2333\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4459 - acc: 0.4086 - val_loss: 2.0681 - val_acc: 0.2300\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4452 - acc: 0.4043 - val_loss: 2.0722 - val_acc: 0.2300\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4444 - acc: 0.4114 - val_loss: 2.0858 - val_acc: 0.2367\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4433 - acc: 0.4129 - val_loss: 2.0738 - val_acc: 0.2400\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0801 - val_acc: 0.2367\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4430 - acc: 0.4129 - val_loss: 2.0722 - val_acc: 0.2467\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4447 - acc: 0.4114 - val_loss: 2.0670 - val_acc: 0.2333\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4414 - acc: 0.4100 - val_loss: 2.0835 - val_acc: 0.2600\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4422 - acc: 0.4171 - val_loss: 2.0861 - val_acc: 0.2367\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4436 - acc: 0.4143 - val_loss: 2.0745 - val_acc: 0.2333\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4418 - acc: 0.4129 - val_loss: 2.0754 - val_acc: 0.2467\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4426 - acc: 0.4057 - val_loss: 2.0779 - val_acc: 0.2333\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4426 - acc: 0.4143 - val_loss: 2.0735 - val_acc: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4417 - acc: 0.4043 - val_loss: 2.0964 - val_acc: 0.2400\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4409 - acc: 0.4186 - val_loss: 2.0937 - val_acc: 0.2567\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4408 - acc: 0.4100 - val_loss: 2.0671 - val_acc: 0.2567\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4401 - acc: 0.4114 - val_loss: 2.0908 - val_acc: 0.2367\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4396 - acc: 0.4157 - val_loss: 2.0683 - val_acc: 0.2300\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4411 - acc: 0.4143 - val_loss: 2.0826 - val_acc: 0.2400\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4420 - acc: 0.4157 - val_loss: 2.0815 - val_acc: 0.2367\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4416 - acc: 0.4129 - val_loss: 2.0774 - val_acc: 0.2300\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4403 - acc: 0.4143 - val_loss: 2.0782 - val_acc: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4404 - acc: 0.4057 - val_loss: 2.0677 - val_acc: 0.2500\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4368 - acc: 0.4129 - val_loss: 2.0817 - val_acc: 0.2567\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4399 - acc: 0.4100 - val_loss: 2.0774 - val_acc: 0.2500\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4395 - acc: 0.4143 - val_loss: 2.0973 - val_acc: 0.2500\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4393 - acc: 0.4143 - val_loss: 2.0713 - val_acc: 0.2367\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4400 - acc: 0.4143 - val_loss: 2.0790 - val_acc: 0.2333\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4391 - acc: 0.4129 - val_loss: 2.0835 - val_acc: 0.2433\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4389 - acc: 0.4186 - val_loss: 2.0882 - val_acc: 0.2333\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4379 - acc: 0.4200 - val_loss: 2.0890 - val_acc: 0.2367\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4383 - acc: 0.4157 - val_loss: 2.0806 - val_acc: 0.2333\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4391 - acc: 0.4100 - val_loss: 2.0779 - val_acc: 0.2367\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.1026 - val_acc: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4393 - acc: 0.4143 - val_loss: 2.0796 - val_acc: 0.2533\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4365 - acc: 0.4157 - val_loss: 2.0921 - val_acc: 0.2400\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4378 - acc: 0.4100 - val_loss: 2.0976 - val_acc: 0.2533\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4377 - acc: 0.4143 - val_loss: 2.0890 - val_acc: 0.2467\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4373 - acc: 0.4186 - val_loss: 2.0889 - val_acc: 0.2300\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4369 - acc: 0.4129 - val_loss: 2.0870 - val_acc: 0.2500\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4360 - acc: 0.4171 - val_loss: 2.0823 - val_acc: 0.2500\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4368 - acc: 0.4129 - val_loss: 2.0838 - val_acc: 0.2400\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4358 - acc: 0.4214 - val_loss: 2.1042 - val_acc: 0.2367\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4368 - acc: 0.4157 - val_loss: 2.0839 - val_acc: 0.2467\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4365 - acc: 0.4086 - val_loss: 2.0790 - val_acc: 0.2367\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4363 - acc: 0.4200 - val_loss: 2.0696 - val_acc: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4358 - acc: 0.4200 - val_loss: 2.0846 - val_acc: 0.2400\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4359 - acc: 0.4171 - val_loss: 2.0834 - val_acc: 0.2367\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4337 - acc: 0.4243 - val_loss: 2.1038 - val_acc: 0.2567\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4358 - acc: 0.4186 - val_loss: 2.0860 - val_acc: 0.2433\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4347 - acc: 0.4114 - val_loss: 2.0861 - val_acc: 0.2400\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4344 - acc: 0.4143 - val_loss: 2.0922 - val_acc: 0.2567\n",
      "Epoch 713/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 92us/step - loss: 1.4354 - acc: 0.4129 - val_loss: 2.0766 - val_acc: 0.2367\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0908 - val_acc: 0.2400\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0834 - val_acc: 0.2533\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4350 - acc: 0.4100 - val_loss: 2.0870 - val_acc: 0.2400\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4342 - acc: 0.4157 - val_loss: 2.0920 - val_acc: 0.2333\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4334 - acc: 0.4171 - val_loss: 2.1102 - val_acc: 0.2600\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4345 - acc: 0.4171 - val_loss: 2.1028 - val_acc: 0.2333\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4339 - acc: 0.4157 - val_loss: 2.0940 - val_acc: 0.2433\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4336 - acc: 0.4157 - val_loss: 2.0919 - val_acc: 0.2433\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4327 - acc: 0.4200 - val_loss: 2.1024 - val_acc: 0.2400\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4328 - acc: 0.4200 - val_loss: 2.0852 - val_acc: 0.2367\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4327 - acc: 0.4214 - val_loss: 2.0969 - val_acc: 0.2333\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4319 - acc: 0.4157 - val_loss: 2.1063 - val_acc: 0.2433\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4320 - acc: 0.4171 - val_loss: 2.0867 - val_acc: 0.2333\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4315 - acc: 0.4229 - val_loss: 2.1179 - val_acc: 0.2400\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4318 - acc: 0.4186 - val_loss: 2.0864 - val_acc: 0.2333\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4312 - acc: 0.4243 - val_loss: 2.1087 - val_acc: 0.2533\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4311 - acc: 0.4243 - val_loss: 2.1150 - val_acc: 0.2367\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4317 - acc: 0.4143 - val_loss: 2.0999 - val_acc: 0.2367\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4297 - acc: 0.4243 - val_loss: 2.1039 - val_acc: 0.2333\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4304 - acc: 0.4257 - val_loss: 2.1029 - val_acc: 0.2400\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4313 - acc: 0.4143 - val_loss: 2.1062 - val_acc: 0.2367\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4302 - acc: 0.4200 - val_loss: 2.0997 - val_acc: 0.2367\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4289 - acc: 0.4243 - val_loss: 2.0929 - val_acc: 0.2367\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4305 - acc: 0.4229 - val_loss: 2.1091 - val_acc: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4305 - acc: 0.4200 - val_loss: 2.1005 - val_acc: 0.2433\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4290 - acc: 0.4214 - val_loss: 2.1062 - val_acc: 0.2400\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4294 - acc: 0.4257 - val_loss: 2.1001 - val_acc: 0.2433\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4287 - acc: 0.4214 - val_loss: 2.1103 - val_acc: 0.2533\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4290 - acc: 0.4143 - val_loss: 2.0996 - val_acc: 0.2500\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4276 - acc: 0.4271 - val_loss: 2.0947 - val_acc: 0.2567\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4296 - acc: 0.4214 - val_loss: 2.0950 - val_acc: 0.2400\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4261 - acc: 0.4329 - val_loss: 2.1084 - val_acc: 0.2600\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4292 - acc: 0.4257 - val_loss: 2.0999 - val_acc: 0.2367\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4290 - acc: 0.4171 - val_loss: 2.1090 - val_acc: 0.2400\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4270 - acc: 0.4186 - val_loss: 2.1161 - val_acc: 0.2567\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4259 - acc: 0.4243 - val_loss: 2.0891 - val_acc: 0.2367\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4279 - acc: 0.4300 - val_loss: 2.0941 - val_acc: 0.2367\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4264 - acc: 0.4200 - val_loss: 2.1049 - val_acc: 0.2367\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4271 - acc: 0.4271 - val_loss: 2.1056 - val_acc: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4259 - acc: 0.4214 - val_loss: 2.1270 - val_acc: 0.2433\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4274 - acc: 0.4229 - val_loss: 2.1114 - val_acc: 0.2367\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4260 - acc: 0.4300 - val_loss: 2.1064 - val_acc: 0.2500\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4260 - acc: 0.4129 - val_loss: 2.1067 - val_acc: 0.2400\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4273 - acc: 0.4143 - val_loss: 2.1124 - val_acc: 0.2467\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4258 - acc: 0.4229 - val_loss: 2.1074 - val_acc: 0.2467\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4260 - acc: 0.4271 - val_loss: 2.1038 - val_acc: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4255 - acc: 0.4314 - val_loss: 2.1043 - val_acc: 0.2400\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4256 - acc: 0.4186 - val_loss: 2.1250 - val_acc: 0.2467\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4264 - acc: 0.4257 - val_loss: 2.1161 - val_acc: 0.2433\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4255 - acc: 0.4243 - val_loss: 2.1041 - val_acc: 0.2367\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4262 - acc: 0.4229 - val_loss: 2.1204 - val_acc: 0.2467\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4240 - acc: 0.4157 - val_loss: 2.1297 - val_acc: 0.2367\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4256 - acc: 0.4186 - val_loss: 2.1060 - val_acc: 0.2433\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4254 - acc: 0.4243 - val_loss: 2.1053 - val_acc: 0.2433\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4243 - acc: 0.4300 - val_loss: 2.1004 - val_acc: 0.2400\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4244 - acc: 0.4229 - val_loss: 2.1077 - val_acc: 0.2367\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4239 - acc: 0.4229 - val_loss: 2.0997 - val_acc: 0.2367\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4233 - acc: 0.4171 - val_loss: 2.1190 - val_acc: 0.2400\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4239 - acc: 0.4200 - val_loss: 2.1169 - val_acc: 0.2367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4239 - acc: 0.4171 - val_loss: 2.1254 - val_acc: 0.2467\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4228 - acc: 0.4186 - val_loss: 2.1182 - val_acc: 0.2433\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4218 - acc: 0.4300 - val_loss: 2.1197 - val_acc: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4230 - acc: 0.4229 - val_loss: 2.1180 - val_acc: 0.2433\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4217 - acc: 0.4243 - val_loss: 2.1273 - val_acc: 0.2400\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4230 - acc: 0.4200 - val_loss: 2.1154 - val_acc: 0.2367\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4230 - acc: 0.4286 - val_loss: 2.1153 - val_acc: 0.2400\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4227 - acc: 0.4200 - val_loss: 2.1082 - val_acc: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4234 - acc: 0.4186 - val_loss: 2.1124 - val_acc: 0.2467\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4221 - acc: 0.4200 - val_loss: 2.0982 - val_acc: 0.2367\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4225 - acc: 0.4271 - val_loss: 2.1162 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4220 - acc: 0.4271 - val_loss: 2.1186 - val_acc: 0.2433\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4218 - acc: 0.4257 - val_loss: 2.1296 - val_acc: 0.2400\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1182 - val_acc: 0.2500\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4225 - acc: 0.4200 - val_loss: 2.1075 - val_acc: 0.2433\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4215 - acc: 0.4271 - val_loss: 2.1161 - val_acc: 0.2400\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4211 - acc: 0.4243 - val_loss: 2.1127 - val_acc: 0.2433\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4214 - acc: 0.4271 - val_loss: 2.1207 - val_acc: 0.2467\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4201 - acc: 0.4214 - val_loss: 2.1185 - val_acc: 0.2500\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4208 - acc: 0.4200 - val_loss: 2.1078 - val_acc: 0.2400\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4202 - acc: 0.4286 - val_loss: 2.1254 - val_acc: 0.2500\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4207 - acc: 0.4214 - val_loss: 2.1222 - val_acc: 0.2400\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4204 - acc: 0.4286 - val_loss: 2.1176 - val_acc: 0.2367\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4198 - acc: 0.4214 - val_loss: 2.1165 - val_acc: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4201 - acc: 0.4214 - val_loss: 2.1262 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4197 - acc: 0.4329 - val_loss: 2.1253 - val_acc: 0.2400\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4189 - acc: 0.4300 - val_loss: 2.1168 - val_acc: 0.2533\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4197 - acc: 0.4200 - val_loss: 2.1266 - val_acc: 0.2400\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4198 - acc: 0.4229 - val_loss: 2.1243 - val_acc: 0.2367\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4198 - acc: 0.4286 - val_loss: 2.1559 - val_acc: 0.2433\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4182 - acc: 0.4314 - val_loss: 2.1188 - val_acc: 0.2500\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4185 - acc: 0.4257 - val_loss: 2.1197 - val_acc: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4179 - acc: 0.4286 - val_loss: 2.1142 - val_acc: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4188 - acc: 0.4271 - val_loss: 2.1190 - val_acc: 0.2433\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4187 - acc: 0.4314 - val_loss: 2.1221 - val_acc: 0.2400\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4180 - acc: 0.4214 - val_loss: 2.1233 - val_acc: 0.2467\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4189 - acc: 0.4200 - val_loss: 2.1305 - val_acc: 0.2467\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4176 - acc: 0.4286 - val_loss: 2.1296 - val_acc: 0.2433\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4178 - acc: 0.4257 - val_loss: 2.1169 - val_acc: 0.2433\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4178 - acc: 0.4314 - val_loss: 2.1316 - val_acc: 0.2367\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4165 - acc: 0.4257 - val_loss: 2.1303 - val_acc: 0.2600\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4177 - acc: 0.4271 - val_loss: 2.1269 - val_acc: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4170 - acc: 0.4343 - val_loss: 2.1192 - val_acc: 0.2433\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4154 - acc: 0.4229 - val_loss: 2.1248 - val_acc: 0.2400\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4161 - acc: 0.4271 - val_loss: 2.1348 - val_acc: 0.2400\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4146 - acc: 0.4357 - val_loss: 2.1406 - val_acc: 0.2633\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4168 - acc: 0.4300 - val_loss: 2.1318 - val_acc: 0.2600\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4169 - acc: 0.4200 - val_loss: 2.1425 - val_acc: 0.2433\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4167 - acc: 0.4271 - val_loss: 2.1282 - val_acc: 0.2467\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4153 - acc: 0.4243 - val_loss: 2.1339 - val_acc: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4146 - acc: 0.4257 - val_loss: 2.1324 - val_acc: 0.2467\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4150 - acc: 0.4329 - val_loss: 2.1435 - val_acc: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4160 - acc: 0.4229 - val_loss: 2.1382 - val_acc: 0.2467\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4147 - acc: 0.4314 - val_loss: 2.1403 - val_acc: 0.2400\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4154 - acc: 0.4343 - val_loss: 2.1277 - val_acc: 0.2400\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4146 - acc: 0.4257 - val_loss: 2.1329 - val_acc: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1352 - val_acc: 0.2433\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4141 - acc: 0.4386 - val_loss: 2.1466 - val_acc: 0.2467\n",
      "Epoch 832/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.4149 - acc: 0.4329 - val_loss: 2.1497 - val_acc: 0.2400\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4147 - acc: 0.4257 - val_loss: 2.1534 - val_acc: 0.2333\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4145 - acc: 0.4286 - val_loss: 2.1620 - val_acc: 0.2400\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4133 - acc: 0.4257 - val_loss: 2.1331 - val_acc: 0.2400\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4134 - acc: 0.4329 - val_loss: 2.1387 - val_acc: 0.2467\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4140 - acc: 0.4243 - val_loss: 2.1291 - val_acc: 0.2367\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4143 - acc: 0.4271 - val_loss: 2.1374 - val_acc: 0.2467\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4124 - acc: 0.4314 - val_loss: 2.1354 - val_acc: 0.2367\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4118 - acc: 0.4343 - val_loss: 2.1261 - val_acc: 0.2467\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4129 - acc: 0.4314 - val_loss: 2.1363 - val_acc: 0.2433\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4136 - acc: 0.4329 - val_loss: 2.1530 - val_acc: 0.2467\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1348 - val_acc: 0.2400\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4119 - acc: 0.4286 - val_loss: 2.1498 - val_acc: 0.2433\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4122 - acc: 0.4271 - val_loss: 2.1321 - val_acc: 0.2467\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4128 - acc: 0.4300 - val_loss: 2.1375 - val_acc: 0.2433\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4112 - acc: 0.4243 - val_loss: 2.1431 - val_acc: 0.2433\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4116 - acc: 0.4286 - val_loss: 2.1433 - val_acc: 0.2600\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4121 - acc: 0.4300 - val_loss: 2.1435 - val_acc: 0.2467\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4108 - acc: 0.4271 - val_loss: 2.1334 - val_acc: 0.2467\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4106 - acc: 0.4186 - val_loss: 2.1350 - val_acc: 0.2367\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4125 - acc: 0.4271 - val_loss: 2.1381 - val_acc: 0.2400\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1395 - val_acc: 0.2400\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4084 - acc: 0.4357 - val_loss: 2.1601 - val_acc: 0.2633\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4109 - acc: 0.4286 - val_loss: 2.1365 - val_acc: 0.2433\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4113 - acc: 0.4314 - val_loss: 2.1541 - val_acc: 0.2467\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4107 - acc: 0.4286 - val_loss: 2.1488 - val_acc: 0.2500\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4105 - acc: 0.4271 - val_loss: 2.1433 - val_acc: 0.2400\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4088 - acc: 0.4343 - val_loss: 2.1438 - val_acc: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4096 - acc: 0.4300 - val_loss: 2.1612 - val_acc: 0.2467\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4100 - acc: 0.4329 - val_loss: 2.1468 - val_acc: 0.2533\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4107 - acc: 0.4229 - val_loss: 2.1571 - val_acc: 0.2467\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4092 - acc: 0.4329 - val_loss: 2.1566 - val_acc: 0.2533\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4093 - acc: 0.4300 - val_loss: 2.1460 - val_acc: 0.2533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4082 - acc: 0.4329 - val_loss: 2.1560 - val_acc: 0.2667\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4087 - acc: 0.4314 - val_loss: 2.1247 - val_acc: 0.2467\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4089 - acc: 0.4314 - val_loss: 2.1550 - val_acc: 0.2400\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4093 - acc: 0.4300 - val_loss: 2.1489 - val_acc: 0.2467\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4088 - acc: 0.4329 - val_loss: 2.1467 - val_acc: 0.2433\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4070 - acc: 0.4343 - val_loss: 2.1598 - val_acc: 0.2467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4085 - acc: 0.4300 - val_loss: 2.1643 - val_acc: 0.2433\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4075 - acc: 0.4357 - val_loss: 2.1465 - val_acc: 0.2633\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4080 - acc: 0.4300 - val_loss: 2.1296 - val_acc: 0.2367\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4086 - acc: 0.4286 - val_loss: 2.1407 - val_acc: 0.2433\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4076 - acc: 0.4343 - val_loss: 2.1613 - val_acc: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4075 - acc: 0.4300 - val_loss: 2.1379 - val_acc: 0.2500\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4069 - acc: 0.4300 - val_loss: 2.1702 - val_acc: 0.2433\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4081 - acc: 0.4257 - val_loss: 2.1562 - val_acc: 0.2433\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4048 - acc: 0.4371 - val_loss: 2.1560 - val_acc: 0.2333\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4089 - acc: 0.4286 - val_loss: 2.1440 - val_acc: 0.2367\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4068 - acc: 0.4314 - val_loss: 2.1739 - val_acc: 0.2467\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4073 - acc: 0.4371 - val_loss: 2.1584 - val_acc: 0.2533\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4079 - acc: 0.4214 - val_loss: 2.1381 - val_acc: 0.2433\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.4065 - acc: 0.4329 - val_loss: 2.1680 - val_acc: 0.2633\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4068 - acc: 0.4257 - val_loss: 2.1322 - val_acc: 0.2433\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4073 - acc: 0.4357 - val_loss: 2.1534 - val_acc: 0.2533\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4063 - acc: 0.4329 - val_loss: 2.1507 - val_acc: 0.2500\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4064 - acc: 0.4329 - val_loss: 2.1546 - val_acc: 0.2467\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4047 - acc: 0.4386 - val_loss: 2.1678 - val_acc: 0.2600\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4065 - acc: 0.4357 - val_loss: 2.1520 - val_acc: 0.2600\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4062 - acc: 0.4271 - val_loss: 2.1569 - val_acc: 0.2533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4063 - acc: 0.4400 - val_loss: 2.1618 - val_acc: 0.2533\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4057 - acc: 0.4300 - val_loss: 2.1671 - val_acc: 0.2533\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4059 - acc: 0.4386 - val_loss: 2.1537 - val_acc: 0.2433\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4051 - acc: 0.4257 - val_loss: 2.1611 - val_acc: 0.2533\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4050 - acc: 0.4329 - val_loss: 2.1667 - val_acc: 0.2667\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4054 - acc: 0.4300 - val_loss: 2.1659 - val_acc: 0.2600\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4050 - acc: 0.4371 - val_loss: 2.1707 - val_acc: 0.2533\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4052 - acc: 0.4271 - val_loss: 2.1500 - val_acc: 0.2500\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4039 - acc: 0.4457 - val_loss: 2.1547 - val_acc: 0.2533\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4036 - acc: 0.4343 - val_loss: 2.1692 - val_acc: 0.2667\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4040 - acc: 0.4329 - val_loss: 2.1594 - val_acc: 0.2533\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4030 - acc: 0.4343 - val_loss: 2.1741 - val_acc: 0.2600\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4027 - acc: 0.4329 - val_loss: 2.1524 - val_acc: 0.2467\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4047 - acc: 0.4386 - val_loss: 2.1494 - val_acc: 0.2433\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4037 - acc: 0.4329 - val_loss: 2.1461 - val_acc: 0.2467\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4040 - acc: 0.4343 - val_loss: 2.1653 - val_acc: 0.2533\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4035 - acc: 0.4300 - val_loss: 2.1588 - val_acc: 0.2467\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4032 - acc: 0.4329 - val_loss: 2.1674 - val_acc: 0.2533\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4039 - acc: 0.4329 - val_loss: 2.1493 - val_acc: 0.2467\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4027 - acc: 0.4357 - val_loss: 2.1684 - val_acc: 0.2433\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4033 - acc: 0.4357 - val_loss: 2.1563 - val_acc: 0.2433\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4039 - acc: 0.4400 - val_loss: 2.1746 - val_acc: 0.2500\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4023 - acc: 0.4357 - val_loss: 2.1762 - val_acc: 0.2633\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4028 - acc: 0.4343 - val_loss: 2.1636 - val_acc: 0.2533\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4026 - acc: 0.4357 - val_loss: 2.1716 - val_acc: 0.2433\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4017 - acc: 0.4457 - val_loss: 2.1688 - val_acc: 0.2433\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4008 - acc: 0.4329 - val_loss: 2.1667 - val_acc: 0.2600\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4022 - acc: 0.4314 - val_loss: 2.1748 - val_acc: 0.2467\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4026 - acc: 0.4300 - val_loss: 2.1583 - val_acc: 0.2500\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4021 - acc: 0.4314 - val_loss: 2.1603 - val_acc: 0.2433\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4004 - acc: 0.4371 - val_loss: 2.1720 - val_acc: 0.2533\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4003 - acc: 0.4386 - val_loss: 2.1588 - val_acc: 0.2633\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4027 - acc: 0.4429 - val_loss: 2.1678 - val_acc: 0.2533\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4007 - acc: 0.4329 - val_loss: 2.1708 - val_acc: 0.2433\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4009 - acc: 0.4414 - val_loss: 2.1639 - val_acc: 0.2533\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4014 - acc: 0.4271 - val_loss: 2.1687 - val_acc: 0.2467\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4009 - acc: 0.4400 - val_loss: 2.1866 - val_acc: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4008 - acc: 0.4357 - val_loss: 2.1807 - val_acc: 0.2467\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4010 - acc: 0.4343 - val_loss: 2.1734 - val_acc: 0.2533\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4005 - acc: 0.4357 - val_loss: 2.1657 - val_acc: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4000 - acc: 0.4429 - val_loss: 2.1568 - val_acc: 0.2500\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4005 - acc: 0.4300 - val_loss: 2.1691 - val_acc: 0.2500\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3996 - acc: 0.4386 - val_loss: 2.1744 - val_acc: 0.2533\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4005 - acc: 0.4371 - val_loss: 2.1728 - val_acc: 0.2500\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4003 - acc: 0.4400 - val_loss: 2.1779 - val_acc: 0.2533\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3998 - acc: 0.4314 - val_loss: 2.1739 - val_acc: 0.2433\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3992 - acc: 0.4400 - val_loss: 2.1765 - val_acc: 0.2533\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3990 - acc: 0.4357 - val_loss: 2.1881 - val_acc: 0.2567\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3998 - acc: 0.4343 - val_loss: 2.1663 - val_acc: 0.2433\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3993 - acc: 0.4314 - val_loss: 2.1706 - val_acc: 0.2467\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3985 - acc: 0.4371 - val_loss: 2.1556 - val_acc: 0.2367\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3992 - acc: 0.4386 - val_loss: 2.1806 - val_acc: 0.2467\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3980 - acc: 0.4386 - val_loss: 2.1827 - val_acc: 0.2533\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3984 - acc: 0.4314 - val_loss: 2.1829 - val_acc: 0.2533\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3984 - acc: 0.4314 - val_loss: 2.1725 - val_acc: 0.2567\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3974 - acc: 0.4371 - val_loss: 2.1940 - val_acc: 0.2600\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3979 - acc: 0.4271 - val_loss: 2.1637 - val_acc: 0.2400\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3981 - acc: 0.4400 - val_loss: 2.1660 - val_acc: 0.2433\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3966 - acc: 0.4386 - val_loss: 2.1731 - val_acc: 0.2467\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3977 - acc: 0.4343 - val_loss: 2.1786 - val_acc: 0.2567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3976 - acc: 0.4386 - val_loss: 2.1805 - val_acc: 0.2467\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3976 - acc: 0.4357 - val_loss: 2.1796 - val_acc: 0.2600\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3976 - acc: 0.4414 - val_loss: 2.1744 - val_acc: 0.2567\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3974 - acc: 0.4400 - val_loss: 2.1879 - val_acc: 0.2500\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3970 - acc: 0.4414 - val_loss: 2.1923 - val_acc: 0.2433\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3964 - acc: 0.4371 - val_loss: 2.1810 - val_acc: 0.2467\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3977 - acc: 0.4329 - val_loss: 2.2068 - val_acc: 0.2433\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3974 - acc: 0.4343 - val_loss: 2.1689 - val_acc: 0.2433\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3966 - acc: 0.4314 - val_loss: 2.1847 - val_acc: 0.2467\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3962 - acc: 0.4414 - val_loss: 2.1560 - val_acc: 0.2433\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3970 - acc: 0.4343 - val_loss: 2.1800 - val_acc: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3963 - acc: 0.4357 - val_loss: 2.1845 - val_acc: 0.2533\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3958 - acc: 0.4400 - val_loss: 2.1675 - val_acc: 0.2433\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3950 - acc: 0.4429 - val_loss: 2.1737 - val_acc: 0.2467\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3963 - acc: 0.4414 - val_loss: 2.1962 - val_acc: 0.2500\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3963 - acc: 0.4357 - val_loss: 2.1870 - val_acc: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3953 - acc: 0.4357 - val_loss: 2.1756 - val_acc: 0.2400\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3955 - acc: 0.4471 - val_loss: 2.1807 - val_acc: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3953 - acc: 0.4357 - val_loss: 2.1991 - val_acc: 0.2433\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3955 - acc: 0.4414 - val_loss: 2.1873 - val_acc: 0.2467\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3952 - acc: 0.4371 - val_loss: 2.1876 - val_acc: 0.2467\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3941 - acc: 0.4371 - val_loss: 2.1853 - val_acc: 0.2533\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3948 - acc: 0.4329 - val_loss: 2.1879 - val_acc: 0.2500\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3947 - acc: 0.4414 - val_loss: 2.1965 - val_acc: 0.2533\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3941 - acc: 0.4400 - val_loss: 2.1804 - val_acc: 0.2467\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3943 - acc: 0.4386 - val_loss: 2.1763 - val_acc: 0.2367\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3937 - acc: 0.4486 - val_loss: 2.1874 - val_acc: 0.2500\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3944 - acc: 0.4357 - val_loss: 2.1869 - val_acc: 0.2433\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3945 - acc: 0.4400 - val_loss: 2.1994 - val_acc: 0.2533\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3933 - acc: 0.4343 - val_loss: 2.2087 - val_acc: 0.2500\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3940 - acc: 0.4386 - val_loss: 2.1905 - val_acc: 0.2533\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3937 - acc: 0.4343 - val_loss: 2.1962 - val_acc: 0.2500\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3937 - acc: 0.4371 - val_loss: 2.1868 - val_acc: 0.2533\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3930 - acc: 0.4371 - val_loss: 2.1978 - val_acc: 0.2433\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3931 - acc: 0.4414 - val_loss: 2.1925 - val_acc: 0.2567\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3925 - acc: 0.4371 - val_loss: 2.1835 - val_acc: 0.2400\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3925 - acc: 0.4443 - val_loss: 2.2108 - val_acc: 0.2633\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3942 - acc: 0.4371 - val_loss: 2.2074 - val_acc: 0.2500\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3926 - acc: 0.4429 - val_loss: 2.2209 - val_acc: 0.2467\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3929 - acc: 0.4457 - val_loss: 2.1873 - val_acc: 0.2467\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3926 - acc: 0.4386 - val_loss: 2.2005 - val_acc: 0.2467\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3926 - acc: 0.4486 - val_loss: 2.1931 - val_acc: 0.2433\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3922 - acc: 0.4357 - val_loss: 2.1761 - val_acc: 0.2333\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3931 - acc: 0.4371 - val_loss: 2.1908 - val_acc: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3915 - acc: 0.4429 - val_loss: 2.1999 - val_acc: 0.2433\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3917 - acc: 0.4443 - val_loss: 2.1966 - val_acc: 0.2467\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3924 - acc: 0.4414 - val_loss: 2.2098 - val_acc: 0.2500\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3920 - acc: 0.4386 - val_loss: 2.1896 - val_acc: 0.2467\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3919 - acc: 0.4400 - val_loss: 2.2065 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "## 2.) Make ModeL!\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch') #x축 이름 정하기\n",
    "    loss_ax.set_ylabel('loss') #y축 이름 정하기\n",
    "    acc_ax.set_ylabel('accuracy') \n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2575961351394653,\n",
       " 2.2072013003485544,\n",
       " 2.1729851228850228,\n",
       " 2.1441288931029185,\n",
       " 2.117690556389945,\n",
       " 2.094027440888541,\n",
       " 2.0720738427979604,\n",
       " 2.0520268031529016,\n",
       " 2.0341565438679288,\n",
       " 2.0189663648605345,\n",
       " 2.0040798102106367,\n",
       " 1.991146458898272,\n",
       " 1.9788600019046239,\n",
       " 1.9684650540351867,\n",
       " 1.9581576449530465,\n",
       " 1.948373077596937,\n",
       " 1.939316305092403,\n",
       " 1.9308262535503933,\n",
       " 1.9231540288243976,\n",
       " 1.9155606610434397,\n",
       " 1.9085986954825265,\n",
       " 1.9011238251413618,\n",
       " 1.8953436153275627,\n",
       " 1.889441226209913,\n",
       " 1.8829641921179636,\n",
       " 1.8768834131104606,\n",
       " 1.8714358704430716,\n",
       " 1.8661296793392725,\n",
       " 1.8614633202552795,\n",
       " 1.8564352461269924,\n",
       " 1.8513204046658107,\n",
       " 1.846307294709342,\n",
       " 1.842308417388371,\n",
       " 1.8382214665412904,\n",
       " 1.8334996938705443,\n",
       " 1.8298744678497314,\n",
       " 1.825686992917742,\n",
       " 1.8220052548817225,\n",
       " 1.8184059739112854,\n",
       " 1.8143443090575082,\n",
       " 1.8104264037949698,\n",
       " 1.8075042877878462,\n",
       " 1.804540731225695,\n",
       " 1.8001060536929538,\n",
       " 1.7969402176993234,\n",
       " 1.7938224060194834,\n",
       " 1.7913046428135464,\n",
       " 1.788569096156529,\n",
       " 1.7857855337006705,\n",
       " 1.7818859474999564,\n",
       " 1.77939590045384,\n",
       " 1.7761464289256506,\n",
       " 1.7744111350604466,\n",
       " 1.7714833463941302,\n",
       " 1.7686558655330114,\n",
       " 1.76720849275589,\n",
       " 1.7640065039907182,\n",
       " 1.7615219133240836,\n",
       " 1.7589723195348468,\n",
       " 1.755156569821494,\n",
       " 1.7566945569855825,\n",
       " 1.753110728945051,\n",
       " 1.7504866668156216,\n",
       " 1.7484394260815213,\n",
       " 1.7458006790706089,\n",
       " 1.7439589841025216,\n",
       " 1.742053977080754,\n",
       " 1.7405523998396737,\n",
       " 1.7377520271709987,\n",
       " 1.7357641867228917,\n",
       " 1.7346941981996808,\n",
       " 1.732908638886043,\n",
       " 1.7300414204597474,\n",
       " 1.7285445247377669,\n",
       " 1.7270315630095345,\n",
       " 1.7256990960666112,\n",
       " 1.7229743787220546,\n",
       " 1.7214373895100186,\n",
       " 1.7200537715639388,\n",
       " 1.7190370849200658,\n",
       " 1.716710034438542,\n",
       " 1.7143045510564532,\n",
       " 1.7134918178830827,\n",
       " 1.712693200792585,\n",
       " 1.7097879239491054,\n",
       " 1.7082707285881042,\n",
       " 1.7053049683570862,\n",
       " 1.7064446994236537,\n",
       " 1.7045148849487304,\n",
       " 1.7029791780880519,\n",
       " 1.7019695452281407,\n",
       " 1.6989105922835215,\n",
       " 1.6983094249452864,\n",
       " 1.697017126423972,\n",
       " 1.6944840601512363,\n",
       " 1.6950476578303746,\n",
       " 1.6931656582014902,\n",
       " 1.6923073632376535,\n",
       " 1.6903040392058237,\n",
       " 1.689219696181161,\n",
       " 1.6880241002355303,\n",
       " 1.687951718057905,\n",
       " 1.6845421757016863,\n",
       " 1.6844385164124624,\n",
       " 1.6821509037699018,\n",
       " 1.68171991450446,\n",
       " 1.6807347757475717,\n",
       " 1.6786044665745325,\n",
       " 1.6785366245678492,\n",
       " 1.6777832882744925,\n",
       " 1.677790594100952,\n",
       " 1.6747190645762853,\n",
       " 1.67397598028183,\n",
       " 1.6726225750786918,\n",
       " 1.6713481869016376,\n",
       " 1.6705256428037372,\n",
       " 1.6695392659732273,\n",
       " 1.6683634519577026,\n",
       " 1.667244817529406,\n",
       " 1.666250445161547,\n",
       " 1.6647934181349617,\n",
       " 1.663893233026777,\n",
       " 1.663094757284437,\n",
       " 1.6620974523680552,\n",
       " 1.6609420554978507,\n",
       " 1.6594071217945643,\n",
       " 1.6585426977702549,\n",
       " 1.6566782474517823,\n",
       " 1.6571527021271841,\n",
       " 1.654966970852443,\n",
       " 1.654891289983477,\n",
       " 1.6546300257955278,\n",
       " 1.6525686877114432,\n",
       " 1.6516532318932668,\n",
       " 1.6514036280768258,\n",
       " 1.6494718040738787,\n",
       " 1.6484929544585092,\n",
       " 1.6488746711186,\n",
       " 1.6467561057635716,\n",
       " 1.6466981410980224,\n",
       " 1.6446986947740827,\n",
       " 1.6435419423239572,\n",
       " 1.643890643119812,\n",
       " 1.6432876893452235,\n",
       " 1.642185480254037,\n",
       " 1.6397159882954189,\n",
       " 1.6416140147617886,\n",
       " 1.6396627477237156,\n",
       " 1.6387277449880326,\n",
       " 1.6378070967538017,\n",
       " 1.637515584060124,\n",
       " 1.6359629665102278,\n",
       " 1.6348303573472158,\n",
       " 1.6330040216445922,\n",
       " 1.632593071460724,\n",
       " 1.6335779820169722,\n",
       " 1.6317132438932147,\n",
       " 1.6316043138504028,\n",
       " 1.6291397912161691,\n",
       " 1.628516183580671,\n",
       " 1.627868594442095,\n",
       " 1.6271241818155562,\n",
       " 1.625965883050646,\n",
       " 1.624547360624586,\n",
       " 1.6241504192352294,\n",
       " 1.6235300881522043,\n",
       " 1.6225990329469953,\n",
       " 1.621240098135812,\n",
       " 1.6202887381826128,\n",
       " 1.6196147850581577,\n",
       " 1.6173390643937247,\n",
       " 1.616853756564004,\n",
       " 1.6185663444655283,\n",
       " 1.6171750255993433,\n",
       " 1.6169688684599741,\n",
       " 1.6146416800362724,\n",
       " 1.6136785251753671,\n",
       " 1.6143159117017474,\n",
       " 1.6137934276035855,\n",
       " 1.6114012173243932,\n",
       " 1.6118870513779777,\n",
       " 1.6109695587839399,\n",
       " 1.6117887565067837,\n",
       " 1.6096378224236625,\n",
       " 1.6078933766910009,\n",
       " 1.6089582664625985,\n",
       " 1.6069116881915502,\n",
       " 1.6077946901321412,\n",
       " 1.6047460096223014,\n",
       " 1.606752530166081,\n",
       " 1.6045408265931265,\n",
       " 1.6047094396182469,\n",
       " 1.6031885709081377,\n",
       " 1.6028024537222727,\n",
       " 1.6021794761930193,\n",
       " 1.601875671318599,\n",
       " 1.6004718218530927,\n",
       " 1.6007006185395376,\n",
       " 1.60058696440288,\n",
       " 1.597740970339094,\n",
       " 1.5988814115524292,\n",
       " 1.5982011863163539,\n",
       " 1.5967334389686585,\n",
       " 1.5955701742853436,\n",
       " 1.5955758810043335,\n",
       " 1.5948408280100141,\n",
       " 1.5949106420789445,\n",
       " 1.5921582426343646,\n",
       " 1.5922246388026646,\n",
       " 1.5917563455445425,\n",
       " 1.5905977777072362,\n",
       " 1.591558289527893,\n",
       " 1.5896152530397687,\n",
       " 1.5908473627907889,\n",
       " 1.5887795295034135,\n",
       " 1.589791030543191,\n",
       " 1.5882568069866725,\n",
       " 1.5878837517329625,\n",
       " 1.5867457611220224,\n",
       " 1.5856716564723423,\n",
       " 1.585780700615474,\n",
       " 1.5847683770315988,\n",
       " 1.5846343891961234,\n",
       " 1.5848228982516697,\n",
       " 1.5835245660373143,\n",
       " 1.58379659141813,\n",
       " 1.5827003189495632,\n",
       " 1.5826406683240617,\n",
       " 1.5803364736693246,\n",
       " 1.5820670740944998,\n",
       " 1.579959009374891,\n",
       " 1.5811717646462577,\n",
       " 1.5798667975834437,\n",
       " 1.5793249538966587,\n",
       " 1.5779179164341517,\n",
       " 1.5779486690248763,\n",
       " 1.5773152027811324,\n",
       " 1.5776005353246416,\n",
       " 1.5771853855678013,\n",
       " 1.5751159514699664,\n",
       " 1.5750946606908525,\n",
       " 1.5745267936161587,\n",
       " 1.5745231917926243,\n",
       " 1.571536225931985,\n",
       " 1.5717521173613411,\n",
       " 1.5713329826082503,\n",
       " 1.5725446156093053,\n",
       " 1.5717915790421622,\n",
       " 1.5714504565511431,\n",
       " 1.5682240997041974,\n",
       " 1.5706403068133763,\n",
       " 1.5684871741703579,\n",
       " 1.569143763610295,\n",
       " 1.5680219496999468,\n",
       " 1.5682817459106446,\n",
       " 1.5659960372107369,\n",
       " 1.5668898480279105,\n",
       " 1.5651651859283446,\n",
       " 1.5650066886629377,\n",
       " 1.5658704042434692,\n",
       " 1.5639302577291216,\n",
       " 1.563926100730896,\n",
       " 1.563391329560961,\n",
       " 1.5640965597970145,\n",
       " 1.5640270829200744,\n",
       " 1.5616193226405553,\n",
       " 1.5614409634045192,\n",
       " 1.5614514112472535,\n",
       " 1.560309866496495,\n",
       " 1.5597111174038478,\n",
       " 1.5611634850502014,\n",
       " 1.559831167970385,\n",
       " 1.5592790365219116,\n",
       " 1.55902692931039,\n",
       " 1.5590504152434213,\n",
       " 1.558132709775652,\n",
       " 1.5582682592528208,\n",
       " 1.558033571924482,\n",
       " 1.5560861229896545,\n",
       " 1.556095061983381,\n",
       " 1.554285420690264,\n",
       " 1.555525527681623,\n",
       " 1.5544709392956324,\n",
       " 1.5543737394469126,\n",
       " 1.5538097415651595,\n",
       " 1.5537656017712185,\n",
       " 1.5529263836996896,\n",
       " 1.5526761770248414,\n",
       " 1.552101835182735,\n",
       " 1.5515932389668057,\n",
       " 1.5515229054859707,\n",
       " 1.5510762538228715,\n",
       " 1.5508807914597647,\n",
       " 1.5499271307672773,\n",
       " 1.5501051596232822,\n",
       " 1.5496562225478037,\n",
       " 1.5480852144105093,\n",
       " 1.5479607479912894,\n",
       " 1.5485278061458043,\n",
       " 1.5474576047488622,\n",
       " 1.5470867497580392,\n",
       " 1.5480532680238996,\n",
       " 1.5466211812836783,\n",
       " 1.5454382368496486,\n",
       " 1.5437102556228637,\n",
       " 1.546025424344199,\n",
       " 1.5438596384865897,\n",
       " 1.5453568134989057,\n",
       " 1.5436964120183672,\n",
       " 1.5449765358652388,\n",
       " 1.5428493976593018,\n",
       " 1.5425055061067854,\n",
       " 1.5389002612658909,\n",
       " 1.5434746061052596,\n",
       " 1.540731792790549,\n",
       " 1.5406115804399763,\n",
       " 1.5413939782551356,\n",
       " 1.5410189526421683,\n",
       " 1.5391737767628262,\n",
       " 1.5394348059381757,\n",
       " 1.5394016913005284,\n",
       " 1.5375997730663844,\n",
       " 1.5384779027530124,\n",
       " 1.5373444540160044,\n",
       " 1.5388549447059632,\n",
       " 1.536722091266087,\n",
       " 1.5360276562826973,\n",
       " 1.5368152158600943,\n",
       " 1.5355848448617118,\n",
       " 1.5353177292006357,\n",
       " 1.5340123976979936,\n",
       " 1.5347310781478882,\n",
       " 1.5359714882714408,\n",
       " 1.5350675463676453,\n",
       " 1.5327861530440194,\n",
       " 1.5336969358580452,\n",
       " 1.5331938675471715,\n",
       " 1.5321861130850656,\n",
       " 1.5315797363008772,\n",
       " 1.5329900452068874,\n",
       " 1.5317745515278407,\n",
       " 1.5314278670719692,\n",
       " 1.5311962808881487,\n",
       " 1.5309560418128967,\n",
       " 1.529225172315325,\n",
       " 1.5302242244992936,\n",
       " 1.5279103926249913,\n",
       " 1.5285329631396702,\n",
       " 1.5282922216824122,\n",
       " 1.5281563316072737,\n",
       " 1.5266065699713571,\n",
       " 1.5284443429538181,\n",
       " 1.5257947155407496,\n",
       " 1.528139102458954,\n",
       " 1.5264399766921997,\n",
       " 1.5262765066964286,\n",
       " 1.526232602766582,\n",
       " 1.525180436883654,\n",
       " 1.525460548060281,\n",
       " 1.5233800019536698,\n",
       " 1.5233608518327986,\n",
       " 1.524204342705863,\n",
       " 1.521790337562561,\n",
       " 1.5231846724237714,\n",
       " 1.5226658650806972,\n",
       " 1.5225654755319868,\n",
       " 1.5223695823124477,\n",
       " 1.5208100574357168,\n",
       " 1.5209241117749894,\n",
       " 1.5201797672680446,\n",
       " 1.521123036316463,\n",
       " 1.5196368541036334,\n",
       " 1.5206699865204947,\n",
       " 1.519863533973694,\n",
       " 1.5182933006967818,\n",
       " 1.5183831998280117,\n",
       " 1.5171538233757018,\n",
       " 1.5182757309504917,\n",
       " 1.5189781171934946,\n",
       " 1.5167875272887095,\n",
       " 1.518171535219465,\n",
       " 1.5162944793701172,\n",
       " 1.5156447206224715,\n",
       " 1.5166074752807617,\n",
       " 1.5163975834846497,\n",
       " 1.5157887646130153,\n",
       " 1.515512125832694,\n",
       " 1.5144466638565064,\n",
       " 1.5160278354372296,\n",
       " 1.5126617550849915,\n",
       " 1.5133255175181797,\n",
       " 1.5139220135552542,\n",
       " 1.5137832266943796,\n",
       " 1.513702620778765,\n",
       " 1.5131274785314288,\n",
       " 1.5123812300818307,\n",
       " 1.5112804566110885,\n",
       " 1.512573220048632,\n",
       " 1.5108273897852216,\n",
       " 1.5114383935928344,\n",
       " 1.5110308051109314,\n",
       " 1.508736847128187,\n",
       " 1.5070045811789377,\n",
       " 1.5087008714675902,\n",
       " 1.5075270329202926,\n",
       " 1.5085158620561872,\n",
       " 1.5082964965275356,\n",
       " 1.5077764562198095,\n",
       " 1.504173721585955,\n",
       " 1.5059984632900782,\n",
       " 1.5058367541858129,\n",
       " 1.5048846483230591,\n",
       " 1.5034444638660975,\n",
       " 1.504487122808184,\n",
       " 1.50166232245309,\n",
       " 1.5033018010003225,\n",
       " 1.5033795578139169,\n",
       " 1.5018057107925415,\n",
       " 1.5020672747067043,\n",
       " 1.5017170565468925,\n",
       " 1.5012631041663034,\n",
       " 1.5006609405790057,\n",
       " 1.500481653213501,\n",
       " 1.5003546272005355,\n",
       " 1.4992426259177072,\n",
       " 1.498566356727055,\n",
       " 1.498415984426226,\n",
       " 1.4986491186278208,\n",
       " 1.498345603261675,\n",
       " 1.4978842428752355,\n",
       " 1.4991613507270813,\n",
       " 1.497627808366503,\n",
       " 1.4969405617032732,\n",
       " 1.4977275797298977,\n",
       " 1.4958670037133353,\n",
       " 1.497610274383,\n",
       " 1.4959240402494158,\n",
       " 1.4949300357273647,\n",
       " 1.4949043086596898,\n",
       " 1.4961445995739528,\n",
       " 1.4952863965715681,\n",
       " 1.4945838110787528,\n",
       " 1.4939417140824454,\n",
       " 1.494819414615631,\n",
       " 1.4942767517907278,\n",
       " 1.4932963831084116,\n",
       " 1.4926942365510123,\n",
       " 1.492899569443294,\n",
       " 1.4919416734150477,\n",
       " 1.4930963550295149,\n",
       " 1.492131783281054,\n",
       " 1.49119131565094,\n",
       " 1.4908300144331796,\n",
       " 1.4910314985683986,\n",
       " 1.490861075265067,\n",
       " 1.4899312496185302,\n",
       " 1.4899761353220258,\n",
       " 1.4903824857303074,\n",
       " 1.4882552351270404,\n",
       " 1.4902297343526567,\n",
       " 1.4884915317807879,\n",
       " 1.4887598991394042,\n",
       " 1.4874000694070544,\n",
       " 1.4873364652906145,\n",
       " 1.487864886011396,\n",
       " 1.4873417939458575,\n",
       " 1.4873673694474356,\n",
       " 1.4866979667118618,\n",
       " 1.4858412044388907,\n",
       " 1.4871664558138167,\n",
       " 1.4861189944403512,\n",
       " 1.4846240418297905,\n",
       " 1.4851630577019284,\n",
       " 1.483944068636213,\n",
       " 1.4844056895800999,\n",
       " 1.483655252626964,\n",
       " 1.484083604812622,\n",
       " 1.4839234249932425,\n",
       " 1.4835383074624198,\n",
       " 1.4826042822429113,\n",
       " 1.4821957537106105,\n",
       " 1.481085957799639,\n",
       " 1.482344855581011,\n",
       " 1.4815429312842232,\n",
       " 1.4808613419532777,\n",
       " 1.4809447067124504,\n",
       " 1.481126527275358,\n",
       " 1.4808804196970804,\n",
       " 1.480631823199136,\n",
       " 1.4807560903685433,\n",
       " 1.4805931636265346,\n",
       " 1.4798024773597718,\n",
       " 1.4796330468995231,\n",
       " 1.4801896921225957,\n",
       " 1.479245240347726,\n",
       " 1.4785032561847142,\n",
       " 1.4772289173943656,\n",
       " 1.4763703669820514,\n",
       " 1.4774843096733092,\n",
       " 1.4780830298151288,\n",
       " 1.4781207851001195,\n",
       " 1.4758695653506688,\n",
       " 1.476471154178892,\n",
       " 1.4757457954542978,\n",
       " 1.4753911205700465,\n",
       " 1.4753458942685809,\n",
       " 1.4769558063575199,\n",
       " 1.4749652692249844,\n",
       " 1.474425344807761,\n",
       " 1.4743985840252467,\n",
       " 1.4740334459713527,\n",
       " 1.4740269303321838,\n",
       " 1.4729669400623866,\n",
       " 1.4727920651435853,\n",
       " 1.473395015512194,\n",
       " 1.4741154227937971,\n",
       " 1.4705008183206831,\n",
       " 1.4741503553731101,\n",
       " 1.472695062841688,\n",
       " 1.471950032029833,\n",
       " 1.4713637283870151,\n",
       " 1.4725780401911055,\n",
       " 1.4721232158797128,\n",
       " 1.4711979917117528,\n",
       " 1.4696237819535392,\n",
       " 1.4710764016423907,\n",
       " 1.4702642747334072,\n",
       " 1.4694459864071436,\n",
       " 1.4682039856910705,\n",
       " 1.4688808040959493,\n",
       " 1.468806963307517,\n",
       " 1.4691930072648185,\n",
       " 1.4684554491724287,\n",
       " 1.468927401304245,\n",
       " 1.4674126591001238,\n",
       " 1.467067880289895,\n",
       " 1.4677289809499467,\n",
       " 1.4671989015170506,\n",
       " 1.4691364884376525,\n",
       " 1.467852919442313,\n",
       " 1.4669589408806392,\n",
       " 1.4665748579161508,\n",
       " 1.4671308432306562,\n",
       " 1.4657903756414141,\n",
       " 1.4665750554629735,\n",
       " 1.4636873619897024,\n",
       " 1.4657914314951215,\n",
       " 1.4644754494939531,\n",
       " 1.4646224686077662,\n",
       " 1.4640595742634364,\n",
       " 1.4647242035184587,\n",
       " 1.4632991518293108,\n",
       " 1.4656705907412937,\n",
       " 1.4628819823265076,\n",
       " 1.4638137110642024,\n",
       " 1.4622315866606577,\n",
       " 1.461535678591047,\n",
       " 1.463231772184372,\n",
       " 1.4615996667316982,\n",
       " 1.4614161099706378,\n",
       " 1.4623972705432347,\n",
       " 1.462091680935451,\n",
       " 1.4612379959651403,\n",
       " 1.4611260942050388,\n",
       " 1.4604961012090956,\n",
       " 1.4621477791241237,\n",
       " 1.460005877699171,\n",
       " 1.459786091532026,\n",
       " 1.459361148732049,\n",
       " 1.4586953835827963,\n",
       " 1.4588493125779287,\n",
       " 1.4580934592655728,\n",
       " 1.4573507615498134,\n",
       " 1.4598771393299104,\n",
       " 1.4599488828863416,\n",
       " 1.458634432724544,\n",
       " 1.4585625648498535,\n",
       " 1.4579661454473223,\n",
       " 1.4584289414542062,\n",
       " 1.4574469430106027,\n",
       " 1.457149520942143,\n",
       " 1.4570441211972918,\n",
       " 1.4565637588500977,\n",
       " 1.4572263939040049,\n",
       " 1.4559170876230512,\n",
       " 1.4550913725580488,\n",
       " 1.4573937041418894,\n",
       " 1.456101381778717,\n",
       " 1.455400608267103,\n",
       " 1.4554294381822859,\n",
       " 1.4555002689361571,\n",
       " 1.454591589314597,\n",
       " 1.454745784827641,\n",
       " 1.454124847480229,\n",
       " 1.454328339440482,\n",
       " 1.4538956301552908,\n",
       " 1.452688399383,\n",
       " 1.453787704876491,\n",
       " 1.4543143681117467,\n",
       " 1.4526747516223362,\n",
       " 1.4523037595408304,\n",
       " 1.452715766429901,\n",
       " 1.4529623014586313,\n",
       " 1.4526865312031336,\n",
       " 1.4516924287591662,\n",
       " 1.4518292614391872,\n",
       " 1.4520367980003357,\n",
       " 1.4517383064542497,\n",
       " 1.4501812245164598,\n",
       " 1.4509280758244651,\n",
       " 1.450950540815081,\n",
       " 1.4507774846894401,\n",
       " 1.4505685465676443,\n",
       " 1.449664979321616,\n",
       " 1.4503851124218532,\n",
       " 1.449654562132699,\n",
       " 1.4480183362960815,\n",
       " 1.449236729315349,\n",
       " 1.448040062189102,\n",
       " 1.4487907835415432,\n",
       " 1.4487527762140546,\n",
       " 1.4478454845292228,\n",
       " 1.44716659954616,\n",
       " 1.4480746686458588,\n",
       " 1.4480343324797493,\n",
       " 1.4472486419337136,\n",
       " 1.4478853378977095,\n",
       " 1.4459794972624098,\n",
       " 1.4475746716771807,\n",
       " 1.446092825276511,\n",
       " 1.4469870056424823,\n",
       " 1.446785306930542,\n",
       " 1.4459437140396663,\n",
       " 1.445804112298148,\n",
       " 1.4445455244609289,\n",
       " 1.4464564170156207,\n",
       " 1.4452828764915466,\n",
       " 1.4453542811529978,\n",
       " 1.4450615882873534,\n",
       " 1.4440985594476972,\n",
       " 1.4439235738345555,\n",
       " 1.4450136073998043,\n",
       " 1.4440692688737597,\n",
       " 1.4442127125603812,\n",
       " 1.4434140494891576,\n",
       " 1.4416670254298618,\n",
       " 1.4425069843019758,\n",
       " 1.443352336542947,\n",
       " 1.4416149752480643,\n",
       " 1.4433505484036038,\n",
       " 1.4420843669346401,\n",
       " 1.4430291490895408,\n",
       " 1.441838765144348,\n",
       " 1.4416100536073957,\n",
       " 1.440721847329821,\n",
       " 1.4427423996584756,\n",
       " 1.4411313005856106,\n",
       " 1.4409832554204123,\n",
       " 1.4406479673726218,\n",
       " 1.4411292791366577,\n",
       " 1.4418834669249398,\n",
       " 1.441174748965672,\n",
       " 1.4403492944581169,\n",
       " 1.439393709387098,\n",
       " 1.4398684484618052,\n",
       " 1.4390812490667615,\n",
       " 1.440689459017345,\n",
       " 1.4376003384590148,\n",
       " 1.4383535402161733,\n",
       " 1.4394852655274528,\n",
       " 1.4378867541040694,\n",
       " 1.4384495820317948,\n",
       " 1.438424071243831,\n",
       " 1.4375173364366804,\n",
       " 1.4368240177631377,\n",
       " 1.4368840524128506,\n",
       " 1.4361611468451363,\n",
       " 1.4357525689261301,\n",
       " 1.4370716060910906,\n",
       " 1.4379952277456012,\n",
       " 1.437129203762327,\n",
       " 1.4361764669418335,\n",
       " 1.4357560728277479,\n",
       " 1.4331369434084211,\n",
       " 1.4357390659196037,\n",
       " 1.435397275856563,\n",
       " 1.435636043548584,\n",
       " 1.4356432003634316,\n",
       " 1.4349658267838614,\n",
       " 1.4345840845789228,\n",
       " 1.4338808570589339,\n",
       " 1.4341725758143833,\n",
       " 1.434856162752424,\n",
       " 1.4336198721613203,\n",
       " 1.435043740272522,\n",
       " 1.4324318766593933,\n",
       " 1.433750991310392,\n",
       " 1.4335131185395378,\n",
       " 1.4329262069293431,\n",
       " 1.4331403417246682,\n",
       " 1.431883909021105,\n",
       " 1.432867144686835,\n",
       " 1.4317874567849296,\n",
       " 1.4324241382735117,\n",
       " 1.4321301758289338,\n",
       " 1.4322509459086827,\n",
       " 1.4317010845456803,\n",
       " 1.431644242150443,\n",
       " 1.4297535998480662,\n",
       " 1.4317710093089513,\n",
       " 1.430588471038001,\n",
       " 1.4302055614335196,\n",
       " 1.431210548537118,\n",
       " 1.4306491357939584,\n",
       " 1.4283609134810311,\n",
       " 1.430740816252572,\n",
       " 1.4299462369510105,\n",
       " 1.4291014807564872,\n",
       " 1.4303160888808115,\n",
       " 1.429824013369424,\n",
       " 1.4291940408093589,\n",
       " 1.4287636263029917,\n",
       " 1.428467583656311,\n",
       " 1.428398506981986,\n",
       " 1.4279811961310251,\n",
       " 1.427829727104732,\n",
       " 1.4275363530431475,\n",
       " 1.4277818475450788,\n",
       " 1.4271816526140486,\n",
       " 1.427095241206033,\n",
       " 1.4277943577085221,\n",
       " 1.4261742949485778,\n",
       " 1.4265294560364314,\n",
       " 1.4274915661130632,\n",
       " 1.426074755191803,\n",
       " 1.4252001651695796,\n",
       " 1.426579373223441,\n",
       " 1.4266825931412832,\n",
       " 1.4252252527645657,\n",
       " 1.4251522830554417,\n",
       " 1.424948787689209,\n",
       " 1.425485884291785,\n",
       " 1.4241535033498491,\n",
       " 1.4258119259561812,\n",
       " 1.4222710507256644,\n",
       " 1.4255974292755127,\n",
       " 1.4252782685416086,\n",
       " 1.423222884110042,\n",
       " 1.4223656381879535,\n",
       " 1.4241979309490749,\n",
       " 1.4225992449692317,\n",
       " 1.4236012194837844,\n",
       " 1.42233122246606,\n",
       " 1.4238838119166237,\n",
       " 1.4221939487116677,\n",
       " 1.4222602546215057,\n",
       " 1.4233912817069463,\n",
       " 1.4221140248434885,\n",
       " 1.422370377608708,\n",
       " 1.4219496752534593,\n",
       " 1.4216340780258179,\n",
       " 1.4225592349256788,\n",
       " 1.421740059341703,\n",
       " 1.4225363297121865,\n",
       " 1.4204392560890742,\n",
       " 1.421866204057421,\n",
       " 1.4217829287052155,\n",
       " 1.4206043601036071,\n",
       " 1.4207113002027785,\n",
       " 1.4202740456376757,\n",
       " 1.4197446175983974,\n",
       " 1.4202738608632768,\n",
       " 1.4202568548066274,\n",
       " 1.4192152627876826,\n",
       " 1.418336912563869,\n",
       " 1.419270795583725,\n",
       " 1.4179423059735978,\n",
       " 1.419186338356563,\n",
       " 1.4194326145308358,\n",
       " 1.4191568587507521,\n",
       " 1.4198721996375492,\n",
       " 1.418574490717479,\n",
       " 1.4188102040972028,\n",
       " 1.4182567119598388,\n",
       " 1.4181228109768458,\n",
       " 1.4181224984782084,\n",
       " 1.4185452733721051,\n",
       " 1.4179915751729693,\n",
       " 1.4174483290740423,\n",
       " 1.4175317926066262,\n",
       " 1.4166487676756723,\n",
       " 1.4172626325062343,\n",
       " 1.4166645509856088,\n",
       " 1.4170121320656368,\n",
       " 1.4166353072438922,\n",
       " 1.4161382743290492,\n",
       " 1.4164906024932862,\n",
       " 1.4162286400794983,\n",
       " 1.4152532458305358,\n",
       " 1.416036366564887,\n",
       " 1.4159472107887268,\n",
       " 1.4161271955285752,\n",
       " 1.4146825637136187,\n",
       " 1.414942671571459,\n",
       " 1.4144358464649744,\n",
       " 1.4149996859686715,\n",
       " 1.4149266566549028,\n",
       " 1.4145458655697958,\n",
       " 1.415225338935852,\n",
       " 1.4141837264810289,\n",
       " 1.4143388663019454,\n",
       " 1.4143313101359776,\n",
       " 1.4140176832675935,\n",
       " 1.4132265150547028,\n",
       " 1.4140794243131365,\n",
       " 1.413613155909947,\n",
       " 1.41188930443355,\n",
       " 1.4125094839504786,\n",
       " 1.4111465351922172,\n",
       " 1.4132253774574826,\n",
       " 1.4131401240825654,\n",
       " 1.4130636990070342,\n",
       " 1.4118839859962464,\n",
       " 1.4109422956194198,\n",
       " 1.411434826680592,\n",
       " 1.412342186485018,\n",
       " 1.4113137117453984,\n",
       " 1.4118393651076726,\n",
       " 1.4112538976328715,\n",
       " 1.4107124677726202,\n",
       " 1.4105484988008226,\n",
       " 1.4112259728567942,\n",
       " 1.411129082952227,\n",
       " 1.4108404559748513,\n",
       " 1.4098038043294634,\n",
       " 1.409942308494023,\n",
       " 1.410258185012,\n",
       " 1.4108886591025762,\n",
       " 1.4088247426918574,\n",
       " 1.4082265036446708,\n",
       " 1.4094040742942264,\n",
       " 1.4099509017808096,\n",
       " 1.4091667039053781,\n",
       " 1.4083300190312522,\n",
       " 1.4086917894227164,\n",
       " 1.409162232705525,\n",
       " 1.4076809406280517,\n",
       " 1.408126074075699,\n",
       " 1.408641048840114,\n",
       " 1.4073629651750836,\n",
       " 1.4071299365588597,\n",
       " 1.4087073113237107,\n",
       " 1.4066539789949144,\n",
       " 1.4049240478447504,\n",
       " 1.4074686246258872,\n",
       " 1.4076070691858018,\n",
       " 1.4068723729678563,\n",
       " 1.4071012599127632,\n",
       " 1.4051737768309458,\n",
       " 1.4058439595358712,\n",
       " 1.4064707977431161,\n",
       " 1.4074912190437316,\n",
       " 1.4055484575884682,\n",
       " 1.4055987630571638,\n",
       " 1.4047042063304356,\n",
       " 1.4050135450703758,\n",
       " 1.40535843031747,\n",
       " 1.4057813337871006,\n",
       " 1.4050763777324131,\n",
       " 1.4035711560930524,\n",
       " 1.404950259413038,\n",
       " 1.4036406457424164,\n",
       " 1.404458008493696,\n",
       " 1.4048747675759452,\n",
       " 1.4038966051169803,\n",
       " 1.403824814728328,\n",
       " 1.4037219371114458,\n",
       " 1.4043395723615373,\n",
       " 1.4014085394995552,\n",
       " 1.405425511939185,\n",
       " 1.4035438103335245,\n",
       " 1.4037083327770232,\n",
       " 1.4045885418142592,\n",
       " 1.402840508733477,\n",
       " 1.4031066409179143,\n",
       " 1.4036220158849444,\n",
       " 1.4027064757687704,\n",
       " 1.4029608752046312,\n",
       " 1.4011082759925297,\n",
       " 1.4028871289321354,\n",
       " 1.4025038037981306,\n",
       " 1.4023451047284263,\n",
       " 1.4019455671310426,\n",
       " 1.4022042214870454,\n",
       " 1.4013201202665055,\n",
       " 1.401590735571725,\n",
       " 1.4017232137066977,\n",
       " 1.4012932981763566,\n",
       " 1.401478568145207,\n",
       " 1.4002833868776048,\n",
       " 1.4000294515064784,\n",
       " 1.4004173355443137,\n",
       " 1.399430650472641,\n",
       " 1.3990513043744224,\n",
       " 1.4011000454425813,\n",
       " 1.3999624337468828,\n",
       " 1.4005934178829194,\n",
       " 1.3997976328645434,\n",
       " 1.399610424041748,\n",
       " 1.4003965071269444,\n",
       " 1.399216980593545,\n",
       " 1.3997536071709225,\n",
       " 1.4001917685781207,\n",
       " 1.3988213224070414,\n",
       " 1.3991168090275357,\n",
       " 1.3988987956728254,\n",
       " 1.3979550327573504,\n",
       " 1.3972690514155797,\n",
       " 1.3986382501465933,\n",
       " 1.3989770753043038,\n",
       " 1.3985819237572805,\n",
       " 1.396816291127886,\n",
       " 1.3967407958848135,\n",
       " 1.3989106340067727,\n",
       " 1.3971711763313839,\n",
       " 1.397226275716509,\n",
       " 1.3977387394223895,\n",
       " 1.3973612121173313,\n",
       " 1.3972947878496988,\n",
       " 1.3972496492522104,\n",
       " 1.3969094770295278,\n",
       " 1.396375641652516,\n",
       " 1.3967989078589849,\n",
       " 1.3956927597522735,\n",
       " 1.396547693014145,\n",
       " 1.396438181400299,\n",
       " 1.396020988055638,\n",
       " 1.3955570323126656,\n",
       " 1.3954660952091218,\n",
       " 1.3962143642561777,\n",
       " 1.395620392901557,\n",
       " 1.3948778927326202,\n",
       " 1.3955636169229235,\n",
       " 1.394588463647025,\n",
       " 1.3948163092136383,\n",
       " 1.3946729413100651,\n",
       " 1.39416897552354,\n",
       " 1.3940296624388013,\n",
       " 1.3937635864530291,\n",
       " 1.3930215903690883,\n",
       " 1.394213021653039,\n",
       " 1.3939518077032906,\n",
       " 1.3937342916216169,\n",
       " 1.3942020501409258,\n",
       " 1.3937877237796783,\n",
       " 1.393195880310876,\n",
       " 1.3925304787499564,\n",
       " 1.393945460660117,\n",
       " 1.3936960884502956,\n",
       " 1.3930242947169713,\n",
       " 1.3925013133457729,\n",
       " 1.3931569584778376,\n",
       " 1.3927460789680481,\n",
       " 1.3920682208878654,\n",
       " 1.39145045706204,\n",
       " 1.3922814147812979,\n",
       " 1.3925829325403487,\n",
       " 1.3914781212806702,\n",
       " 1.3919110528060368,\n",
       " 1.3916439720562526,\n",
       " 1.3917823817048753,\n",
       " 1.3913564043385642,\n",
       " 1.3904590010643005,\n",
       " 1.3910778837544577,\n",
       " 1.3910001048019953,\n",
       " 1.3905329457351139,\n",
       " 1.3907606533595493,\n",
       " 1.390209253345217,\n",
       " 1.3907547175884247,\n",
       " 1.390724061216627,\n",
       " 1.3896026296275004,\n",
       " 1.3904252128941672,\n",
       " 1.3900499837739126,\n",
       " 1.389890777213233,\n",
       " 1.3893514275550842,\n",
       " 1.3894272812775204,\n",
       " 1.388928119625364,\n",
       " 1.3888964891433715,\n",
       " 1.3903109431266785,\n",
       " 1.3886988188539233,\n",
       " 1.3889380761555263,\n",
       " 1.3889311049665725,\n",
       " 1.3886646100452968,\n",
       " 1.3884114061083113,\n",
       " 1.3892443069389888,\n",
       " 1.3878601482936315,\n",
       " 1.3880746756281173,\n",
       " 1.3884540677070618,\n",
       " 1.3881348712103707,\n",
       " 1.387978469473975]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3876 - acc: 0.4429 - val_loss: 6.1177 - val_acc: 0.1933\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3880 - acc: 0.4400 - val_loss: 6.1575 - val_acc: 0.1933\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3876 - acc: 0.4371 - val_loss: 6.1464 - val_acc: 0.1933\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3870 - acc: 0.4486 - val_loss: 6.1576 - val_acc: 0.1933\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3868 - acc: 0.4414 - val_loss: 6.1463 - val_acc: 0.1933\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3873 - acc: 0.4400 - val_loss: 6.1149 - val_acc: 0.1933\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3873 - acc: 0.4414 - val_loss: 6.1475 - val_acc: 0.1933\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3865 - acc: 0.4400 - val_loss: 6.1085 - val_acc: 0.1933\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3863 - acc: 0.4457 - val_loss: 6.1549 - val_acc: 0.1933\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3875 - acc: 0.4400 - val_loss: 6.1343 - val_acc: 0.1933\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3861 - acc: 0.4414 - val_loss: 6.1150 - val_acc: 0.1933\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3860 - acc: 0.4414 - val_loss: 6.1150 - val_acc: 0.1933\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3874 - acc: 0.4471 - val_loss: 6.1579 - val_acc: 0.1933\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3860 - acc: 0.4486 - val_loss: 6.1151 - val_acc: 0.1933\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3854 - acc: 0.4486 - val_loss: 6.1073 - val_acc: 0.1933\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3859 - acc: 0.4457 - val_loss: 6.1132 - val_acc: 0.1933\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3853 - acc: 0.4386 - val_loss: 6.1287 - val_acc: 0.1933\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3841 - acc: 0.4371 - val_loss: 6.1581 - val_acc: 0.1933\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3859 - acc: 0.4414 - val_loss: 6.1153 - val_acc: 0.1933\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3860 - acc: 0.4429 - val_loss: 6.1117 - val_acc: 0.1933\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3849 - acc: 0.4429 - val_loss: 6.1082 - val_acc: 0.1933\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3852 - acc: 0.4414 - val_loss: 6.1103 - val_acc: 0.1933\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3848 - acc: 0.4414 - val_loss: 6.1155 - val_acc: 0.1933\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3857 - acc: 0.4471 - val_loss: 6.1216 - val_acc: 0.1933\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3640 - acc: 0.444 - 0s 117us/step - loss: 1.3836 - acc: 0.4457 - val_loss: 6.1583 - val_acc: 0.1933\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3852 - acc: 0.4429 - val_loss: 6.1156 - val_acc: 0.1933\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3844 - acc: 0.4443 - val_loss: 6.1156 - val_acc: 0.1933\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3840 - acc: 0.4486 - val_loss: 6.1156 - val_acc: 0.1933\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3850 - acc: 0.4400 - val_loss: 6.1288 - val_acc: 0.1933\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3841 - acc: 0.4400 - val_loss: 6.1157 - val_acc: 0.1933\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3840 - acc: 0.4443 - val_loss: 6.1158 - val_acc: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3842 - acc: 0.4457 - val_loss: 6.1158 - val_acc: 0.1933\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3839 - acc: 0.4443 - val_loss: 6.1123 - val_acc: 0.1933\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3842 - acc: 0.4386 - val_loss: 6.1159 - val_acc: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3835 - acc: 0.4429 - val_loss: 6.1159 - val_acc: 0.1933\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3823 - acc: 0.4400 - val_loss: 6.1159 - val_acc: 0.1933\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3829 - acc: 0.4443 - val_loss: 6.1160 - val_acc: 0.1933\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3830 - acc: 0.4443 - val_loss: 6.1160 - val_acc: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3828 - acc: 0.4500 - val_loss: 6.1161 - val_acc: 0.1933\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3824 - acc: 0.4414 - val_loss: 6.1161 - val_acc: 0.1933\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3821 - acc: 0.4414 - val_loss: 6.1161 - val_acc: 0.1933\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3819 - acc: 0.4514 - val_loss: 6.1162 - val_acc: 0.1933\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3827 - acc: 0.4471 - val_loss: 6.1162 - val_acc: 0.1933\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3829 - acc: 0.4429 - val_loss: 6.1119 - val_acc: 0.1933\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3823 - acc: 0.4414 - val_loss: 6.1081 - val_acc: 0.1967\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3815 - acc: 0.4414 - val_loss: 6.1164 - val_acc: 0.1933\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3810 - acc: 0.4371 - val_loss: 6.1081 - val_acc: 0.1967\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3827 - acc: 0.4414 - val_loss: 6.1592 - val_acc: 0.1933\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3818 - acc: 0.4514 - val_loss: 6.1129 - val_acc: 0.1933\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3824 - acc: 0.4486 - val_loss: 6.1129 - val_acc: 0.1933\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3816 - acc: 0.4457 - val_loss: 6.1165 - val_acc: 0.1933\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3805 - acc: 0.4429 - val_loss: 6.1166 - val_acc: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3819 - acc: 0.4429 - val_loss: 6.1166 - val_acc: 0.1933\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3816 - acc: 0.4400 - val_loss: 6.1166 - val_acc: 0.1933\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3805 - acc: 0.4429 - val_loss: 6.1167 - val_acc: 0.1933\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3806 - acc: 0.4414 - val_loss: 6.1167 - val_acc: 0.1933\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3803 - acc: 0.4529 - val_loss: 6.1167 - val_acc: 0.1933\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3807 - acc: 0.4429 - val_loss: 6.1168 - val_acc: 0.1933\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3808 - acc: 0.4457 - val_loss: 6.1168 - val_acc: 0.1933\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 121us/step - loss: 1.3809 - acc: 0.4386 - val_loss: 6.1169 - val_acc: 0.1933\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3505 - acc: 0.484 - 0s 113us/step - loss: 1.3796 - acc: 0.4614 - val_loss: 6.1120 - val_acc: 0.1933\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3817 - acc: 0.4457 - val_loss: 6.1169 - val_acc: 0.1933\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3804 - acc: 0.4414 - val_loss: 6.1170 - val_acc: 0.1933\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3809 - acc: 0.4429 - val_loss: 6.1170 - val_acc: 0.1933\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3797 - acc: 0.4443 - val_loss: 6.1171 - val_acc: 0.1933\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3807 - acc: 0.4386 - val_loss: 6.1433 - val_acc: 0.1933\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3804 - acc: 0.4414 - val_loss: 6.1171 - val_acc: 0.1933\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3792 - acc: 0.4471 - val_loss: 6.1172 - val_acc: 0.1933\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3803 - acc: 0.4457 - val_loss: 6.1224 - val_acc: 0.1933\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3793 - acc: 0.4443 - val_loss: 6.1172 - val_acc: 0.1933\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3791 - acc: 0.4457 - val_loss: 6.1173 - val_acc: 0.1933\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3788 - acc: 0.4386 - val_loss: 6.1092 - val_acc: 0.1967\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3796 - acc: 0.4414 - val_loss: 6.1173 - val_acc: 0.1933\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3802 - acc: 0.4400 - val_loss: 6.1174 - val_acc: 0.1933\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3786 - acc: 0.4471 - val_loss: 6.1174 - val_acc: 0.1933\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3782 - acc: 0.4514 - val_loss: 6.0902 - val_acc: 0.1933\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3792 - acc: 0.4443 - val_loss: 6.1175 - val_acc: 0.1933\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3789 - acc: 0.4443 - val_loss: 6.1175 - val_acc: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3783 - acc: 0.4500 - val_loss: 6.1175 - val_acc: 0.1933\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3785 - acc: 0.4486 - val_loss: 6.1124 - val_acc: 0.1933\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3777 - acc: 0.4400 - val_loss: 6.1176 - val_acc: 0.1933\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3780 - acc: 0.4443 - val_loss: 6.1176 - val_acc: 0.1933\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3782 - acc: 0.4414 - val_loss: 6.1177 - val_acc: 0.1933\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3776 - acc: 0.4443 - val_loss: 6.1177 - val_acc: 0.1933\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3768 - acc: 0.4500 - val_loss: 6.1177 - val_acc: 0.1933\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3765 - acc: 0.4471 - val_loss: 6.1178 - val_acc: 0.1933\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3776 - acc: 0.4457 - val_loss: 6.1178 - val_acc: 0.1933\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3788 - acc: 0.4486 - val_loss: 6.1178 - val_acc: 0.1933\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3770 - acc: 0.4529 - val_loss: 6.1179 - val_acc: 0.1933\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3774 - acc: 0.4471 - val_loss: 6.1179 - val_acc: 0.1933\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3772 - acc: 0.4457 - val_loss: 6.1179 - val_acc: 0.1933\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3775 - acc: 0.4471 - val_loss: 6.1180 - val_acc: 0.1933\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3764 - acc: 0.4443 - val_loss: 6.1180 - val_acc: 0.1933\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3775 - acc: 0.4400 - val_loss: 6.1181 - val_acc: 0.1933\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3769 - acc: 0.4443 - val_loss: 6.1181 - val_acc: 0.1933\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3763 - acc: 0.4486 - val_loss: 6.1181 - val_acc: 0.1933\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3755 - acc: 0.4471 - val_loss: 6.1182 - val_acc: 0.1933\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3763 - acc: 0.4457 - val_loss: 6.1182 - val_acc: 0.1933\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3767 - acc: 0.4486 - val_loss: 6.0824 - val_acc: 0.1933\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3758 - acc: 0.4486 - val_loss: 6.1183 - val_acc: 0.1933\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3758 - acc: 0.4500 - val_loss: 6.1183 - val_acc: 0.1933\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3748 - acc: 0.4543 - val_loss: 6.1183 - val_acc: 0.1933\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3756 - acc: 0.4457 - val_loss: 6.1184 - val_acc: 0.1933\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3756 - acc: 0.4429 - val_loss: 6.1184 - val_acc: 0.1933\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3759 - acc: 0.4371 - val_loss: 6.1185 - val_acc: 0.1933\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3760 - acc: 0.4500 - val_loss: 6.1185 - val_acc: 0.1933\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3747 - acc: 0.4500 - val_loss: 6.1185 - val_acc: 0.1933\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3747 - acc: 0.4471 - val_loss: 6.1186 - val_acc: 0.1933\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3748 - acc: 0.4514 - val_loss: 6.1186 - val_acc: 0.1933\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3752 - acc: 0.4443 - val_loss: 6.1186 - val_acc: 0.1933\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3747 - acc: 0.4443 - val_loss: 6.1187 - val_acc: 0.1933\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3742 - acc: 0.4500 - val_loss: 6.1187 - val_acc: 0.1933\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3746 - acc: 0.4529 - val_loss: 6.1187 - val_acc: 0.1933\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3744 - acc: 0.4471 - val_loss: 6.1188 - val_acc: 0.1933\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3750 - acc: 0.4457 - val_loss: 6.1188 - val_acc: 0.1933\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3742 - acc: 0.4471 - val_loss: 6.1188 - val_acc: 0.1933\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3744 - acc: 0.4471 - val_loss: 6.1188 - val_acc: 0.1933\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3739 - acc: 0.4529 - val_loss: 6.1142 - val_acc: 0.1933\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 114us/step - loss: 1.3744 - acc: 0.4557 - val_loss: 6.1189 - val_acc: 0.1933\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3743 - acc: 0.4429 - val_loss: 6.1190 - val_acc: 0.1933\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3739 - acc: 0.4457 - val_loss: 6.1190 - val_acc: 0.1933\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3731 - acc: 0.4443 - val_loss: 6.0214 - val_acc: 0.1933\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3751 - acc: 0.4500 - val_loss: 6.1190 - val_acc: 0.1933\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3740 - acc: 0.4457 - val_loss: 6.1191 - val_acc: 0.1933\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3733 - acc: 0.4471 - val_loss: 6.1191 - val_acc: 0.1933\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3738 - acc: 0.4443 - val_loss: 6.1192 - val_acc: 0.1933\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3708 - acc: 0.4457 - val_loss: 6.1192 - val_acc: 0.1933\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3728 - acc: 0.4529 - val_loss: 6.1192 - val_acc: 0.1933\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3731 - acc: 0.4486 - val_loss: 6.1192 - val_acc: 0.1933\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3727 - acc: 0.4514 - val_loss: 6.1193 - val_acc: 0.1933\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3726 - acc: 0.4471 - val_loss: 6.1193 - val_acc: 0.1933\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3726 - acc: 0.4471 - val_loss: 6.1194 - val_acc: 0.1933\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3724 - acc: 0.4486 - val_loss: 6.1194 - val_acc: 0.1933\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3719 - acc: 0.4529 - val_loss: 6.1194 - val_acc: 0.1933\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3719 - acc: 0.4500 - val_loss: 6.1194 - val_acc: 0.1933\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3720 - acc: 0.4471 - val_loss: 6.1195 - val_acc: 0.1933\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3722 - acc: 0.4443 - val_loss: 6.1195 - val_acc: 0.1933\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3720 - acc: 0.4543 - val_loss: 6.1195 - val_acc: 0.1933\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3718 - acc: 0.4514 - val_loss: 6.1196 - val_acc: 0.1933\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3715 - acc: 0.4471 - val_loss: 6.1196 - val_acc: 0.1933\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3724 - acc: 0.4514 - val_loss: 6.1197 - val_acc: 0.1933\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3710 - acc: 0.4514 - val_loss: 6.1197 - val_acc: 0.1933\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3725 - acc: 0.4500 - val_loss: 6.1197 - val_acc: 0.1933\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3713 - acc: 0.4543 - val_loss: 6.1198 - val_acc: 0.1933\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3717 - acc: 0.4471 - val_loss: 6.1198 - val_acc: 0.1933\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3710 - acc: 0.4471 - val_loss: 6.1199 - val_acc: 0.1933\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3700 - acc: 0.4471 - val_loss: 6.1199 - val_acc: 0.1933\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3704 - acc: 0.4471 - val_loss: 6.1199 - val_acc: 0.1933\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3711 - acc: 0.4514 - val_loss: 6.1200 - val_acc: 0.1933\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3702 - acc: 0.4486 - val_loss: 6.1200 - val_acc: 0.1933\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3708 - acc: 0.4500 - val_loss: 6.0805 - val_acc: 0.1933\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3710 - acc: 0.4471 - val_loss: 6.0729 - val_acc: 0.1933\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3699 - acc: 0.4500 - val_loss: 6.1201 - val_acc: 0.1933\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3707 - acc: 0.4514 - val_loss: 6.1202 - val_acc: 0.1933\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3696 - acc: 0.4571 - val_loss: 6.1202 - val_acc: 0.1933\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3693 - acc: 0.4514 - val_loss: 6.1202 - val_acc: 0.1933\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3711 - acc: 0.4486 - val_loss: 6.1203 - val_acc: 0.1933\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3697 - acc: 0.4543 - val_loss: 6.1203 - val_acc: 0.1933\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3696 - acc: 0.4471 - val_loss: 6.0864 - val_acc: 0.1933\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3696 - acc: 0.4586 - val_loss: 6.1203 - val_acc: 0.1933\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3689 - acc: 0.4500 - val_loss: 6.1204 - val_acc: 0.1933\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3693 - acc: 0.4529 - val_loss: 6.1204 - val_acc: 0.1933\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3685 - acc: 0.4471 - val_loss: 6.1205 - val_acc: 0.1933\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3695 - acc: 0.4486 - val_loss: 6.1205 - val_acc: 0.1933\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3695 - acc: 0.4543 - val_loss: 6.1205 - val_acc: 0.1933\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3683 - acc: 0.4471 - val_loss: 6.1206 - val_acc: 0.1933\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3687 - acc: 0.4471 - val_loss: 6.1206 - val_acc: 0.1933\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3687 - acc: 0.4514 - val_loss: 6.1206 - val_acc: 0.1933\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3686 - acc: 0.4500 - val_loss: 6.1207 - val_acc: 0.1933\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3683 - acc: 0.4557 - val_loss: 6.1207 - val_acc: 0.1933\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3687 - acc: 0.4514 - val_loss: 6.1208 - val_acc: 0.1933\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3685 - acc: 0.4543 - val_loss: 6.0772 - val_acc: 0.1933\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3684 - acc: 0.4471 - val_loss: 6.1208 - val_acc: 0.1933\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3671 - acc: 0.4614 - val_loss: 6.1209 - val_acc: 0.1933\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3685 - acc: 0.4529 - val_loss: 6.1209 - val_acc: 0.1933\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3681 - acc: 0.4543 - val_loss: 6.1210 - val_acc: 0.1933\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3691 - acc: 0.4486 - val_loss: 6.1210 - val_acc: 0.1933\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.3674 - acc: 0.4557 - val_loss: 6.1210 - val_acc: 0.1933\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3677 - acc: 0.4486 - val_loss: 6.1211 - val_acc: 0.1933\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3682 - acc: 0.4529 - val_loss: 6.1211 - val_acc: 0.1933\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3666 - acc: 0.4586 - val_loss: 6.1211 - val_acc: 0.1933\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3670 - acc: 0.4400 - val_loss: 6.1212 - val_acc: 0.1933\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3674 - acc: 0.4529 - val_loss: 6.1212 - val_acc: 0.1933\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3674 - acc: 0.4486 - val_loss: 6.1212 - val_acc: 0.1933\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3668 - acc: 0.4443 - val_loss: 6.1213 - val_acc: 0.1933\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3664 - acc: 0.4514 - val_loss: 6.1213 - val_acc: 0.1933\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3669 - acc: 0.4529 - val_loss: 6.1213 - val_acc: 0.1933\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3669 - acc: 0.4571 - val_loss: 6.1214 - val_acc: 0.1933\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3656 - acc: 0.4557 - val_loss: 6.1214 - val_acc: 0.1933\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3669 - acc: 0.4586 - val_loss: 6.0977 - val_acc: 0.1933\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3660 - acc: 0.4586 - val_loss: 6.1215 - val_acc: 0.1933\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3657 - acc: 0.4529 - val_loss: 6.1215 - val_acc: 0.1933\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3658 - acc: 0.4514 - val_loss: 6.1215 - val_acc: 0.1933\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3658 - acc: 0.4571 - val_loss: 6.0766 - val_acc: 0.1933\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3668 - acc: 0.4571 - val_loss: 6.1216 - val_acc: 0.1933\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3660 - acc: 0.4514 - val_loss: 6.1216 - val_acc: 0.1933\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3659 - acc: 0.4557 - val_loss: 6.1217 - val_acc: 0.1933\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3663 - acc: 0.4543 - val_loss: 6.1076 - val_acc: 0.1933\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3658 - acc: 0.4529 - val_loss: 6.1217 - val_acc: 0.1933\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3658 - acc: 0.4600 - val_loss: 6.1217 - val_acc: 0.1933\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3654 - acc: 0.4571 - val_loss: 6.1218 - val_acc: 0.1933\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3656 - acc: 0.4486 - val_loss: 6.1218 - val_acc: 0.1933\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3648 - acc: 0.4571 - val_loss: 6.1219 - val_acc: 0.1933\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3651 - acc: 0.4500 - val_loss: 6.1219 - val_acc: 0.1933\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3646 - acc: 0.4557 - val_loss: 6.1219 - val_acc: 0.1933\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3646 - acc: 0.4471 - val_loss: 6.0949 - val_acc: 0.1933\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3648 - acc: 0.4543 - val_loss: 6.1220 - val_acc: 0.1933\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3650 - acc: 0.4500 - val_loss: 6.1220 - val_acc: 0.1933\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3649 - acc: 0.4543 - val_loss: 6.1221 - val_acc: 0.1933\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3646 - acc: 0.4500 - val_loss: 6.1221 - val_acc: 0.1933\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3638 - acc: 0.4543 - val_loss: 6.1221 - val_acc: 0.1933\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3641 - acc: 0.4529 - val_loss: 6.1222 - val_acc: 0.1933\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3646 - acc: 0.4543 - val_loss: 6.1222 - val_acc: 0.1933\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3642 - acc: 0.4529 - val_loss: 6.1222 - val_acc: 0.1933\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3636 - acc: 0.4571 - val_loss: 6.1223 - val_acc: 0.1933\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3624 - acc: 0.4600 - val_loss: 6.1223 - val_acc: 0.1933\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3637 - acc: 0.4500 - val_loss: 6.1224 - val_acc: 0.1933\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3639 - acc: 0.4486 - val_loss: 6.1224 - val_acc: 0.1933\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3641 - acc: 0.4500 - val_loss: 6.1224 - val_acc: 0.1933\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3631 - acc: 0.4543 - val_loss: 6.1225 - val_acc: 0.1933\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3636 - acc: 0.4514 - val_loss: 6.1225 - val_acc: 0.1933\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3630 - acc: 0.4543 - val_loss: 6.1225 - val_acc: 0.1933\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3632 - acc: 0.4571 - val_loss: 6.1226 - val_acc: 0.1933\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3631 - acc: 0.4514 - val_loss: 6.1226 - val_acc: 0.1933\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3629 - acc: 0.4571 - val_loss: 6.0811 - val_acc: 0.1933\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3636 - acc: 0.4529 - val_loss: 6.1227 - val_acc: 0.1933\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3627 - acc: 0.4600 - val_loss: 6.1227 - val_acc: 0.1933\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3626 - acc: 0.4643 - val_loss: 6.1227 - val_acc: 0.1933\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3627 - acc: 0.4557 - val_loss: 6.1228 - val_acc: 0.1933\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3622 - acc: 0.4514 - val_loss: 6.1228 - val_acc: 0.1933\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3629 - acc: 0.4557 - val_loss: 6.1228 - val_acc: 0.1933\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3620 - acc: 0.4586 - val_loss: 6.1228 - val_acc: 0.1933\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3613 - acc: 0.4543 - val_loss: 6.1229 - val_acc: 0.1933\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3620 - acc: 0.4571 - val_loss: 6.1229 - val_acc: 0.1933\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3625 - acc: 0.4571 - val_loss: 6.1229 - val_acc: 0.1933\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3620 - acc: 0.4557 - val_loss: 6.1230 - val_acc: 0.1933\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.3615 - acc: 0.4557 - val_loss: 6.1230 - val_acc: 0.1933\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3620 - acc: 0.4643 - val_loss: 6.1230 - val_acc: 0.1933\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3615 - acc: 0.4600 - val_loss: 6.1231 - val_acc: 0.1933\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3610 - acc: 0.4586 - val_loss: 6.1231 - val_acc: 0.1933\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3619 - acc: 0.4571 - val_loss: 6.1232 - val_acc: 0.1933\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3614 - acc: 0.4586 - val_loss: 6.1232 - val_acc: 0.1933\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3623 - acc: 0.4571 - val_loss: 6.1232 - val_acc: 0.1933\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3613 - acc: 0.4514 - val_loss: 6.1233 - val_acc: 0.1933\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3608 - acc: 0.4614 - val_loss: 6.1233 - val_acc: 0.1933\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3618 - acc: 0.4586 - val_loss: 6.1233 - val_acc: 0.1933\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3608 - acc: 0.4614 - val_loss: 6.1234 - val_acc: 0.1933\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3608 - acc: 0.4571 - val_loss: 6.1234 - val_acc: 0.1933\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3603 - acc: 0.4614 - val_loss: 6.1234 - val_acc: 0.1933\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3609 - acc: 0.4586 - val_loss: 6.1234 - val_acc: 0.1933\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3605 - acc: 0.4543 - val_loss: 6.1113 - val_acc: 0.1933\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3610 - acc: 0.4657 - val_loss: 6.1235 - val_acc: 0.1933\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3598 - acc: 0.4586 - val_loss: 6.1235 - val_acc: 0.1933\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3606 - acc: 0.4529 - val_loss: 6.1236 - val_acc: 0.1933\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3604 - acc: 0.4514 - val_loss: 6.1236 - val_acc: 0.1933\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3601 - acc: 0.4600 - val_loss: 6.0749 - val_acc: 0.1933\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3600 - acc: 0.4629 - val_loss: 6.1237 - val_acc: 0.1933\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3605 - acc: 0.4571 - val_loss: 6.1237 - val_acc: 0.1933\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3599 - acc: 0.4557 - val_loss: 6.1237 - val_acc: 0.1933\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3590 - acc: 0.4586 - val_loss: 6.0796 - val_acc: 0.1933\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3593 - acc: 0.4614 - val_loss: 6.1238 - val_acc: 0.1933\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3596 - acc: 0.4557 - val_loss: 6.1238 - val_acc: 0.1933\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3597 - acc: 0.4686 - val_loss: 6.1238 - val_acc: 0.1933\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3583 - acc: 0.4571 - val_loss: 6.1239 - val_acc: 0.1933\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3592 - acc: 0.4586 - val_loss: 6.0978 - val_acc: 0.1933\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3595 - acc: 0.4557 - val_loss: 6.1240 - val_acc: 0.1933\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3590 - acc: 0.4643 - val_loss: 6.1240 - val_acc: 0.1933\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3588 - acc: 0.4614 - val_loss: 6.1240 - val_acc: 0.1933\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3589 - acc: 0.4557 - val_loss: 6.1241 - val_acc: 0.1933\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3588 - acc: 0.4614 - val_loss: 6.1241 - val_acc: 0.1933\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3576 - acc: 0.4586 - val_loss: 6.1241 - val_acc: 0.1933\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3576 - acc: 0.4629 - val_loss: 6.1152 - val_acc: 0.1933\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3589 - acc: 0.4600 - val_loss: 6.1242 - val_acc: 0.1933\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3586 - acc: 0.4600 - val_loss: 6.1242 - val_acc: 0.1933\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3587 - acc: 0.4571 - val_loss: 6.1213 - val_acc: 0.1933\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3585 - acc: 0.4643 - val_loss: 6.1243 - val_acc: 0.1933\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3582 - acc: 0.4529 - val_loss: 6.1243 - val_acc: 0.1933\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3580 - acc: 0.4629 - val_loss: 6.1243 - val_acc: 0.1933\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3576 - acc: 0.4529 - val_loss: 6.1244 - val_acc: 0.1933\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3577 - acc: 0.4643 - val_loss: 6.1244 - val_acc: 0.1933\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3576 - acc: 0.4571 - val_loss: 6.1244 - val_acc: 0.1933\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3566 - acc: 0.4657 - val_loss: 6.1245 - val_acc: 0.1933\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3573 - acc: 0.4571 - val_loss: 6.1245 - val_acc: 0.1933\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3574 - acc: 0.4600 - val_loss: 6.1245 - val_acc: 0.1933\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3571 - acc: 0.4657 - val_loss: 6.1246 - val_acc: 0.1933\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3570 - acc: 0.4600 - val_loss: 6.1246 - val_acc: 0.1933\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3573 - acc: 0.4614 - val_loss: 6.1246 - val_acc: 0.1933\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3574 - acc: 0.4629 - val_loss: 6.1247 - val_acc: 0.1933\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3580 - acc: 0.4643 - val_loss: 6.0820 - val_acc: 0.1933\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3564 - acc: 0.4657 - val_loss: 6.1247 - val_acc: 0.1933\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3572 - acc: 0.4629 - val_loss: 6.1248 - val_acc: 0.1933\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3563 - acc: 0.4557 - val_loss: 6.1248 - val_acc: 0.1933\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3548 - acc: 0.4614 - val_loss: 6.1248 - val_acc: 0.1933\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3568 - acc: 0.4614 - val_loss: 6.1249 - val_acc: 0.1933\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3560 - acc: 0.4586 - val_loss: 6.0822 - val_acc: 0.1933\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 134us/step - loss: 1.3567 - acc: 0.4614 - val_loss: 6.1249 - val_acc: 0.1933\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3555 - acc: 0.4629 - val_loss: 6.1250 - val_acc: 0.1933\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3568 - acc: 0.4586 - val_loss: 6.1250 - val_acc: 0.1933\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3561 - acc: 0.4629 - val_loss: 6.1250 - val_acc: 0.1933\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3556 - acc: 0.4657 - val_loss: 6.1251 - val_acc: 0.1933\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3560 - acc: 0.4571 - val_loss: 6.1251 - val_acc: 0.1933\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3561 - acc: 0.4600 - val_loss: 6.1251 - val_acc: 0.1933\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3555 - acc: 0.4629 - val_loss: 6.1252 - val_acc: 0.1933\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3566 - acc: 0.4614 - val_loss: 6.1252 - val_acc: 0.1933\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3560 - acc: 0.4614 - val_loss: 6.1252 - val_acc: 0.1933\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3557 - acc: 0.4600 - val_loss: 6.1252 - val_acc: 0.1933\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3554 - acc: 0.4686 - val_loss: 6.1253 - val_acc: 0.1933\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3557 - acc: 0.4614 - val_loss: 6.1253 - val_acc: 0.1933\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3546 - acc: 0.4657 - val_loss: 6.1254 - val_acc: 0.1933\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3555 - acc: 0.4557 - val_loss: 6.1254 - val_acc: 0.1933\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3546 - acc: 0.4657 - val_loss: 6.1254 - val_acc: 0.1933\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3553 - acc: 0.4629 - val_loss: 6.1212 - val_acc: 0.1933\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3540 - acc: 0.4657 - val_loss: 6.1255 - val_acc: 0.1933\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3531 - acc: 0.4671 - val_loss: 6.1255 - val_acc: 0.1933\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3547 - acc: 0.4643 - val_loss: 6.0743 - val_acc: 0.1967\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3547 - acc: 0.4671 - val_loss: 6.1256 - val_acc: 0.1933\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3533 - acc: 0.4729 - val_loss: 6.1256 - val_acc: 0.1933\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3538 - acc: 0.4629 - val_loss: 6.1257 - val_acc: 0.1933\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3548 - acc: 0.4614 - val_loss: 6.1257 - val_acc: 0.1933\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3543 - acc: 0.4600 - val_loss: 6.1155 - val_acc: 0.1933\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3540 - acc: 0.4614 - val_loss: 6.1258 - val_acc: 0.1933\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3544 - acc: 0.4629 - val_loss: 6.1258 - val_acc: 0.1933\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3534 - acc: 0.4629 - val_loss: 6.1258 - val_acc: 0.1933\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3552 - acc: 0.4657 - val_loss: 6.1259 - val_acc: 0.1933\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3541 - acc: 0.4586 - val_loss: 6.1259 - val_acc: 0.1933\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3538 - acc: 0.4643 - val_loss: 6.1260 - val_acc: 0.1933\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3522 - acc: 0.4614 - val_loss: 6.1260 - val_acc: 0.1933\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3526 - acc: 0.4643 - val_loss: 6.1260 - val_acc: 0.1933\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3535 - acc: 0.4600 - val_loss: 6.1261 - val_acc: 0.1933\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3531 - acc: 0.4671 - val_loss: 6.1261 - val_acc: 0.1933\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3517 - acc: 0.4700 - val_loss: 6.1261 - val_acc: 0.1933\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3533 - acc: 0.4714 - val_loss: 6.1261 - val_acc: 0.1933\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3527 - acc: 0.4671 - val_loss: 6.1262 - val_acc: 0.1933\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3531 - acc: 0.4629 - val_loss: 6.1262 - val_acc: 0.1933\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3527 - acc: 0.4586 - val_loss: 6.1262 - val_acc: 0.1933\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3519 - acc: 0.4671 - val_loss: 6.1263 - val_acc: 0.1933\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3527 - acc: 0.4614 - val_loss: 6.1263 - val_acc: 0.1933\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3530 - acc: 0.4643 - val_loss: 6.1263 - val_acc: 0.1933\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3516 - acc: 0.4586 - val_loss: 6.1264 - val_acc: 0.1933\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3519 - acc: 0.4657 - val_loss: 6.1264 - val_acc: 0.1933\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3534 - acc: 0.4586 - val_loss: 6.1264 - val_acc: 0.1933\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3526 - acc: 0.4629 - val_loss: 6.1265 - val_acc: 0.1933\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3516 - acc: 0.4714 - val_loss: 6.1265 - val_acc: 0.1933\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3532 - acc: 0.4643 - val_loss: 6.1265 - val_acc: 0.1933\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3519 - acc: 0.4671 - val_loss: 6.1266 - val_acc: 0.1933\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3528 - acc: 0.4686 - val_loss: 6.1266 - val_acc: 0.1933\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3514 - acc: 0.4671 - val_loss: 6.1266 - val_acc: 0.1933\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3515 - acc: 0.4729 - val_loss: 6.1266 - val_acc: 0.1933\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3517 - acc: 0.4586 - val_loss: 6.1267 - val_acc: 0.1933\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3510 - acc: 0.4700 - val_loss: 6.1267 - val_acc: 0.1933\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3514 - acc: 0.4671 - val_loss: 6.1267 - val_acc: 0.1933\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3511 - acc: 0.4686 - val_loss: 6.1268 - val_acc: 0.1933\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3510 - acc: 0.4629 - val_loss: 6.1268 - val_acc: 0.1933\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3512 - acc: 0.4657 - val_loss: 6.1268 - val_acc: 0.1933\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 115us/step - loss: 1.3504 - acc: 0.4700 - val_loss: 6.1039 - val_acc: 0.1933\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3511 - acc: 0.4643 - val_loss: 6.1269 - val_acc: 0.1933\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3508 - acc: 0.4714 - val_loss: 6.1269 - val_acc: 0.1933\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3505 - acc: 0.4643 - val_loss: 6.1269 - val_acc: 0.1933\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3508 - acc: 0.4714 - val_loss: 6.1270 - val_acc: 0.1933\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3505 - acc: 0.4657 - val_loss: 6.1270 - val_acc: 0.1933\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3502 - acc: 0.4714 - val_loss: 6.1271 - val_acc: 0.1933\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3494 - acc: 0.4671 - val_loss: 6.1271 - val_acc: 0.1933\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3504 - acc: 0.4629 - val_loss: 6.1271 - val_acc: 0.1933\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3503 - acc: 0.4700 - val_loss: 6.1272 - val_acc: 0.1933\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3503 - acc: 0.4657 - val_loss: 6.1272 - val_acc: 0.1933\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3498 - acc: 0.4671 - val_loss: 6.1272 - val_acc: 0.1933\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3503 - acc: 0.4643 - val_loss: 6.1273 - val_acc: 0.1933\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3501 - acc: 0.4700 - val_loss: 6.1210 - val_acc: 0.1933\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3502 - acc: 0.4629 - val_loss: 6.1273 - val_acc: 0.1933\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3500 - acc: 0.4671 - val_loss: 6.1274 - val_acc: 0.1933\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3503 - acc: 0.4686 - val_loss: 6.1274 - val_acc: 0.1933\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3495 - acc: 0.4686 - val_loss: 6.1274 - val_acc: 0.1933\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3497 - acc: 0.4671 - val_loss: 6.1274 - val_acc: 0.1933\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3489 - acc: 0.4629 - val_loss: 6.1275 - val_acc: 0.1933\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3495 - acc: 0.4714 - val_loss: 6.1275 - val_acc: 0.1933\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3484 - acc: 0.4643 - val_loss: 6.1275 - val_acc: 0.1933\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3492 - acc: 0.4657 - val_loss: 6.1276 - val_acc: 0.1933\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3477 - acc: 0.4657 - val_loss: 6.1276 - val_acc: 0.1933\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3492 - acc: 0.4629 - val_loss: 6.1276 - val_acc: 0.1933\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3481 - acc: 0.4657 - val_loss: 6.1277 - val_acc: 0.1933\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3486 - acc: 0.4657 - val_loss: 6.1277 - val_acc: 0.1933\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3489 - acc: 0.4671 - val_loss: 6.1277 - val_acc: 0.1933\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3478 - acc: 0.4729 - val_loss: 6.1277 - val_acc: 0.1933\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3488 - acc: 0.4657 - val_loss: 6.1278 - val_acc: 0.1933\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3494 - acc: 0.4643 - val_loss: 6.1278 - val_acc: 0.1933\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3479 - acc: 0.4629 - val_loss: 6.1278 - val_acc: 0.1933\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3477 - acc: 0.4643 - val_loss: 6.1279 - val_acc: 0.1933\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3482 - acc: 0.4686 - val_loss: 6.1279 - val_acc: 0.1933\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3466 - acc: 0.4729 - val_loss: 6.1279 - val_acc: 0.1933\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3476 - acc: 0.4729 - val_loss: 6.1279 - val_acc: 0.1933\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3488 - acc: 0.4686 - val_loss: 6.1280 - val_acc: 0.1933\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3489 - acc: 0.4729 - val_loss: 6.1280 - val_acc: 0.1933\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3478 - acc: 0.4643 - val_loss: 6.1280 - val_acc: 0.1933\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3479 - acc: 0.4671 - val_loss: 6.1281 - val_acc: 0.1933\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3483 - acc: 0.4686 - val_loss: 6.1281 - val_acc: 0.1933\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3478 - acc: 0.4700 - val_loss: 6.1281 - val_acc: 0.1933\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3481 - acc: 0.4686 - val_loss: 6.1282 - val_acc: 0.1933\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3476 - acc: 0.4729 - val_loss: 6.1282 - val_acc: 0.1933\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3467 - acc: 0.4571 - val_loss: 6.1282 - val_acc: 0.1933\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3471 - acc: 0.4671 - val_loss: 6.1283 - val_acc: 0.1933\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3476 - acc: 0.4614 - val_loss: 6.1283 - val_acc: 0.1933\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3474 - acc: 0.4671 - val_loss: 6.1277 - val_acc: 0.1933\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3471 - acc: 0.4686 - val_loss: 6.1247 - val_acc: 0.1933\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3461 - acc: 0.4700 - val_loss: 6.0795 - val_acc: 0.1933\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3470 - acc: 0.4686 - val_loss: 6.1284 - val_acc: 0.1933\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3467 - acc: 0.4643 - val_loss: 6.1285 - val_acc: 0.1933\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3457 - acc: 0.4657 - val_loss: 6.1285 - val_acc: 0.1933\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3473 - acc: 0.4643 - val_loss: 6.1285 - val_acc: 0.1933\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3472 - acc: 0.4700 - val_loss: 6.1286 - val_acc: 0.1933\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3460 - acc: 0.4686 - val_loss: 6.1286 - val_acc: 0.1933\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3463 - acc: 0.4671 - val_loss: 6.1286 - val_acc: 0.1933\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3459 - acc: 0.4643 - val_loss: 6.1192 - val_acc: 0.1933\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3467 - acc: 0.4657 - val_loss: 6.1287 - val_acc: 0.1933\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 102us/step - loss: 1.3458 - acc: 0.4729 - val_loss: 6.1287 - val_acc: 0.1933\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3457 - acc: 0.4729 - val_loss: 6.1288 - val_acc: 0.1933\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3463 - acc: 0.4657 - val_loss: 6.1288 - val_acc: 0.1933\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3464 - acc: 0.4671 - val_loss: 6.1288 - val_acc: 0.1933\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3446 - acc: 0.4671 - val_loss: 6.1288 - val_acc: 0.1933\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3462 - acc: 0.4643 - val_loss: 6.1289 - val_acc: 0.1933\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3465 - acc: 0.4729 - val_loss: 6.1289 - val_acc: 0.1933\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3451 - acc: 0.4671 - val_loss: 6.1290 - val_acc: 0.1933\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3449 - acc: 0.4714 - val_loss: 6.1290 - val_acc: 0.1933\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3454 - acc: 0.4686 - val_loss: 6.1290 - val_acc: 0.1933\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3450 - acc: 0.4686 - val_loss: 6.0864 - val_acc: 0.1933\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3454 - acc: 0.4714 - val_loss: 6.1291 - val_acc: 0.1933\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3447 - acc: 0.4686 - val_loss: 6.1291 - val_acc: 0.1933\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3453 - acc: 0.4700 - val_loss: 6.1291 - val_acc: 0.1933\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3452 - acc: 0.4714 - val_loss: 6.1292 - val_acc: 0.1933\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3447 - acc: 0.4729 - val_loss: 6.1292 - val_acc: 0.1933\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3429 - acc: 0.4729 - val_loss: 6.1292 - val_acc: 0.1933\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3441 - acc: 0.4671 - val_loss: 6.1293 - val_acc: 0.1933\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3448 - acc: 0.4729 - val_loss: 6.0803 - val_acc: 0.1933\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3443 - acc: 0.4629 - val_loss: 6.1293 - val_acc: 0.1933\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3445 - acc: 0.4657 - val_loss: 6.1293 - val_acc: 0.1933\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3451 - acc: 0.4686 - val_loss: 6.1294 - val_acc: 0.1933\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3444 - acc: 0.4757 - val_loss: 6.0781 - val_acc: 0.1967\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3431 - acc: 0.4686 - val_loss: 6.1294 - val_acc: 0.1933\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3443 - acc: 0.4629 - val_loss: 6.1295 - val_acc: 0.1933\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3443 - acc: 0.4714 - val_loss: 6.1295 - val_acc: 0.1933\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3431 - acc: 0.4671 - val_loss: 6.1295 - val_acc: 0.1933\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3438 - acc: 0.4671 - val_loss: 6.0869 - val_acc: 0.1933\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3435 - acc: 0.4671 - val_loss: 6.1296 - val_acc: 0.1933\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3429 - acc: 0.4686 - val_loss: 6.1296 - val_acc: 0.1933\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3435 - acc: 0.4714 - val_loss: 6.0870 - val_acc: 0.1933\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3438 - acc: 0.4729 - val_loss: 6.0870 - val_acc: 0.1933\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3437 - acc: 0.4600 - val_loss: 6.1297 - val_acc: 0.1933\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3430 - acc: 0.4643 - val_loss: 6.0982 - val_acc: 0.1933\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3438 - acc: 0.4643 - val_loss: 6.1297 - val_acc: 0.1933\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3434 - acc: 0.4657 - val_loss: 6.1245 - val_acc: 0.1933\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3429 - acc: 0.4700 - val_loss: 6.1298 - val_acc: 0.1933\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3430 - acc: 0.4657 - val_loss: 6.1298 - val_acc: 0.1933\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3432 - acc: 0.4757 - val_loss: 6.1299 - val_acc: 0.1933\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3431 - acc: 0.4700 - val_loss: 6.1299 - val_acc: 0.1933\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3428 - acc: 0.4657 - val_loss: 6.0873 - val_acc: 0.1933\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3423 - acc: 0.4714 - val_loss: 6.0788 - val_acc: 0.1967\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3433 - acc: 0.4743 - val_loss: 6.1300 - val_acc: 0.1933\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3431 - acc: 0.4671 - val_loss: 6.1246 - val_acc: 0.1933\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3423 - acc: 0.4771 - val_loss: 6.1301 - val_acc: 0.1933\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3421 - acc: 0.4714 - val_loss: 6.1301 - val_acc: 0.1933\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3424 - acc: 0.4671 - val_loss: 6.1215 - val_acc: 0.1933\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3422 - acc: 0.4700 - val_loss: 6.1131 - val_acc: 0.1933\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3415 - acc: 0.4686 - val_loss: 6.0876 - val_acc: 0.1933\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3424 - acc: 0.4729 - val_loss: 6.0876 - val_acc: 0.1933\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3421 - acc: 0.4714 - val_loss: 6.1303 - val_acc: 0.1933\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3418 - acc: 0.4657 - val_loss: 6.1303 - val_acc: 0.1933\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3416 - acc: 0.4671 - val_loss: 6.1303 - val_acc: 0.1933\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3428 - acc: 0.4700 - val_loss: 6.1304 - val_acc: 0.1933\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3424 - acc: 0.4657 - val_loss: 6.1304 - val_acc: 0.1933\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3413 - acc: 0.4714 - val_loss: 6.1304 - val_acc: 0.1933\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3416 - acc: 0.4729 - val_loss: 6.1304 - val_acc: 0.1933\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3407 - acc: 0.4743 - val_loss: 6.1305 - val_acc: 0.1933\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3413 - acc: 0.4643 - val_loss: 6.1305 - val_acc: 0.1933\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 1.3404 - acc: 0.4729 - val_loss: 6.1305 - val_acc: 0.1933\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3412 - acc: 0.4686 - val_loss: 6.1298 - val_acc: 0.1933\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3406 - acc: 0.4729 - val_loss: 6.1306 - val_acc: 0.1933\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3415 - acc: 0.4743 - val_loss: 6.1306 - val_acc: 0.1933\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3413 - acc: 0.4729 - val_loss: 6.1307 - val_acc: 0.1933\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3413 - acc: 0.4629 - val_loss: 6.1307 - val_acc: 0.1933\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3406 - acc: 0.4714 - val_loss: 6.0463 - val_acc: 0.1933\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3400 - acc: 0.4643 - val_loss: 6.0882 - val_acc: 0.1933\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3406 - acc: 0.4743 - val_loss: 6.1308 - val_acc: 0.1933\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3414 - acc: 0.4700 - val_loss: 6.1308 - val_acc: 0.1933\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3404 - acc: 0.4657 - val_loss: 6.1308 - val_acc: 0.1933\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3405 - acc: 0.4700 - val_loss: 6.0795 - val_acc: 0.1967\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3403 - acc: 0.4743 - val_loss: 6.1309 - val_acc: 0.1933\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3404 - acc: 0.4729 - val_loss: 6.1310 - val_acc: 0.1933\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3401 - acc: 0.4671 - val_loss: 6.1310 - val_acc: 0.1933\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3397 - acc: 0.4700 - val_loss: 6.1310 - val_acc: 0.1933\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3408 - acc: 0.4729 - val_loss: 6.1310 - val_acc: 0.1933\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3395 - acc: 0.4771 - val_loss: 6.1310 - val_acc: 0.1933\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3396 - acc: 0.4629 - val_loss: 6.1311 - val_acc: 0.1933\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3390 - acc: 0.4743 - val_loss: 6.1301 - val_acc: 0.1933\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3391 - acc: 0.4686 - val_loss: 6.0808 - val_acc: 0.1967\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3394 - acc: 0.4729 - val_loss: 6.1312 - val_acc: 0.1933\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3400 - acc: 0.4714 - val_loss: 6.1312 - val_acc: 0.1933\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3396 - acc: 0.4671 - val_loss: 6.1312 - val_acc: 0.1933\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3401 - acc: 0.4743 - val_loss: 6.0419 - val_acc: 0.1933\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3395 - acc: 0.4757 - val_loss: 6.1313 - val_acc: 0.1933\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3396 - acc: 0.4714 - val_loss: 6.1313 - val_acc: 0.1933\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3384 - acc: 0.4800 - val_loss: 6.1314 - val_acc: 0.1933\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3391 - acc: 0.4714 - val_loss: 6.0900 - val_acc: 0.1933\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3391 - acc: 0.4743 - val_loss: 6.1314 - val_acc: 0.1933\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3391 - acc: 0.4700 - val_loss: 6.0888 - val_acc: 0.1933\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3380 - acc: 0.4714 - val_loss: 6.0860 - val_acc: 0.1933\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3383 - acc: 0.4743 - val_loss: 6.1315 - val_acc: 0.1933\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3390 - acc: 0.4729 - val_loss: 6.1315 - val_acc: 0.1933\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3391 - acc: 0.4671 - val_loss: 6.1316 - val_acc: 0.1933\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3381 - acc: 0.4714 - val_loss: 6.0890 - val_acc: 0.1933\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3385 - acc: 0.4686 - val_loss: 6.0890 - val_acc: 0.1933\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3379 - acc: 0.4714 - val_loss: 6.0804 - val_acc: 0.1967\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3385 - acc: 0.4657 - val_loss: 6.1317 - val_acc: 0.1933\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3376 - acc: 0.4757 - val_loss: 6.1317 - val_acc: 0.1933\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3384 - acc: 0.4700 - val_loss: 6.1318 - val_acc: 0.1933\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3382 - acc: 0.4757 - val_loss: 6.0892 - val_acc: 0.1933\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3372 - acc: 0.4771 - val_loss: 6.1796 - val_acc: 0.1933\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3383 - acc: 0.4671 - val_loss: 6.1318 - val_acc: 0.1933\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3376 - acc: 0.4757 - val_loss: 6.0843 - val_acc: 0.1933\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3394 - acc: 0.4643 - val_loss: 6.0893 - val_acc: 0.1933\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3371 - acc: 0.4800 - val_loss: 6.1319 - val_acc: 0.1933\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3382 - acc: 0.4729 - val_loss: 6.1320 - val_acc: 0.1933\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3373 - acc: 0.4743 - val_loss: 6.1798 - val_acc: 0.1933\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3383 - acc: 0.4729 - val_loss: 6.1320 - val_acc: 0.1933\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3371 - acc: 0.4743 - val_loss: 6.1798 - val_acc: 0.1933\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3372 - acc: 0.4729 - val_loss: 6.1321 - val_acc: 0.1933\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3361 - acc: 0.4829 - val_loss: 6.1321 - val_acc: 0.1933\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3378 - acc: 0.4714 - val_loss: 6.1308 - val_acc: 0.1933\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3371 - acc: 0.4729 - val_loss: 6.0822 - val_acc: 0.1967\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3370 - acc: 0.4714 - val_loss: 6.1322 - val_acc: 0.1933\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3368 - acc: 0.4757 - val_loss: 6.1322 - val_acc: 0.1933\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3365 - acc: 0.4700 - val_loss: 6.1323 - val_acc: 0.1933\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3361 - acc: 0.4714 - val_loss: 6.1323 - val_acc: 0.1933\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 1.3373 - acc: 0.4714 - val_loss: 6.1323 - val_acc: 0.1933\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3370 - acc: 0.4743 - val_loss: 6.1801 - val_acc: 0.1933\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3367 - acc: 0.4743 - val_loss: 6.1324 - val_acc: 0.1933\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3369 - acc: 0.4729 - val_loss: 6.0976 - val_acc: 0.1933\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3365 - acc: 0.4714 - val_loss: 6.1802 - val_acc: 0.1933\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3368 - acc: 0.4657 - val_loss: 6.1325 - val_acc: 0.1933\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3350 - acc: 0.4700 - val_loss: 6.1325 - val_acc: 0.1933\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3360 - acc: 0.4700 - val_loss: 6.1325 - val_acc: 0.1933\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3355 - acc: 0.4743 - val_loss: 6.1326 - val_acc: 0.1933\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3362 - acc: 0.4729 - val_loss: 6.1011 - val_acc: 0.1933\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3353 - acc: 0.4729 - val_loss: 6.1326 - val_acc: 0.1933\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3357 - acc: 0.4729 - val_loss: 6.1225 - val_acc: 0.1933\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3357 - acc: 0.4686 - val_loss: 6.1327 - val_acc: 0.1933\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3359 - acc: 0.4729 - val_loss: 6.1327 - val_acc: 0.1933\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3355 - acc: 0.4743 - val_loss: 6.1805 - val_acc: 0.1933\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3354 - acc: 0.4729 - val_loss: 6.1327 - val_acc: 0.1933\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3349 - acc: 0.4743 - val_loss: 6.1805 - val_acc: 0.1933\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3349 - acc: 0.4771 - val_loss: 6.1328 - val_acc: 0.1933\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3354 - acc: 0.4700 - val_loss: 6.0849 - val_acc: 0.1933\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3351 - acc: 0.4700 - val_loss: 6.1329 - val_acc: 0.1933\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3358 - acc: 0.4700 - val_loss: 6.1329 - val_acc: 0.1933\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3357 - acc: 0.4714 - val_loss: 6.1329 - val_acc: 0.1933\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3340 - acc: 0.4786 - val_loss: 6.1330 - val_acc: 0.1933\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3342 - acc: 0.4743 - val_loss: 6.1330 - val_acc: 0.1933\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3337 - acc: 0.4800 - val_loss: 6.1808 - val_acc: 0.1933\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3358 - acc: 0.4743 - val_loss: 6.1330 - val_acc: 0.1933\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3347 - acc: 0.4771 - val_loss: 6.1331 - val_acc: 0.1933\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3339 - acc: 0.4743 - val_loss: 6.1331 - val_acc: 0.1933\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3346 - acc: 0.4829 - val_loss: 6.1331 - val_acc: 0.1933\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3340 - acc: 0.4771 - val_loss: 6.1810 - val_acc: 0.1933\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3342 - acc: 0.4671 - val_loss: 6.1332 - val_acc: 0.1933\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3344 - acc: 0.4643 - val_loss: 6.1333 - val_acc: 0.1933\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3325 - acc: 0.4786 - val_loss: 6.1811 - val_acc: 0.1933\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3346 - acc: 0.4714 - val_loss: 6.1333 - val_acc: 0.1933\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3338 - acc: 0.4786 - val_loss: 6.1298 - val_acc: 0.1933\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3344 - acc: 0.4729 - val_loss: 6.1378 - val_acc: 0.1933\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3339 - acc: 0.4743 - val_loss: 6.1542 - val_acc: 0.1933\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3327 - acc: 0.4743 - val_loss: 6.1334 - val_acc: 0.1933\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3345 - acc: 0.4743 - val_loss: 6.1335 - val_acc: 0.1933\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3344 - acc: 0.4757 - val_loss: 6.1335 - val_acc: 0.1933\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3335 - acc: 0.4729 - val_loss: 6.1813 - val_acc: 0.1933\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3327 - acc: 0.4714 - val_loss: 6.1335 - val_acc: 0.1933\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3338 - acc: 0.4800 - val_loss: 6.1806 - val_acc: 0.1933\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3333 - acc: 0.4729 - val_loss: 6.1810 - val_acc: 0.1933\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3328 - acc: 0.4757 - val_loss: 6.1337 - val_acc: 0.1933\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3333 - acc: 0.4700 - val_loss: 6.1337 - val_acc: 0.1933\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3303 - acc: 0.4743 - val_loss: 6.1337 - val_acc: 0.1933\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3324 - acc: 0.4743 - val_loss: 6.1815 - val_acc: 0.1933\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3335 - acc: 0.4743 - val_loss: 6.1100 - val_acc: 0.1933\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3321 - acc: 0.4814 - val_loss: 6.1816 - val_acc: 0.1933\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3330 - acc: 0.4786 - val_loss: 6.0859 - val_acc: 0.1933\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3340 - acc: 0.4771 - val_loss: 6.1338 - val_acc: 0.1933\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3332 - acc: 0.4786 - val_loss: 6.1339 - val_acc: 0.1933\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3313 - acc: 0.4671 - val_loss: 6.0913 - val_acc: 0.1933\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3323 - acc: 0.4714 - val_loss: 6.0349 - val_acc: 0.1967\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3326 - acc: 0.4757 - val_loss: 6.0650 - val_acc: 0.1933\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3325 - acc: 0.4771 - val_loss: 6.1818 - val_acc: 0.1933\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3327 - acc: 0.4714 - val_loss: 6.1622 - val_acc: 0.1933\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3326 - acc: 0.4700 - val_loss: 6.1340 - val_acc: 0.1933\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.3315 - acc: 0.4729 - val_loss: 6.1819 - val_acc: 0.1933\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3305 - acc: 0.4757 - val_loss: 6.1819 - val_acc: 0.1933\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3330 - acc: 0.4800 - val_loss: 6.1819 - val_acc: 0.1933\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3324 - acc: 0.4771 - val_loss: 6.1069 - val_acc: 0.1933\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3317 - acc: 0.4757 - val_loss: 6.1820 - val_acc: 0.1933\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3318 - acc: 0.4729 - val_loss: 6.1820 - val_acc: 0.1933\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3327 - acc: 0.4729 - val_loss: 6.1820 - val_acc: 0.1933\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3316 - acc: 0.4714 - val_loss: 6.0569 - val_acc: 0.1933\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3319 - acc: 0.4757 - val_loss: 6.1343 - val_acc: 0.1933\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3308 - acc: 0.4729 - val_loss: 6.1668 - val_acc: 0.1933\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3313 - acc: 0.4757 - val_loss: 6.1344 - val_acc: 0.1933\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3301 - acc: 0.4757 - val_loss: 6.1822 - val_acc: 0.1933\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3314 - acc: 0.4657 - val_loss: 6.0439 - val_acc: 0.1933\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3307 - acc: 0.4743 - val_loss: 6.1823 - val_acc: 0.1933\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3317 - acc: 0.4771 - val_loss: 6.1823 - val_acc: 0.1933\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3308 - acc: 0.4743 - val_loss: 6.1823 - val_acc: 0.1933\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3310 - acc: 0.4643 - val_loss: 6.0920 - val_acc: 0.1933\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3300 - acc: 0.4700 - val_loss: 6.0547 - val_acc: 0.1933\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3318 - acc: 0.4757 - val_loss: 6.1403 - val_acc: 0.1933\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3299 - acc: 0.4743 - val_loss: 6.1824 - val_acc: 0.1933\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3301 - acc: 0.4700 - val_loss: 6.0973 - val_acc: 0.1933\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3319 - acc: 0.4714 - val_loss: 6.0885 - val_acc: 0.1933\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3305 - acc: 0.4829 - val_loss: 6.1347 - val_acc: 0.1933\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3299 - acc: 0.4729 - val_loss: 6.0646 - val_acc: 0.1933\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3304 - acc: 0.4714 - val_loss: 6.0381 - val_acc: 0.1933\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3296 - acc: 0.4771 - val_loss: 6.0420 - val_acc: 0.1933\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3300 - acc: 0.4771 - val_loss: 6.1826 - val_acc: 0.1933\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3302 - acc: 0.4786 - val_loss: 6.0869 - val_acc: 0.1933\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3298 - acc: 0.4800 - val_loss: 6.0443 - val_acc: 0.1933\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3303 - acc: 0.4786 - val_loss: 6.1827 - val_acc: 0.1933\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3305 - acc: 0.4771 - val_loss: 6.1243 - val_acc: 0.1933\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3297 - acc: 0.4800 - val_loss: 6.0870 - val_acc: 0.1933\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3296 - acc: 0.4729 - val_loss: 6.1828 - val_acc: 0.1933\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3301 - acc: 0.4729 - val_loss: 6.1349 - val_acc: 0.1933\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3301 - acc: 0.4757 - val_loss: 6.1349 - val_acc: 0.1933\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3293 - acc: 0.4743 - val_loss: 6.1829 - val_acc: 0.1933\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3299 - acc: 0.4686 - val_loss: 6.1829 - val_acc: 0.1933\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3300 - acc: 0.4743 - val_loss: 6.1350 - val_acc: 0.1933\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3289 - acc: 0.4700 - val_loss: 6.1350 - val_acc: 0.1933\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3297 - acc: 0.4729 - val_loss: 6.1830 - val_acc: 0.1933\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3290 - acc: 0.4729 - val_loss: 6.1830 - val_acc: 0.1933\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3290 - acc: 0.4743 - val_loss: 6.0386 - val_acc: 0.1933\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3295 - acc: 0.4786 - val_loss: 6.1024 - val_acc: 0.1933\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3289 - acc: 0.4729 - val_loss: 6.1091 - val_acc: 0.1933\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3292 - acc: 0.4700 - val_loss: 6.1831 - val_acc: 0.1933\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3286 - acc: 0.4786 - val_loss: 6.1354 - val_acc: 0.1933\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3282 - acc: 0.4786 - val_loss: 6.1832 - val_acc: 0.1933\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3284 - acc: 0.4771 - val_loss: 6.1832 - val_acc: 0.1933\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3293 - acc: 0.4829 - val_loss: 6.1401 - val_acc: 0.1933\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3289 - acc: 0.4714 - val_loss: 6.0894 - val_acc: 0.1933\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3282 - acc: 0.4786 - val_loss: 6.0450 - val_acc: 0.1933\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3291 - acc: 0.4786 - val_loss: 6.1833 - val_acc: 0.1933\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3283 - acc: 0.4743 - val_loss: 6.0450 - val_acc: 0.1933\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3288 - acc: 0.4771 - val_loss: 6.1834 - val_acc: 0.1933\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3275 - acc: 0.4714 - val_loss: 6.1355 - val_acc: 0.1933\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3269 - acc: 0.4800 - val_loss: 6.1834 - val_acc: 0.1933\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3278 - acc: 0.4743 - val_loss: 6.1835 - val_acc: 0.1933\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3291 - acc: 0.4814 - val_loss: 6.1660 - val_acc: 0.1933\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3273 - acc: 0.4743 - val_loss: 6.1356 - val_acc: 0.1933\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 118us/step - loss: 1.3279 - acc: 0.4757 - val_loss: 6.1835 - val_acc: 0.1933\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3275 - acc: 0.4771 - val_loss: 6.1069 - val_acc: 0.1933\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3285 - acc: 0.4829 - val_loss: 6.0931 - val_acc: 0.1933\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3277 - acc: 0.4829 - val_loss: 6.1357 - val_acc: 0.1933\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3271 - acc: 0.4771 - val_loss: 6.0460 - val_acc: 0.1933\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3278 - acc: 0.4771 - val_loss: 6.0932 - val_acc: 0.1933\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3268 - acc: 0.4700 - val_loss: 6.0932 - val_acc: 0.1933\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3270 - acc: 0.4800 - val_loss: 6.1837 - val_acc: 0.1933\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3284 - acc: 0.4771 - val_loss: 6.1838 - val_acc: 0.1933\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3273 - acc: 0.4743 - val_loss: 6.0933 - val_acc: 0.1933\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3265 - acc: 0.4786 - val_loss: 6.1838 - val_acc: 0.1933\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3266 - acc: 0.4743 - val_loss: 6.1351 - val_acc: 0.1933\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3258 - acc: 0.4757 - val_loss: 6.1359 - val_acc: 0.1933\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3268 - acc: 0.4743 - val_loss: 6.0934 - val_acc: 0.1933\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3262 - acc: 0.4800 - val_loss: 6.1839 - val_acc: 0.1933\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3268 - acc: 0.4771 - val_loss: 6.1332 - val_acc: 0.1933\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3265 - acc: 0.4757 - val_loss: 6.1840 - val_acc: 0.1933\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3262 - acc: 0.4800 - val_loss: 6.1840 - val_acc: 0.1933\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3264 - acc: 0.4829 - val_loss: 6.1314 - val_acc: 0.1933\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3251 - acc: 0.4829 - val_loss: 6.1840 - val_acc: 0.1933\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3263 - acc: 0.4757 - val_loss: 6.1361 - val_acc: 0.1933\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3262 - acc: 0.4771 - val_loss: 6.1511 - val_acc: 0.1933\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3256 - acc: 0.4786 - val_loss: 6.1362 - val_acc: 0.1933\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3254 - acc: 0.4714 - val_loss: 6.1362 - val_acc: 0.1933\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3251 - acc: 0.4814 - val_loss: 6.1589 - val_acc: 0.1933\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3261 - acc: 0.4771 - val_loss: 6.1917 - val_acc: 0.1933\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3247 - acc: 0.4786 - val_loss: 6.1668 - val_acc: 0.1933\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3241 - acc: 0.4743 - val_loss: 6.0937 - val_acc: 0.1933\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3257 - acc: 0.4786 - val_loss: 6.1605 - val_acc: 0.1933\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3250 - acc: 0.4757 - val_loss: 6.0938 - val_acc: 0.1933\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3244 - acc: 0.4786 - val_loss: 6.0938 - val_acc: 0.1933\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3244 - acc: 0.4757 - val_loss: 6.1303 - val_acc: 0.1933\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3242 - acc: 0.4829 - val_loss: 6.1844 - val_acc: 0.1933\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3247 - acc: 0.4714 - val_loss: 6.1844 - val_acc: 0.1933\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3252 - acc: 0.4714 - val_loss: 6.1413 - val_acc: 0.1933\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3245 - acc: 0.4757 - val_loss: 6.1532 - val_acc: 0.1933\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3247 - acc: 0.4743 - val_loss: 6.1366 - val_acc: 0.1933\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3237 - acc: 0.4814 - val_loss: 6.0473 - val_acc: 0.1933\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3241 - acc: 0.4771 - val_loss: 6.0907 - val_acc: 0.1933\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3244 - acc: 0.4786 - val_loss: 6.0898 - val_acc: 0.1933\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3241 - acc: 0.4800 - val_loss: 6.1847 - val_acc: 0.1933\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3243 - acc: 0.4757 - val_loss: 6.1847 - val_acc: 0.1933\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3250 - acc: 0.4743 - val_loss: 6.0942 - val_acc: 0.1933\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3241 - acc: 0.4829 - val_loss: 6.1848 - val_acc: 0.1933\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3239 - acc: 0.4829 - val_loss: 6.1848 - val_acc: 0.1933\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3239 - acc: 0.4771 - val_loss: 6.1369 - val_acc: 0.1933\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3241 - acc: 0.4786 - val_loss: 6.1369 - val_acc: 0.1933\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3232 - acc: 0.4729 - val_loss: 6.0944 - val_acc: 0.1933\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3236 - acc: 0.4800 - val_loss: 6.1079 - val_acc: 0.1933\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3229 - acc: 0.4800 - val_loss: 6.1370 - val_acc: 0.1933\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3238 - acc: 0.4743 - val_loss: 6.1850 - val_acc: 0.1933\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3226 - acc: 0.4771 - val_loss: 6.1850 - val_acc: 0.1933\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3224 - acc: 0.4757 - val_loss: 6.1850 - val_acc: 0.1933\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3229 - acc: 0.4857 - val_loss: 6.1068 - val_acc: 0.1933\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3230 - acc: 0.4843 - val_loss: 6.1972 - val_acc: 0.1933\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3225 - acc: 0.4814 - val_loss: 6.1851 - val_acc: 0.1933\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3233 - acc: 0.4814 - val_loss: 6.1430 - val_acc: 0.1933\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3230 - acc: 0.4800 - val_loss: 6.1852 - val_acc: 0.1933\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3218 - acc: 0.4829 - val_loss: 6.1372 - val_acc: 0.1933\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 116us/step - loss: 1.3229 - acc: 0.4843 - val_loss: 6.0904 - val_acc: 0.1933\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3209 - acc: 0.4814 - val_loss: 6.1829 - val_acc: 0.1933\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3223 - acc: 0.4843 - val_loss: 6.1373 - val_acc: 0.1933\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3235 - acc: 0.4771 - val_loss: 6.1853 - val_acc: 0.1933\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3225 - acc: 0.4814 - val_loss: 6.1095 - val_acc: 0.1933\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3228 - acc: 0.4786 - val_loss: 6.1854 - val_acc: 0.1933\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3226 - acc: 0.4857 - val_loss: 6.1854 - val_acc: 0.1933\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3227 - acc: 0.4814 - val_loss: 6.1375 - val_acc: 0.1933\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3224 - acc: 0.4771 - val_loss: 6.1375 - val_acc: 0.1933\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3222 - acc: 0.4829 - val_loss: 6.1855 - val_acc: 0.1933\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3225 - acc: 0.4757 - val_loss: 6.1494 - val_acc: 0.1933\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3221 - acc: 0.4757 - val_loss: 6.0950 - val_acc: 0.1933\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3218 - acc: 0.4886 - val_loss: 6.1376 - val_acc: 0.1933\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3220 - acc: 0.4814 - val_loss: 6.1376 - val_acc: 0.1933\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3221 - acc: 0.4829 - val_loss: 6.0951 - val_acc: 0.1933\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3222 - acc: 0.4814 - val_loss: 6.1377 - val_acc: 0.1933\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3220 - acc: 0.4786 - val_loss: 6.1856 - val_acc: 0.1933\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3211 - acc: 0.4857 - val_loss: 6.1377 - val_acc: 0.1933\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3220 - acc: 0.4786 - val_loss: 6.0952 - val_acc: 0.1933\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3213 - acc: 0.4814 - val_loss: 6.1344 - val_acc: 0.1933\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3217 - acc: 0.4829 - val_loss: 6.0880 - val_acc: 0.1967\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3221 - acc: 0.4871 - val_loss: 6.1040 - val_acc: 0.1933\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3218 - acc: 0.4814 - val_loss: 6.1378 - val_acc: 0.1933\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3218 - acc: 0.4800 - val_loss: 6.1379 - val_acc: 0.1933\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3211 - acc: 0.4800 - val_loss: 6.1379 - val_acc: 0.1933\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3218 - acc: 0.4771 - val_loss: 6.0954 - val_acc: 0.1933\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3212 - acc: 0.4800 - val_loss: 6.1174 - val_acc: 0.1933\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3207 - acc: 0.4800 - val_loss: 6.1380 - val_acc: 0.1933\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3208 - acc: 0.4829 - val_loss: 6.0938 - val_acc: 0.1933\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3218 - acc: 0.4829 - val_loss: 6.1286 - val_acc: 0.1933\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3209 - acc: 0.4857 - val_loss: 6.1860 - val_acc: 0.1933\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3201 - acc: 0.4829 - val_loss: 6.1381 - val_acc: 0.1933\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3208 - acc: 0.4814 - val_loss: 6.1381 - val_acc: 0.1933\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3202 - acc: 0.4900 - val_loss: 6.0956 - val_acc: 0.1933\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3202 - acc: 0.4829 - val_loss: 6.1862 - val_acc: 0.1933\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3211 - acc: 0.4814 - val_loss: 6.0957 - val_acc: 0.1933\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3212 - acc: 0.4871 - val_loss: 6.0916 - val_acc: 0.1933\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3205 - acc: 0.4786 - val_loss: 6.1383 - val_acc: 0.1933\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3207 - acc: 0.4757 - val_loss: 6.0958 - val_acc: 0.1933\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3202 - acc: 0.4771 - val_loss: 6.1863 - val_acc: 0.1933\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3202 - acc: 0.4743 - val_loss: 6.1291 - val_acc: 0.1933\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3193 - acc: 0.4871 - val_loss: 6.1864 - val_acc: 0.1933\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3206 - acc: 0.4800 - val_loss: 6.1010 - val_acc: 0.1933\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3199 - acc: 0.4814 - val_loss: 6.1218 - val_acc: 0.1933\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3199 - acc: 0.4814 - val_loss: 6.1394 - val_acc: 0.1933\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3200 - acc: 0.4871 - val_loss: 6.0960 - val_acc: 0.1933\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3199 - acc: 0.4814 - val_loss: 6.0960 - val_acc: 0.1933\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3201 - acc: 0.4843 - val_loss: 6.0960 - val_acc: 0.1933\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3191 - acc: 0.4871 - val_loss: 6.2336 - val_acc: 0.1933\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3205 - acc: 0.4829 - val_loss: 6.1302 - val_acc: 0.1933\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3202 - acc: 0.4814 - val_loss: 6.1121 - val_acc: 0.1933\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3194 - acc: 0.4800 - val_loss: 6.1387 - val_acc: 0.1933\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3179 - acc: 0.4843 - val_loss: 6.0899 - val_acc: 0.1933\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3197 - acc: 0.4800 - val_loss: 6.1368 - val_acc: 0.1933\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3192 - acc: 0.4871 - val_loss: 6.1858 - val_acc: 0.1933\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3194 - acc: 0.4786 - val_loss: 6.1388 - val_acc: 0.1933\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3201 - acc: 0.4814 - val_loss: 6.1859 - val_acc: 0.1933\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3187 - acc: 0.4843 - val_loss: 6.1700 - val_acc: 0.1933\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3195 - acc: 0.4800 - val_loss: 6.0964 - val_acc: 0.1933\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 1.3188 - acc: 0.4800 - val_loss: 6.1860 - val_acc: 0.1933\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3188 - acc: 0.4786 - val_loss: 6.1860 - val_acc: 0.1933\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3187 - acc: 0.4857 - val_loss: 6.1372 - val_acc: 0.1933\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3180 - acc: 0.4800 - val_loss: 6.1860 - val_acc: 0.1933\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3185 - acc: 0.4843 - val_loss: 6.1861 - val_acc: 0.1933\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3193 - acc: 0.4857 - val_loss: 6.1391 - val_acc: 0.1933\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3182 - acc: 0.4843 - val_loss: 6.2238 - val_acc: 0.1933\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3168 - acc: 0.4800 - val_loss: 6.1861 - val_acc: 0.1933\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3178 - acc: 0.4800 - val_loss: 6.1381 - val_acc: 0.1933\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3178 - acc: 0.4814 - val_loss: 6.1474 - val_acc: 0.1933\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3171 - acc: 0.4800 - val_loss: 6.1862 - val_acc: 0.1933\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3179 - acc: 0.4814 - val_loss: 6.0493 - val_acc: 0.1933\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3171 - acc: 0.4843 - val_loss: 6.1863 - val_acc: 0.1933\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3178 - acc: 0.4829 - val_loss: 6.1863 - val_acc: 0.1933\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3172 - acc: 0.4829 - val_loss: 6.1863 - val_acc: 0.1933\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3177 - acc: 0.4771 - val_loss: 6.1439 - val_acc: 0.1933\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3173 - acc: 0.4786 - val_loss: 6.2342 - val_acc: 0.1933\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3166 - acc: 0.4786 - val_loss: 6.2082 - val_acc: 0.1933\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3171 - acc: 0.4829 - val_loss: 6.2401 - val_acc: 0.1933\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3168 - acc: 0.4814 - val_loss: 6.1440 - val_acc: 0.1933\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3165 - acc: 0.4843 - val_loss: 6.1365 - val_acc: 0.1967\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3165 - acc: 0.4871 - val_loss: 6.1865 - val_acc: 0.1933\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3167 - acc: 0.4786 - val_loss: 6.0751 - val_acc: 0.1933\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3168 - acc: 0.4814 - val_loss: 6.1866 - val_acc: 0.1933\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3158 - acc: 0.4800 - val_loss: 6.2246 - val_acc: 0.1933\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3167 - acc: 0.4843 - val_loss: 6.1077 - val_acc: 0.1933\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3171 - acc: 0.4829 - val_loss: 6.1866 - val_acc: 0.1933\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3164 - acc: 0.4871 - val_loss: 6.1867 - val_acc: 0.1933\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3163 - acc: 0.4786 - val_loss: 6.2364 - val_acc: 0.1933\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3161 - acc: 0.4857 - val_loss: 6.1870 - val_acc: 0.1933\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3142 - acc: 0.4843 - val_loss: 6.2825 - val_acc: 0.1933\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3160 - acc: 0.4857 - val_loss: 6.1438 - val_acc: 0.1933\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3161 - acc: 0.4857 - val_loss: 6.2826 - val_acc: 0.1933\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3155 - acc: 0.4843 - val_loss: 6.2826 - val_acc: 0.1933\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3157 - acc: 0.4857 - val_loss: 6.2347 - val_acc: 0.1933\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3149 - acc: 0.4771 - val_loss: 6.2347 - val_acc: 0.1933\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3161 - acc: 0.4829 - val_loss: 6.2827 - val_acc: 0.1933\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3154 - acc: 0.4829 - val_loss: 6.2199 - val_acc: 0.1933\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3166 - acc: 0.4843 - val_loss: 6.2348 - val_acc: 0.1933\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3151 - acc: 0.4843 - val_loss: 6.2287 - val_acc: 0.1933\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3153 - acc: 0.4829 - val_loss: 6.2828 - val_acc: 0.1933\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3149 - acc: 0.4929 - val_loss: 6.2828 - val_acc: 0.1933\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3160 - acc: 0.4871 - val_loss: 6.2349 - val_acc: 0.1933\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3154 - acc: 0.4900 - val_loss: 6.2349 - val_acc: 0.1933\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3150 - acc: 0.4857 - val_loss: 6.1446 - val_acc: 0.1933\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.2919 - acc: 0.487 - 0s 119us/step - loss: 1.3148 - acc: 0.4857 - val_loss: 6.2011 - val_acc: 0.1933\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3153 - acc: 0.4843 - val_loss: 6.2754 - val_acc: 0.1933\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3146 - acc: 0.4843 - val_loss: 6.2350 - val_acc: 0.1933\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3144 - acc: 0.4829 - val_loss: 6.2350 - val_acc: 0.1933\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3149 - acc: 0.4814 - val_loss: 6.2830 - val_acc: 0.1933\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3153 - acc: 0.4871 - val_loss: 6.1983 - val_acc: 0.1933\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.2806 - acc: 0.503 - 0s 111us/step - loss: 1.3142 - acc: 0.4871 - val_loss: 6.2570 - val_acc: 0.1933\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3148 - acc: 0.4814 - val_loss: 6.2351 - val_acc: 0.1933\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3146 - acc: 0.4886 - val_loss: 6.2519 - val_acc: 0.1933\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3147 - acc: 0.4871 - val_loss: 6.2352 - val_acc: 0.1933\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3145 - acc: 0.4771 - val_loss: 6.2352 - val_acc: 0.1933\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3145 - acc: 0.4829 - val_loss: 6.2832 - val_acc: 0.1933\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3153 - acc: 0.4843 - val_loss: 6.2353 - val_acc: 0.1933\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3140 - acc: 0.4871 - val_loss: 6.2015 - val_acc: 0.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3142 - acc: 0.4871 - val_loss: 6.2353 - val_acc: 0.1933\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3143 - acc: 0.4829 - val_loss: 6.2833 - val_acc: 0.1933\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3142 - acc: 0.4886 - val_loss: 6.2354 - val_acc: 0.1933\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3138 - acc: 0.4857 - val_loss: 6.2834 - val_acc: 0.1933\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3137 - acc: 0.4843 - val_loss: 6.2834 - val_acc: 0.1933\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3137 - acc: 0.4886 - val_loss: 6.2834 - val_acc: 0.1933\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3136 - acc: 0.4814 - val_loss: 6.2105 - val_acc: 0.1933\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3144 - acc: 0.4800 - val_loss: 6.1452 - val_acc: 0.1933\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3139 - acc: 0.4843 - val_loss: 6.2835 - val_acc: 0.1933\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3127 - acc: 0.4886 - val_loss: 6.2356 - val_acc: 0.1933\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3140 - acc: 0.4857 - val_loss: 6.2836 - val_acc: 0.1933\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3143 - acc: 0.4843 - val_loss: 6.2356 - val_acc: 0.1933\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3138 - acc: 0.4929 - val_loss: 6.2356 - val_acc: 0.1933\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3136 - acc: 0.4829 - val_loss: 6.2357 - val_acc: 0.1933\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3132 - acc: 0.4886 - val_loss: 6.2357 - val_acc: 0.1933\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3135 - acc: 0.4886 - val_loss: 6.2357 - val_acc: 0.1933\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3137 - acc: 0.4814 - val_loss: 6.2358 - val_acc: 0.1933\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3131 - acc: 0.4886 - val_loss: 6.2358 - val_acc: 0.1933\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3128 - acc: 0.4900 - val_loss: 6.2358 - val_acc: 0.1933\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3124 - acc: 0.4814 - val_loss: 6.2358 - val_acc: 0.1933\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3135 - acc: 0.4900 - val_loss: 6.2359 - val_acc: 0.1933\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3125 - acc: 0.4886 - val_loss: 6.2359 - val_acc: 0.1933\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3124 - acc: 0.4814 - val_loss: 6.2359 - val_acc: 0.1933\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3126 - acc: 0.4814 - val_loss: 6.2359 - val_acc: 0.1933\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3129 - acc: 0.4871 - val_loss: 6.2360 - val_acc: 0.1933\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3127 - acc: 0.4814 - val_loss: 6.2360 - val_acc: 0.1933\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.3123 - acc: 0.4886 - val_loss: 6.2840 - val_acc: 0.1933\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.3127 - acc: 0.4814 - val_loss: 6.2360 - val_acc: 0.1933\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3125 - acc: 0.4943 - val_loss: 6.2361 - val_acc: 0.1933\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3119 - acc: 0.4900 - val_loss: 6.2361 - val_acc: 0.1933\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3129 - acc: 0.4857 - val_loss: 6.2362 - val_acc: 0.1933\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3116 - acc: 0.4886 - val_loss: 6.2362 - val_acc: 0.1933\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3108 - acc: 0.4943 - val_loss: 6.2362 - val_acc: 0.1933\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3129 - acc: 0.4843 - val_loss: 6.2633 - val_acc: 0.1933\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3113 - acc: 0.4914 - val_loss: 6.2362 - val_acc: 0.1933\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3109 - acc: 0.4929 - val_loss: 6.2362 - val_acc: 0.1933\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3119 - acc: 0.4871 - val_loss: 6.2363 - val_acc: 0.1933\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3107 - acc: 0.4814 - val_loss: 6.2363 - val_acc: 0.1933\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3120 - acc: 0.4857 - val_loss: 6.2363 - val_acc: 0.1933\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3125 - acc: 0.4757 - val_loss: 6.2364 - val_acc: 0.1933\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3111 - acc: 0.4900 - val_loss: 6.2364 - val_acc: 0.1933\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3103 - acc: 0.4843 - val_loss: 6.2364 - val_acc: 0.1933\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3107 - acc: 0.4900 - val_loss: 6.2461 - val_acc: 0.1933\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3112 - acc: 0.4843 - val_loss: 6.2568 - val_acc: 0.1933\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3109 - acc: 0.4843 - val_loss: 6.2365 - val_acc: 0.1933\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3115 - acc: 0.4829 - val_loss: 6.2365 - val_acc: 0.1933\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3102 - acc: 0.4929 - val_loss: 6.2365 - val_acc: 0.1933\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3111 - acc: 0.4857 - val_loss: 6.2366 - val_acc: 0.1933\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3101 - acc: 0.4900 - val_loss: 6.2366 - val_acc: 0.1933\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3116 - acc: 0.4843 - val_loss: 6.2366 - val_acc: 0.1933\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3110 - acc: 0.4857 - val_loss: 6.2367 - val_acc: 0.1933\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3109 - acc: 0.4900 - val_loss: 6.2367 - val_acc: 0.1933\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3098 - acc: 0.4929 - val_loss: 6.2367 - val_acc: 0.1933\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3096 - acc: 0.4943 - val_loss: 6.2847 - val_acc: 0.1933\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3111 - acc: 0.4814 - val_loss: 6.1944 - val_acc: 0.1933\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3109 - acc: 0.4857 - val_loss: 6.2368 - val_acc: 0.1933\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3105 - acc: 0.4843 - val_loss: 6.2369 - val_acc: 0.1933\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3109 - acc: 0.4871 - val_loss: 6.2771 - val_acc: 0.1933\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3102 - acc: 0.4857 - val_loss: 6.2369 - val_acc: 0.1933\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 1.3097 - acc: 0.4900 - val_loss: 6.1696 - val_acc: 0.1933\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3097 - acc: 0.4843 - val_loss: 6.2369 - val_acc: 0.1933\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3098 - acc: 0.4886 - val_loss: 6.2370 - val_acc: 0.1933\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3106 - acc: 0.4829 - val_loss: 6.2370 - val_acc: 0.1933\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3101 - acc: 0.4843 - val_loss: 6.2370 - val_acc: 0.1933\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3098 - acc: 0.4871 - val_loss: 6.2370 - val_acc: 0.1933\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3092 - acc: 0.4943 - val_loss: 6.2371 - val_acc: 0.1933\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3086 - acc: 0.4929 - val_loss: 6.2371 - val_acc: 0.1933\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3096 - acc: 0.4843 - val_loss: 6.2371 - val_acc: 0.1933\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3101 - acc: 0.4829 - val_loss: 6.2371 - val_acc: 0.1933\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3100 - acc: 0.4857 - val_loss: 6.2523 - val_acc: 0.1933\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3101 - acc: 0.4814 - val_loss: 6.2372 - val_acc: 0.1933\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3094 - acc: 0.4886 - val_loss: 6.2145 - val_acc: 0.1933\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3097 - acc: 0.4929 - val_loss: 6.2372 - val_acc: 0.1933\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3092 - acc: 0.4829 - val_loss: 6.2373 - val_acc: 0.1933\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3097 - acc: 0.4871 - val_loss: 6.2373 - val_acc: 0.1933\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3087 - acc: 0.4886 - val_loss: 6.2853 - val_acc: 0.1933\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3083 - acc: 0.4814 - val_loss: 6.2373 - val_acc: 0.1933\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3093 - acc: 0.4857 - val_loss: 6.2374 - val_acc: 0.1933\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3091 - acc: 0.4914 - val_loss: 6.2374 - val_acc: 0.1933\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3092 - acc: 0.4929 - val_loss: 6.2374 - val_acc: 0.1933\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3089 - acc: 0.4886 - val_loss: 6.2374 - val_acc: 0.1933\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3086 - acc: 0.4871 - val_loss: 6.2375 - val_acc: 0.1933\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3088 - acc: 0.4900 - val_loss: 6.2375 - val_acc: 0.1933\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3083 - acc: 0.4971 - val_loss: 6.2375 - val_acc: 0.1933\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3088 - acc: 0.4843 - val_loss: 6.2855 - val_acc: 0.1933\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3090 - acc: 0.4929 - val_loss: 6.1896 - val_acc: 0.1933\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3090 - acc: 0.4914 - val_loss: 6.2376 - val_acc: 0.1933\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3089 - acc: 0.4900 - val_loss: 6.2376 - val_acc: 0.1933\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3091 - acc: 0.4900 - val_loss: 6.2376 - val_acc: 0.1933\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3092 - acc: 0.4900 - val_loss: 6.2419 - val_acc: 0.1933\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3085 - acc: 0.4900 - val_loss: 6.2377 - val_acc: 0.1933\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3080 - acc: 0.4900 - val_loss: 6.2377 - val_acc: 0.1933\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3083 - acc: 0.4857 - val_loss: 6.2377 - val_acc: 0.1933\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3089 - acc: 0.4814 - val_loss: 6.2377 - val_acc: 0.1933\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3079 - acc: 0.4929 - val_loss: 6.2378 - val_acc: 0.1933\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3078 - acc: 0.4900 - val_loss: 6.2378 - val_acc: 0.1933\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3080 - acc: 0.4986 - val_loss: 6.2378 - val_acc: 0.1933\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3075 - acc: 0.4857 - val_loss: 6.1205 - val_acc: 0.1933\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3079 - acc: 0.4900 - val_loss: 6.2379 - val_acc: 0.1933\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3078 - acc: 0.4929 - val_loss: 6.2379 - val_acc: 0.1933\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3074 - acc: 0.4914 - val_loss: 6.2379 - val_acc: 0.1933\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3080 - acc: 0.4829 - val_loss: 6.2379 - val_acc: 0.1933\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3072 - acc: 0.4943 - val_loss: 6.2379 - val_acc: 0.1933\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3073 - acc: 0.4886 - val_loss: 6.2380 - val_acc: 0.1933\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3081 - acc: 0.4843 - val_loss: 6.2380 - val_acc: 0.1933\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3072 - acc: 0.4900 - val_loss: 6.2380 - val_acc: 0.1933\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3080 - acc: 0.4971 - val_loss: 6.2381 - val_acc: 0.1933\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3075 - acc: 0.4814 - val_loss: 6.2381 - val_acc: 0.1933\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3068 - acc: 0.4971 - val_loss: 6.2382 - val_acc: 0.1933\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3056 - acc: 0.4814 - val_loss: 6.2764 - val_acc: 0.1933\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3091 - acc: 0.4886 - val_loss: 6.2382 - val_acc: 0.1933\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3074 - acc: 0.4929 - val_loss: 6.2382 - val_acc: 0.1933\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3078 - acc: 0.4871 - val_loss: 6.2383 - val_acc: 0.1933\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3069 - acc: 0.4871 - val_loss: 6.2383 - val_acc: 0.1933\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3070 - acc: 0.4914 - val_loss: 6.2383 - val_acc: 0.1933\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3072 - acc: 0.4929 - val_loss: 6.2384 - val_acc: 0.1933\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3070 - acc: 0.4886 - val_loss: 6.2384 - val_acc: 0.1933\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3067 - acc: 0.4914 - val_loss: 6.2384 - val_acc: 0.1933\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3069 - acc: 0.4971 - val_loss: 6.2384 - val_acc: 0.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3073 - acc: 0.4886 - val_loss: 6.2385 - val_acc: 0.1933\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3064 - acc: 0.4886 - val_loss: 6.2385 - val_acc: 0.1933\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3064 - acc: 0.4914 - val_loss: 6.2385 - val_acc: 0.1933\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3061 - acc: 0.4929 - val_loss: 6.2386 - val_acc: 0.1933\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3064 - acc: 0.4900 - val_loss: 6.2169 - val_acc: 0.1933\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3066 - acc: 0.4886 - val_loss: 6.2386 - val_acc: 0.1933\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3064 - acc: 0.4914 - val_loss: 6.2387 - val_acc: 0.1933\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3065 - acc: 0.4900 - val_loss: 6.2387 - val_acc: 0.1933\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3059 - acc: 0.4900 - val_loss: 6.2387 - val_acc: 0.1933\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3061 - acc: 0.4929 - val_loss: 6.2388 - val_acc: 0.1933\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3067 - acc: 0.4900 - val_loss: 6.2388 - val_acc: 0.1933\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3055 - acc: 0.4929 - val_loss: 6.2388 - val_acc: 0.1933\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3063 - acc: 0.4871 - val_loss: 6.2388 - val_acc: 0.1933\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3057 - acc: 0.4943 - val_loss: 6.2389 - val_acc: 0.1933\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3068 - acc: 0.4886 - val_loss: 6.2389 - val_acc: 0.1933\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3061 - acc: 0.4900 - val_loss: 6.2389 - val_acc: 0.1933\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3057 - acc: 0.4957 - val_loss: 6.2389 - val_acc: 0.1933\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3058 - acc: 0.4871 - val_loss: 6.2389 - val_acc: 0.1933\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3059 - acc: 0.4857 - val_loss: 6.2389 - val_acc: 0.1933\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3051 - acc: 0.4814 - val_loss: 6.2390 - val_acc: 0.1933\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3052 - acc: 0.4914 - val_loss: 6.2390 - val_acc: 0.1933\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3054 - acc: 0.4957 - val_loss: 6.2390 - val_acc: 0.1933\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3053 - acc: 0.4943 - val_loss: 6.2390 - val_acc: 0.1933\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3048 - acc: 0.4957 - val_loss: 6.2390 - val_acc: 0.1933\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3056 - acc: 0.4886 - val_loss: 6.2391 - val_acc: 0.1933\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3053 - acc: 0.4943 - val_loss: 6.2391 - val_acc: 0.1933\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3050 - acc: 0.4900 - val_loss: 6.1854 - val_acc: 0.1933\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3050 - acc: 0.4929 - val_loss: 6.2392 - val_acc: 0.1933\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3054 - acc: 0.4900 - val_loss: 6.2392 - val_acc: 0.1933\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3054 - acc: 0.4900 - val_loss: 6.2392 - val_acc: 0.1933\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3048 - acc: 0.4886 - val_loss: 6.2392 - val_acc: 0.1933\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3047 - acc: 0.4886 - val_loss: 6.2273 - val_acc: 0.1933\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3041 - acc: 0.4957 - val_loss: 6.2393 - val_acc: 0.1933\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3050 - acc: 0.4929 - val_loss: 6.2393 - val_acc: 0.1933\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3050 - acc: 0.4900 - val_loss: 6.2393 - val_acc: 0.1933\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3046 - acc: 0.4900 - val_loss: 6.2393 - val_acc: 0.1933\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3044 - acc: 0.4871 - val_loss: 6.2394 - val_acc: 0.1933\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3036 - acc: 0.4957 - val_loss: 6.2394 - val_acc: 0.1933\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3049 - acc: 0.4886 - val_loss: 6.2394 - val_acc: 0.1933\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3042 - acc: 0.4886 - val_loss: 6.2395 - val_acc: 0.1933\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3038 - acc: 0.4914 - val_loss: 6.2395 - val_acc: 0.1933\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3042 - acc: 0.4929 - val_loss: 6.2395 - val_acc: 0.1933\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3038 - acc: 0.5000 - val_loss: 6.2396 - val_acc: 0.1933\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3042 - acc: 0.4843 - val_loss: 6.2396 - val_acc: 0.1933\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3038 - acc: 0.4914 - val_loss: 6.2396 - val_acc: 0.1933\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3041 - acc: 0.4929 - val_loss: 6.2396 - val_acc: 0.1933\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3040 - acc: 0.4871 - val_loss: 6.2396 - val_acc: 0.1933\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3040 - acc: 0.4943 - val_loss: 6.2397 - val_acc: 0.1933\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3033 - acc: 0.4943 - val_loss: 6.2397 - val_acc: 0.1933\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3039 - acc: 0.4886 - val_loss: 6.2397 - val_acc: 0.1933\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3036 - acc: 0.4871 - val_loss: 6.2398 - val_acc: 0.1933\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3041 - acc: 0.4900 - val_loss: 6.2128 - val_acc: 0.1933\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3038 - acc: 0.4929 - val_loss: 6.2398 - val_acc: 0.1933\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3033 - acc: 0.4943 - val_loss: 6.2399 - val_acc: 0.1933\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3034 - acc: 0.4900 - val_loss: 6.2399 - val_acc: 0.1933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11710fdd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log_dir에 있는 파일을 텐서보드가 읽어서 그래픽으로 띄워준다.\n",
    "tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model.fit(X_train,Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[tb_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
